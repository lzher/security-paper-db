[
  {
    "title": "Cryptography and Computer Security: A View From the Year 2100",
    "author": "Boneh, Dan",
    "abstract": "What will computer security look like in the year 2100? This talk will begin with a few predictions that aim to suggest a few research directions in the present. We will then transition to the exciting area of applied zero knowledge proofs, an area that has seen tremendous growth in recent years. We will describe some of the new ideas in the space and focus on a number of remarkable real-word applications of these techniques. The talk will be self contained and accessible to all.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690378",
    "comment": ""
  },
  {
    "title": "Staving off the IoT Armageddon",
    "author": "Tsudik, Gene",
    "abstract": "IoT devices are increasingly popular and ubiquitous in numerous everyday settings. These specialized gadgets sense and actuate the environment using a wide range of analog peripherals. They are usually deployed in large numbers and often perform safety-and/or mission-critical tasks, in both military and civilian domains. It is no surprise that they represent attractive targets for various attacks. Adversaries range from nation-states to groups (motivated by politics, competition, or greed), to individual malcontents. Their goals vary based on targeted functionality: compromised sensors can exfiltrate sensitive information, while compromised actuators can affect the environment, i.e., physical safety and security. The well-known Stuxnet (2010) is an example of the latter, while numerous hacks into IoT cams exemplify the former. The infamous Mirai botnet (2017) is yet another \"preview of coming attractions\": it successfully zombified a huge number of consumer-grade cameras to form a global botnet later used to mount massive Distributed Denialof- Service (DDoS) attacks.1 Sadly, recent history shows that few, if any, lessons were learned as a result of these attacks. Although not quite malware-relevant, the recent CrowdStrike fiasco underscores the problem. IoT devices are still commonly compromised via both known attack types and zero-day exploits. Realistically speaking, the worst is yet to come. Unfortunately, the current security research limelight is on (both real and imagined) dangers of AI and Machine Learning algorithms, their unfairness, etc. There is thus a real risk of missing the real and present danger posed by the rampant (in)security of the IoT ecosystem.What makes the situation so dire? There are several reasons: First, most IoT-focused attacks and exploits are not physical in nature, meaning that they do not require the adversary to be present at or near victim devices. Because devices are increasingly interconnected and/or connected to the global Internet, they can be reached and attacked remotely. This yields many benefits to the adversary, such as much greater scale of attacks and relative impunity. Remote attacks occur because, similar to general-purpose computers, most IoT devices are programmable and/or configurable, meaning that they contain software/firmware that is fundamentally malleable in order to support legitimate updates and customizable functionality.Second, device manufacturers face certain constraints driven by the desire to offer new or better device functionalities at lower prices, and to do so in a hurry, i.e., the \"rush-to-market\" syndrome. Since security, in and of itself, is not viewed as a useful service, but rather as an inhibitor, it is either ignored or treated as an afterthought. This occurs due to lack of security expertise or because of the pressure to keep device costs low. It thus seems acceptable for manufacturers to improve security reactively, e.g., release patched software/firmware only after an attacks occurs or an exploit becomes public. Furthermore, security is viewed as a barrier to usability, making devices harder to set up and operate by users who are not technologicall adept.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690379",
    "comment": ""
  },
  {
    "title": "Verifiable Security Policies for Distributed Systems",
    "author": "Wolf, Felix A. and M\\\"{u}ller, Peter",
    "abstract": "In the context of secure information flow, security policies express the classification and declassification of data. Existing policy frameworks are tightly linked to a programming language, which limits their flexibility and complicates reasoning, for instance, during audits. We present a framework for the specification and verification of security policies for distributed systems, where attackers may observe the I/O performed by a program, but not its memory. Our policies are expressed over the I/O behaviors of programs and, thereby, language-agnostic. We present techniques to reason formally about policies, and to verify that an implementation satisfies a given policy. We formalize these verification techniques in Isabelle/HOL. An evaluation on several case studies, including an implementation of the WireGuard VPN key exchange protocol, demonstrates that our policies are expressive, and that verification is amenable to SMT-based verification.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690303",
    "comment": ""
  },
  {
    "title": "Libra: Architectural Support For Principled, Secure And Efficient Balanced Execution On High-End Processors",
    "author": "Winderix, Hans and Bognar, Marton and Daniel, Lesly-Ann and Piessens, Frank",
    "abstract": "Control-flow leakage (CFL) attacks enable an attacker to expose control-flow decisions of a victim program via side-channel observations. Linearization (i.e. elimination) of secret-dependent control flow is the main countermeasure against these attacks, yet it comes at a non-negligible cost. Conversely, balancing secret-dependent branches often incurs a smaller overhead, but is notoriously insecure on high-end processors. Hence, linearization has been widely believed to be the only effective countermeasure against CFL attacks. In this paper, we challenge this belief and investigate an unexplored alternative: how to securely balance secret-dependent branches on higher-end processors?We propose Libra, a generic and principled hardware-software codesign to efficiently address CFL on high-end processors. We perform a systematic classification of hardware primitives leaking control flow from the literature, and provide guidelines to handle them with our design. Importantly, Libra enables secure control-flow balancing without the need to disable performance-critical hardware such as the instruction cache and the prefetcher. We formalize the semantics of Libra and propose a code transformation algorithm for securing programs, which we prove correct and secure. Finally, we implement and evaluate Libra on an out-of-order RISC-V processor, showing performance overhead on par with insecure balanced code, and outperforming state-of-the-art linearized code by 19.3\\%.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690319",
    "comment": ""
  },
  {
    "title": "Compositional Verification of Composite Byzantine Protocols",
    "author": "Zhao, Qiyuan and P\\^{\\i}rlea, George and Grzeszkiewicz, Karolina and Gilbert, Seth and Sergey, Ilya",
    "abstract": "Byzantine Fault-Tolerant (BFT) protocols are known to be difficult to design and to reason about. To address this challenge, on one hand, several approaches have been developed recently for computer-aided formal verification of the desired correctness properties, both safety and liveness, of standalone BFT protocols. On the other hand, the distributed computing community has made attempts to reduce the conceptual complexity of constructing new such protocols by showing how to assemble them from simpler \"building blocks\". No methodology to date combines these two approaches for foundational verification of arbitrary BFT protocols.We present Bythos, the first foundational framework for compositional mechanised verification of both safety and liveness of composite BFT protocols. Bythos is implemented on top of the Coq proof assistant and uses Coq's higher-order logic to reuse proofs of common facts about knowledge and trust in BFT protocols. It allows for compact liveness specifications in the style of TLA+, and for their proofs using an embedding of TLA into Coq. Most importantly, Bythos provides a family of higher-order definitions that allow building composite BFT protocols from simpler ones, with their correctness proofs derived. We showcase Bythos by verifying in it safety and liveness properties of three basic BFT protocols: Reliable Broadcast, Provable Broadcast, and the recently proposed Accountable Byzantine Confirmer, as well as their compositions.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690355",
    "comment": ""
  },
  {
    "title": "Byzantine-Secure Relying Party for Resilient RPKI",
    "author": "Frie\\ss{}, Jens and Mirdita, Donika and Schulmann, Haya and Waidner, Michael",
    "abstract": "BGP is a gaping hole in Internet security, as evidenced by numerous hijacks and outages. The significance of BGP for stability and security of the Internet has made it a top priority on the cyber security agenda of the US government, with CISA, FCC, and other federal agencies leading the efforts.To protect against prefix hijacks, Resource Public Key Infrastructure (RPKI) has been standardized. Yet, RPKI validation is still not widely supported. To enjoy the security guarantees of RPKI, networks need to install a new component, the Relying Party validator, which fetches and validates RPKI objects and provides them to border routers. However, research showed that Relying Parties experience failures when retrieving RPKI objects and are vulnerable to a range of attacks, all of which can disable RPKI validation. Therefore, even the few adopters are not necessarily secure.We propose a Byzantine-secure Relying Party functionality, we call ByzRP, and show that it significantly improves the resilience and security of RPKI validation. With ByzRP, Relying Party nodes redundantly validate RPKI objects and reach a global consensus through a voting process. ByzRP removes the need for networks to install, operate, and upgrade their own Relying Party instances on the one hand, and does not require to trust the individual operators of ByzRP nodes on the other hand.We show through simulations and experimental evaluations that ByzRP, as an intermediate RPKI service, reduces the load on RPKI publication points and produces a robust output, despite RPKI repository failures, jitters, and attacks. We engineer ByzRP to be fully backward compatible and readily deployable - it does not require any changes to border routers and RPKI repositories. We demonstrate that ByzRP can protect networks transparently, either with a decentralized or a centralized deployment and it enables users to independently verify the correctness of its operation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690368",
    "comment": ""
  },
  {
    "title": "SysBumps: Exploiting Speculative Execution in System Calls for Breaking KASLR in macOS for Apple Silicon",
    "author": "Jang, Hyerean and Kim, Taehun and Shin, Youngjoo",
    "abstract": "Apple silicon is the proprietary ARM-based processor that powers the mainstream of Apple devices. The move to this proprietary architecture presents unique challenges in addressing security issues, requiring huge research efforts into the security of Apple silicon-based systems. In this paper, we study the security of KASLR, the randomization-based kernel hardening technique, on the state-of-the-art macOS system equipped with Apple silicon processors. Because KASLR has been subject to many microarchitectural side-channel attacks, the latest operating systems, including macOS, use kernel isolation, which separates the kernel page table from the userspace table. Kernel isolation in macOS provides a barrier to KASLR break attacks. To overcome this, we exploit speculative execution in system calls. By using Spectre-type gadgets in system calls, an unprivileged attacker can cause translations of the attacker's chosen kernel addresses, causing the TLB to change according to the validity of the address. This allows the construction of an attack primitive that breaks KASLR bypassing kernel isolation. Since the TLB is used as a side-channel source, we reverse-engineer the hidden internals of the TLB on various M-series processors using a hardware performance monitoring unit. Based on our attack primitive, we implement SysBumps, the first KASLR break attack on macOS for Apple silicon. Throughout evaluation, we show that SysBumps can effectively break KASLR across different M-series processors and macOS versions. We also discuss possible mitigations against the proposed attack.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690189",
    "comment": ""
  },
  {
    "title": "TDXdown: Single-Stepping and Instruction Counting Attacks against Intel TDX",
    "author": "Wilke, Luca and Sieck, Florian and Eisenbarth, Thomas",
    "abstract": "Trusted Execution Environments are a promising solution for solving the data privacy and trust issues introduced by cloud computing. As a result, all major CPU vendors integrated Trusted Execution Environments (TEEs) into their CPUs. The biggest threat to TEE security are side-channel attacks, of which single-stepping attacks turned out to be the most powerful ones. Enabled by the TEE attacker model, single-stepping attacks allow the attacker to execute the TEE one instruction at a time, enabling numerous controlled- and side-channel based security issues. Intel recently launched Intel TDX, its second generation TEE, which protects whole virtual machines (VMs). To minimize the attack surface to side-channels, TDX comes with a dedicated single-stepping attack countermeasure. In this paper, we systematically analyze the single-stepping countermeasure of Intel TDX and show, for the first time, that both, the built-in detection heuristic as well as the prevention mechanism, can be circumvented. We reliably single-step TDX-protected VMs by deluding the TDX security monitor about the elapsed processing time used as part of the detection heuristic. Moreover, our study reveals a design flaw in the single-stepping countermeasure that turns the prevention mechanism against itself: An inherent side-channel within the prevention mechanism leaks the number of instructions executed by the TDX-protected VM, enabling a novel attack we refer to as StumbleStepping. Both attacks, single-stepping and StumbleStepping, work on the most recent Intel TDX enabled Xeon Scalable CPUs. Using StumbleStepping, we demonstrate a novel end-to-end attack against wolfSSL's ECDSA implementation, exploiting a control flow side-channel in its truncation-based nonce generation algorithm. We provide a systematic study of nonce-truncation implementations, revealing similar leakages in OpenSSL, which we exploit with our single-stepping primitive. Finally, we propose design changes to TDX to mitigate our attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690230",
    "comment": ""
  },
  {
    "title": "Cross-Core Interrupt Detection: Exploiting User and Virtualized IPIs",
    "author": "Rauscher, Fabian and Gruss, Daniel",
    "abstract": "Interrupts are fundamental for inter-process and cross-core communication in modern systems. Controlling these communication mechanisms historically requires switches into the kernel or hypervisor, incurring high-performance costs. To alleviate these costs, Intel introduced new hardware mechanisms to send inter-processor interrupts (IPIs) from user space without switching into the kernel and from virtual machines without switching into the hypervisor. However, it is unclear whether this direct, unsupervised interaction between unprivileged (or virtualized) workloads and the underlying hardware introduces a significant change in the attack surface.In this paper, we present the IPI side channel, a novel side-channel attack exploiting the recently introduced user interrupts and IPI virtualization features on Intel Sapphire Rapids and the upcoming Intel Arrow Lake processors. The IPI side channel is the first cross-core interrupt detection side channel, allowing an attacker to monitor interrupts delivered to any physical core of the same processor. Our attack is based on precise measurements of the hardware delivery time of interrupts from user space and virtual machines. More specifically, we exploit that interrupts are delivered through a cross-core bus, leading to timing variations on the attacker's local IPIs. We present multiple case studies to compare the IPI side channel with the state of the art: First, we present an unprivileged cross-core covert channel with a native true capacity of 434.7 kbit/s (n=100, σx=0.03) and a cross-VM capacity of 3.45 kbit/s (n=100, σx=0.01). Second, we demonstrate a native inter-keystroke timing attack with an F1 score of 97.9\\%. Third, we present an open-world website fingerprinting attack on the top 100 websites, achieving an F1 score of 89.0\\% in a native scenario and an F1 score of 71.0\\% in a cross-VM (thin client) scenario. Furthermore, we discuss the broader context of the IPI side channels and categorize interrupt side channels and mitigations.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690242",
    "comment": ""
  },
  {
    "title": "Spec-o-Scope: Cache Probing at Cache Speed",
    "author": "Horowitz, Gal and Ronen, Eyal and Yarom, Yuval",
    "abstract": "Over the last two decades, microarchitectural side channels have been the focus of a large body of research on the development of new attack techniques, exploiting them to attack various classes of targets and designing mitigations. One line of work focuses on increasing the speed of the attacks, achieving higher levels of temporal resolution that can allow attackers to learn finer-grained information. The most recent addition to this line of work is Prime+Scope [CCS '21], which only requires a single access to the L1 cache to confirm the absence of victim activity in a cache set. While significantly faster than prior attacks, Prime+Scope is still an order of magnitude slower than cache access. In this work, we set out to close this gap.We draw on techniques from research into microarchitectural weird gates, software constructs that exploit transient execution to perform arbitrary computation on cache state. We design the Spec-o-Scope gate, a new weird gate that performs 10 cache probes in quick succession, which forms the basis for our eponymous attack. Our Spec-o-Scope attack achieves an order of magnitude improvement in temporal resolution compared to the previous state-of-the-art of Prime+Scope, reducing the measurement time from ~70 cycles to only 5 --- only one cycle more than an L1 cache access. We experimentally verify that our attack can detect timing differences in a 5 cycle resolution. Finally, using our Spec-o-Scope attack, we are able to show the first microarchitectural side-channel attack on an unmodified AES S-box-based implementation, which uses generic CPU features and does not require manipulation of the operating system's scheduler.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690313",
    "comment": ""
  },
  {
    "title": "Training Robust ML-based Raw-Binary Malware Detectors in Hours, not Months",
    "author": "Lucas, Keane and Lin, Weiran and Bauer, Lujo and Reiter, Michael K. and Sharif, Mahmood",
    "abstract": "Machine-learning (ML) classifiers are increasingly used to distinguish malware from benign binaries. Recent work has shown that ML-based detectors can be evaded by adversarial examples, but also that one may defend against such attacks via adversarial training. However, adversarial training, and subsequent robustness evaluation, is computationally expensive in the raw-binary malware-detection domain because it requires producing many adversarial examples for both training and evaluation. Prior work found that Greedy-training, a faster robust training technique that forgoes using adversarial examples, showed some promise in producing robust malware detectors. However, Greedy-training was far less effective in inducing robustness than the more expensive adversarial training, and it also severely hurt natural accuracy (i.e., accuracy on the original data). To faster train models, this work presents GreedyBlock-training, an enhanced version of Greedy-training that we empirically show achieves not only state-of-the-art robustness in malware detectors, exceeding even adversarial training, but also retains natural accuracy better than adversarial training. Furthermore, as it does not require creating adversarial (or functional) examples, GreedyBlock-training is significantly faster than adversarial training. Specifically, we show that GreedyBlock-training can produce more robust (+54\\% on average), more naturally accurate (+7\\% on average), and more efficiently trained (-91\\% average computation) malware detectors than prior work. To faster evaluate models, we also develop methods to faster gauge the robustness of ML-based raw-binary malware detectors by introducing robustness proxies, which can be used either to predict which models are likely to be the most robust, thus helping prioritize which detectors to evaluate with expensive attacks, or aiding in deciding which detectors are worthwhile to continue training. Experimentally, we show these proxy measures can find the most robust detector in a pool of detectors while using only ~20-50\\% of the computation that would otherwise be required.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690208",
    "comment": ""
  },
  {
    "title": "TREC: APT Tactic / Technique Recognition via Few-Shot Provenance Subgraph Learning",
    "author": "Lv, Mingqi and Gao, Hongzhe and Qiu, Xuebo and Chen, Tieming and Zhu, Tiantian and Chen, Jinyin and Ji, Shouling",
    "abstract": "APT (Advanced Persistent Threat) with the characteristics of persistence, stealth, and diversity is one of the greatest threats against cyber-infrastructure. As a countermeasure, existing studies leverage provenance graphs to capture the complex relations between system entities in a host for effective APT detection. In addition to detecting single attack events as most existing work does, understanding the tactics / techniques (e.g., Kill-Chain, ATT&CK) applied to organize and accomplish the APT attack campaign is also important for security operations. Existing studies try to manually design a set of rules to map low-level system events to high-level APT tactics / techniques. However, the rule based methods are coarse-grained and lack generalization ability. Thus, they can only recognize APT tactics and have difficulty in identifying APT techniques. They also cannot adapt to mutant behaviors of existing APT tactics / techniques.In this paper, we propose TREC, the first attempt to recognize APT tactics / techniques from provenance graphs by exploiting deep learning techniques. To address the \"needle in a haystack\" problem, TREC segments small and compact subgraphs covering individual APT technique instances from a large provenance graph based on a malicious node detection model and a subgraph sampling algorithm. To address the \"training sample scarcity\" problem, TREC trains the APT tactic / technique recognition model in a few-shot learning manner by adopting a Siamese neural network. We evaluate TREC based on a customized dataset collected and made public by our team. The experiment results show that TREC significantly outperforms state-of-the-art systems in APT tactic recognition and TREC can also effectively identify APT techniques.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690221",
    "comment": ""
  },
  {
    "title": "SAFARI: Speech-Associated Facial Authentication for AR/VR Settings via Robust VIbration Signatures",
    "author": "Zhang, Tianfang and Ji, Qiufan and Ye, Zhengkun and Akanda, Md Mojibur Rahman Redoy and Mahdad, Ahmed Tanvir and Shi, Cong and Wang, Yan and Saxena, Nitesh and Chen, Yingying",
    "abstract": "In AR/VR devices, the voice interface, serving as one of the primary AR/VR control mechanisms, enables users to interact naturally using speeches (voice commands) for accessing data, controlling applications, and engaging in remote communication/meetings. Voice authentication can be adopted to protect against unauthorized speech inputs. However, existing voice authentication mechanisms are usually susceptible to voice spoofing attacks and are unreliable under the variations of phonetic content. In this work, we propose SAFARI, a spoofing-resistant and text-independent speech authentication system that can be seamlessly integrated into AR/VR voice interfaces. The key idea is to elicit phonetic-invariant biometrics from the facial muscle vibrations upon the headset. During speech production, a user's facial muscles are deformed for articulating phoneme sounds. The facial deformations associated with the phonemes are referred to as visemes. They carry rich biometrics of the wearer's muscles, tissue, and bones, which can propagate through the head and vibrate the headset. SAFARI aims to derive reliable facial biometrics from the viseme-associated facial vibrations captured by the AR/VR motion sensors. Particularly, it identifies the vibration data segments that contain rich viseme patterns (prominent visemes) less susceptible to phonetic variations. Based on the prominent visemes, SAFARI learns on the correlations among facial vibrations of different frequencies to extract biometric representations invariant to the phonetic context. The key advantages of SAFARI are that it is suitable for commodity AR/VR headsets (no additional sensors) and is resistant to voice spoofing attacks as the conductive property of the facial vibrations prevents biometric disclosure via the air media or the audio channel. To mitigate the impacts of body motions in AR/VR scenarios, we also design a generative diffusion model trained to reconstruct the viseme patterns from the data distorted by motion artifacts. We conduct extensive experiments with two representative AR/VR headsets and 35 users under various usage and attack settings. We demonstrate that SAFARI can achieve over 96\\% true positive rate on verifying legitimate users while successfully rejecting different kinds of spoofing attacks with over 97\\% true negative rates.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670358",
    "comment": ""
  },
  {
    "title": "KnowGraph: Knowledge-Enabled Anomaly Detection via Logical Reasoning on Graph Data",
    "author": "Zhou, Andy and Xu, Xiaojun and Raghunathan, Ramesh and Lal, Alok and Guan, Xinze and Yu, Bin and Li, Bo",
    "abstract": "Graph-based anomaly detection is pivotal in diverse security applications, such as fraud detection in transaction networks and intrusion detection for network traffic. Standard approaches, including Graph Neural Networks (GNNs), often struggle to generalize across shifting data distributions. For instance, we observe that a real-world eBay transaction dataset revealed an over 50\\% decline in fraud detection accuracy when adding data from only a single new day to the graph due to data distribution shifts. This highlights a critical vulnerability in purely data-driven approaches. Meanwhile, real-world domain knowledge, such as \"simultaneous transactions in two locations are suspicious,\" is more stable and a common existing component of real-world detection strategies. To explicitly integrate such knowledge into data-driven models such as GCNs, we propose KnowGraph, which integrates domain knowledge with data-driven learning for enhanced graph-based anomaly detection. KnowGraph comprises two principal components: (1) a statistical learning component that utilizes a main model for the overarching detection task, augmented by multiple specialized knowledge models that predict domain-specific semantic entities; (2) a reasoning component that employs probabilistic graphical models to execute logical inferences based on model outputs, encoding domain knowledge through weighted first-order logic formulas. In addition, KnowGraph has leveraged the Predictability-Computability-Stability (PCS) framework for veridical data science to estimate and mitigate prediction uncertainties. Empirically, KnowGraph has been rigorously evaluated on two significant real-world scenarios: collusion detection in the online marketplace eBay and intrusion detection within enterprise networks. Extensive experiments on these large-scale real-world datasets show that KnowGraph consistently outperforms state-of-the-art baselines in both transductive and inductive settings, achieving substantial gains in average precision when generalizing to completely unseen test graphs. Further ablation studies demonstrate the effectiveness of the proposed reasoning component in improving detection performance, especially under extreme class imbalance. These results highlight the potential of integrating domain knowledge into data-driven models for high-stakes, graph-based security applications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690354",
    "comment": ""
  },
  {
    "title": "Principled Microarchitectural Isolation on Cloud CPUs",
    "author": "Volos, Stavros and Fournet, C\\'{e}dric and Hofmann, Jana and K\\\"{o}pf, Boris and Oleksenko, Oleksii",
    "abstract": "We present Marghera, a system design that prevents cross-VM microarchitectural side-channel attacks in the cloud. Marghera is based on isolation contracts which, for a given CPU, describe partitions of physical threads and memory that prevent information leakage through shared microarchitectural resources.We develop isolation contracts for the AMD EPYC 7543P, a modern cloud CPU. To this end, we first identify how microarchitectural resources are shared between its physical threads, including caches, cache-coherence directories, and DRAM banks. We then develop coloring schemes-that comprehensively partition these resources-using previously unknown, reverse-engineered indexing functions.We implement Marghera in Microsoft Hyper-V and evaluate it using cloud benchmarks. Our results show that our approach effectively eliminates side-channels caused by shared microarchitectural resources with small performance overheads.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690183",
    "comment": ""
  },
  {
    "title": "Interstellar: Fully Partitioned and Efficient Security Monitoring Hardware Near a Processor Core for Protecting Systems against Attacks on Privileged Software",
    "author": "Song, YongHo and Woo, Byeongsu and Han, Youngkwang and Kang, Brent ByungHoon",
    "abstract": "The existing approaches to instruction trace-based security monitoring hardware are dependent on the privileged software, which presents a significant challenge in defending against attacks on privileged software itself. To address this challenge, we propose Interstellar, which introduces a partitioned hardware near the CPU's main core and leverages the benefit of hardware-level security monitoring. Interstellar is fully partitioned, parallelized, and simultaneously detecting security monitoring hardware. Interstellar's design makes malicious software hard to reverse-engineer how Interstellar detects the attacks, and Interstellar efficiently protects the system against the attacks on the privileged software(e.g., Trusted Execution Environment (TEE)). Moreover, Interstellar not only monitors but also blocks various attacks in a timely manner without stalling a CPU core by designing with a finite-state machine.We implemented a prototype of Interstellar in Rocket chip using a hardware description language and evaluated Interstellar with a Linux kernel and a custom TEE-equipped Linux kernel for Rocket chip on two different FPGA boards. The performance overhead of Interstellar is negligible for benchmark applications. The average performance overhead incurred from Interstellar on 50MHz Rocket core for three different benchmarks is 0.102\\%.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690247",
    "comment": ""
  },
  {
    "title": "μCFI: Formal Verification of Microarchitectural Control-flow Integrity",
    "author": "Ceesay-Seitz, Katharina and Solt, Flavien and Razavi, Kaveh",
    "abstract": "Formal verification of hardware often requires the creation of clock-cycle accurate properties that need tedious and error-prone adaptations for each design. Property violations further require attention from verification engineers to identify affected instructions. This oftentimes manual effort hinders the adoption of formal verification at scale. This paper introduces Microarchitectural Control-Flow Integrity (μCFI), a new general security property that can capture multiple classes of vulnerabilities under different threat models, most notably the microarchitectural violation of constant-time execution and (micro-)architectural vulnerabilities that allow an attacker to hijack the (architectural) control flow. We show a novel approach for the verification of μCFI using a single property that checks for information flows from instruction operands to the program counter by injecting taint at appropriate clock cycles. To check arbitrary sequences of instructions and associate property violations to a specific Instruction Under Verification (IUV), we propose techniques for declassifying tainted data when it is being written to registers and forwarded from the IUV through architecturally known paths. We show that our verification approach is low effort (e.g., requires tagging six signals) while capturing all interactions between unbounded sequences of instructions in the extended threat model of \\o{}urname. We verify four RISC-V CPUs against μCFI and prove that μCFI is satisfied in many cases while detecting five new security vulnerabilities (4 CVEs), three of which are in Ibex, which has already been checked by state-of-the-art verification approaches.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690344",
    "comment": ""
  },
  {
    "title": "Crystalor: Recoverable Memory Encryption Mechanism with Optimized Metadata Structure",
    "author": "Ueno, Rei and Haneda, Hiromichi and Homma, Naofumi and Inoue, Akiko and Minematsu, Kazuhiko",
    "abstract": "This study presents an efficient recoverable memory encryption mechanism, named Crystalor. Existing memory encryption mechanisms, such as Intel SGX integrity tree, offer neither crash consistency nor recoverability, which results in attack surfaces and causes a non-trivial limitation of practical availability. Although the crash consistency of encrypted memory has been studied in the research field of microarchitecture, existing mechanisms lack formal security analysis and cannot incorporate with metadata optimization mechanisms, which are essential to achieve a practical performance. Crystalor efficiently realizes provably-secure recoverable memory encryption with metadata optimization. To establish Crystalor with provable security and practical performance, we develop a dedicated universal hash function PXOR-Hash and a microarchitecture equipped with PXOR-Hash. Crystalor incurs almost no latency overhead under the nominal operations for the recoverability, while it has a simple construction in such a way as to be compatible with existing microarchitectures. We evaluate its practical performance through both algorithmic analyses and system-level simulation in comparison with the state-of-the-art ones, such as SCUE. Crystalor requires 29--62\\% fewer clock cycles per memory read/write operation than SCUE for protecting a 4 TB memory. In addition, Crystalor and SCUE require 312 GB and 554 GB memory overheads for metadata, respectively, which indicates that Crystalor achieves a memory overhead reduction of 44\\%. The results of the system-level simulation using the gem5 simulator indicate that Crystalor achieves a reduction of up to 11.5\\% in the workload execution time compared to SCUE. Moreover, Crystalor achieves a higher availability and memory recovery several thousand times faster than SCUE, as Crystalor offers lazy recovery.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670273",
    "comment": ""
  },
  {
    "title": "Camel: Communication-Efficient and Maliciously Secure Federated Learning in the Shuffle Model of Differential Privacy",
    "author": "Xu, Shuangqing and Zheng, Yifeng and Hua, Zhongyun",
    "abstract": "Federated learning (FL) has rapidly become a compelling paradigm that enables multiple clients to jointly train a model by sharing only gradient updates for aggregation, without revealing their local private data. In order to protect the gradient updates which could also be privacy-sensitive, there has been a line of work studying local differential privacy (LDP) mechanisms to provide a formal privacy guarantee. With LDP mechanisms, clients locally perturb their gradient updates before sharing them out for aggregation. However, such approaches are known for greatly degrading the model utility, due to heavy noise addition. To enable a better privacy-utility trade-off, a recently emerging trend is to apply the shuffle model of DP in FL, which relies on an intermediate shuffling operation on the perturbed gradient updates to achieve privacy amplification. Following this trend, in this paper, we present Camel, a new communication-efficient and maliciously secure FL framework in the shuffle model of DP. Camel first departs from existing works by ambitiously supporting integrity check for the shuffle computation, achieving security against malicious adversary. Specifically, Camel builds on the trending cryptographic primitive of secret-shared shuffle, with custom techniques we develop for optimizing system-wide communication efficiency, and for lightweight integrity checks to harden the security of server-side computation. In addition, we also derive a significantly tighter bound on the privacy loss through analyzing the R\\'{e}nyi differential privacy (RDP) of the overall FL process. Extensive experiments demonstrate that Camel achieves better privacy-utility trade-offs than the state-of-the-art work, with promising performance.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690200",
    "comment": ""
  },
  {
    "title": "S2NeRF: Privacy-preserving Training Framework for NeRF",
    "author": "Zhang, Bokang and Zhang, Yanglin and Zhang, Zhikun and Yang, Jinglan and Huang, Lingying and Wu, Junfeng",
    "abstract": "Neural Radiance Fields (NeRF) have revolutionized 3D computer vision and graphics, facilitating novel view synthesis and influencing sectors like extended reality and e-commerce. However, NeRF's dependence on extensive data collection, including sensitive scene image data, introduces significant privacy risks when users upload this data for model training. To address this concern, we first propose SplitNeRF, a training framework that incorporates split learning (SL) techniques to enable privacy-preserving collaborative model training between clients and servers without sharing local data. Despite its benefits, we identify vulnerabilities in SplitNeRF by developing two attack methods, Surrogate Model Attack and Scene-aided Surrogate Model Attack, which exploit the shared gradient data and a few leaked scene images to reconstruct private scene information. To counter these threats, we introduce S^2NeRF, secure SplitNeRF that integrates effective defense mechanisms. By introducing decaying noise related to the gradient norm into the shared gradient information, S^2NeRF preserves privacy while maintaining a high utility of the NeRF model. Our extensive evaluations across multiple datasets demonstrate the effectiveness of S^2NeRF against privacy breaches, confirming its viability for secure NeRF training in sensitive applications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690185",
    "comment": ""
  },
  {
    "title": "DPM: Clustering Sensitive Data through Separation",
    "author": "Liebenow, Johannes and Sch\\\"{u}tt, Yara and Braun, Tanya and Gehrke, Marcel and Thaeter, Florian and Mohammadi, Esfandiar",
    "abstract": "Clustering is an important tool for data exploration where the goal is to subdivide a data set into disjoint clusters that fit well into the underlying data structure. When dealing with sensitive data, privacy-preserving algorithms aim to approximate the non-private baseline while minimising the leakage of sensitive information. State-of-the-art privacy-preserving clustering algorithms tend to output clusters that are good in terms of the standard metrics, inertia, silhouette score, and clustering accuracy, however, the clustering result strongly deviates from the non-private KMeans baseline.  In this work, we present a privacy-preserving clustering algorithm called DPM that recursively separates a data set into clusters based on a geometrical clustering approach. In addition, DPM estimates most of the data-dependent hyper-parameters in a privacy-preserving way. We prove that DPM preserves Differential Privacy and analyse the utility guarantees of DPM. Finally, we conduct an extensive empirical evaluation for synthetic and real-life data sets. We show that DPM achieves state-of-the-art utility on the standard clustering metrics and yields a clustering result much closer to that of the popular non-private KMeans algorithm without requiring the number of classes.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690271",
    "comment": ""
  },
  {
    "title": "S-BDT: Distributed Differentially Private Boosted Decision Trees",
    "author": "Peinemann, Thorsten and Kirschte, Moritz and Stock, Joshua and Cotrini, Carlos and Mohammadi, Esfandiar",
    "abstract": "We introduce S-BDT: a novel (ε,δ)-differentially private distributed gradient boosted decision tree (GBDT) learner that improves the protection of single training data points (privacy) while achieving meaningful learning goals, such as accuracy or regression error (utility). S-BDT uses less noise by relying on non-spherical multivariate Gaussian noise, for which we show tight subsampling bounds for privacy amplification and incorporate that into a R\\'{e}nyi filter for individual privacy accounting. We experimentally reach the same utility while saving 50\\% in terms of epsilon for ε ≤ 0.5 on the Abalone regression dataset (dataset size ≈ 4K), saving 30\\% in terms of epsilon for ε ≤ 0.08 for the Adult classification dataset (dataset size ≈ 50K), and saving 30\\% in terms of epsilon for ε ≤ 0.03 for the Spambase classification dataset (dataset size ≈ 5K). Moreover, we show that for situations where a GBDT is learning a stream of data that originates from different subpopulations (non-IID), S-BDT improves the saving of epsilon even further.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690301",
    "comment": ""
  },
  {
    "title": "Cross-silo Federated Learning with Record-level Personalized Differential Privacy",
    "author": "Liu, Junxu and Lou, Jian and Xiong, Li and Liu, Jinfei and Meng, Xiaofeng",
    "abstract": "Federated learning (FL) enhanced by differential privacy has emerged as a popular approach to better safeguard the privacy of client-side data by protecting clients' contributions during the training process. Existing solutions typically assume a uniform privacy budget for all records and provide one-size-fits-all solutions that may not be adequate to meet each record's privacy requirement. In this paper, we explore the uncharted territory of cross-silo FL with record-level personalized differential privacy. We devise a novel framework namedrPDP-FL, employing a two-stage hybrid sampling scheme with both uniform client-level sampling and non-uniform record-level sampling to accommodate varying privacy requirements.A critical and non-trivial problem is how to determine the ideal per-record sampling probability q given the personalized privacy budget ε. We introduce a versatile solution namedSimulation-CurveFitting, allowing us to uncover a significant insight into the nonlinear correlation between q and ε and derive an elegant mathematical model to tackle the problem. Our evaluation demonstrates that our solution can provide significant performance gains over the baselines that do not consider personalized privacy preservation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670351",
    "comment": ""
  },
  {
    "title": "Benchmarking Secure Sampling Protocols for Differential Privacy",
    "author": "Fu, Yucheng and Wang, Tianhao",
    "abstract": "Differential privacy (DP) is widely employed to provide privacy protection for individuals by limiting information leakage from the aggregated data. Two well-known models of DP are the central model and the local model. The former requires a trustworthy server for data aggregation, while the latter requires individuals to add noise, significantly decreasing the utility of aggregated results. Recently, many studies have proposed to achieve DP with Secure Multi-party Computation (MPC) in distributed settings, namely, the distributed model, which has utility comparable to central model while, under specific security assumptions, preventing parties from obtaining others' information. One challenge of realizing DP in distributed model is efficiently sampling noise with MPC. Although many secure sampling methods have been proposed, they have different security assumptions and isolated theoretical analyses. There is a lack of experimental evaluations to measure and compare their performances. We fill this gap by benchmarking existing sampling protocols in MPC and performing comprehensive measurements of their efficiency. First, we present a taxonomy of the underlying techniques of these sampling protocols. Second, we extend widely used distributed noise generation protocols to be resilient against Byzantine attackers. Third, we implement discrete sampling protocols and align their security settings for a fair comparison. We then conduct an extensive evaluation to study their efficiency and utility. Our experiments show that (1) malicious protocols based on a technique called bitwise sampling are more efficient than other methods, and using an oblivious data structure can reduce the circuit size in high-security regimes, (2) the cost of realizing malicious security is high, under the assumption of semi-honest, using a method named distributed noise generation is much more efficient, and (3) the utility loss caused by sampling noise in MPC is small, which to a certain extent eliminates utility concerns when using the DDP protocol in practice. We open-source our code at https://github.com/yuchengxj/Secure-sampling-benchmark.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690257",
    "comment": ""
  },
  {
    "title": "Smooth Sensitivity for Geo-Privacy",
    "author": "Liang, Yuting and Yi, Ke",
    "abstract": "Suppose each user i holds a private value xi in some metric space (U, dist), and an untrusted data analyst wishes to compute Σi f(xi) for some function f : U -> R by asking each user to send in a privatized f(xi). This is a fundamental problem in privacy-preserving population analytics, and the local model of differential privacy (LDP) is the predominant model under which the problem has been studied. However, LDP requires any two different xi, x'i to be ε-distinguishable, which can be overly strong for geometric/numerical data. On the other hand, Geo-Privacy (GP) stipulates that the level of distinguishability be proportional to dist(xi, xi'), providing an attractive alternative notion of personal data privacy in a metric space. However, existing GP mechanisms for this problem, which add a uniform noise to either xi or f(xi), are not satisfactory. In this paper, we generalize the smooth sensitivity framework from Differential Privacy to Geo-Privacy, which allows us to add noise tailored to the hardness of the given instance. We provide definitions, mechanisms, and a generic procedure for computing the smooth sensitivity under GP equipped with a general metric. Then we present three applications: one-way and two-way threshold functions, and Gaussian kernel density estimation, to demonstrate the applicability and utility of our smooth sensitivity framework.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690365",
    "comment": ""
  },
  {
    "title": "Metric Differential Privacy at the User-Level via the Earth-Mover's Distance",
    "author": "Imola, Jacob and Roy Chowdhury, Amrita and Chaudhuri, Kamalika",
    "abstract": "Metric differential privacy (DP) provides heterogeneous privacy guarantees based on a distance between the pair of inputs. It is a widely popular notion of privacy since it captures the natural privacy semantics for many applications (such as, for location data) and results in better utility than standard DP. However, prior work in metric DP has primarily focused on the item-level setting where every user only reports a single data item. A more realistic setting is that of user-level DP where each user contributes multiple items and privacy is then desired at the granularity of the user's entire contribution. In this paper, we initiate the study of one natural definition of metric DP at the user-level. Specifically, we use the earth-mover's distance (dEM) as our metric to obtain a notion of privacy as it captures both the magnitude and spatial aspects of changes in a user's data.We make three main technical contributions. First, we design two novel mechanisms under dEM-DP to answer linear queries and item-wise queries. Specifically, our analysis for the latter involves a generalization of the privacy amplification by shuffling result which may be of independent interest. Second, we provide a black-box reduction from the general unbounded to bounded dEM-DP (size of the dataset is fixed and public) with a novel sampling based mechanism. Third, we show that our proposed mechanisms can provably provide improved utility over user-level DP, for certain types of linear queries and frequency estimation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690363",
    "comment": ""
  },
  {
    "title": "Nakamoto Consensus under Bounded Processing Capacity",
    "author": "Kiffer, Lucianna and Neu, Joachim and Sridhar, Srivatsan and Zohar, Aviv and Tse, David",
    "abstract": "For Nakamoto's longest-chain consensus protocol, whose proof-of-work (PoW) and proof-of-stake (PoS) variants power major blockchains such as Bitcoin and Cardano, we revisit the classic problem of the security--performance tradeoff: Given a network of nodes with finite communication- and computation-resources, against what fraction of adversary power is Nakamoto consensus (NC) secure for a given block production rate? State-of-the-art analyses of NC fail to answer this question, because their bounded-delay model does not capture the rate limits to nodes' processing of blocks, which cause congestion when blocks are released in quick succession. We develop a new analysis technique to prove a refined security--performance tradeoff for PoW NC in a bounded-capacity model. In this model, we show that, in contrast to the classic bounded-delay model, Nakamoto's private attack is no longer the worst attack, and a new attack we call the teasing strategy, that exploits congestion, is strictly worse. In PoS, equivocating blocks can exacerbate congestion, making traditional PoS NC insecure except at very low block production rates. To counter such equivocation spamming, we present a variant of PoS NC we call Blanking NC (BlaNC), which achieves the same resilience as PoW NC.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670347",
    "comment": ""
  },
  {
    "title": "Data Independent Order Policy Enforcement: Limitations and Solutions",
    "author": "Wadhwa, Sarisht and Zanolini, Luca and Asgaonkar, Aditya and D'Amato, Francesco and Fang, Chengrui and Zhang, Fan and Nayak, Kartik",
    "abstract": "Order manipulation attacks such as frontrunning and sandwiching have become an increasing concern in blockchain applications such as DeFi. To protect from such attacks, several recent works have designed order policy enforcement (OPE) protocols to order transactions fairly in a data-independent fashion. However, while the manipulation attacks are motivated by monetary profits, the defenses assume honesty among a significantly large set of participants. In existing protocols, if all participants are rational, they may be incentivized to collude and circumvent the order policy without incurring any penalty.This work makes two key contributions. First, we explore whether the need for the honesty assumption is fundamental. Indeed, we show that it is impossible to design OPE protocols under some requirements when all parties are rational. Second, we explore the tradeoffs needed to circumvent the impossibility result. In the process, we propose a novel concept of rationally binding transactions that allows us to construct AnimaguSwap, the first content-oblivious Automated Market Makers (AMM) interface that is secure under rationality. We report on a prototype implementation of AnimaguSwap and performance evaluation results demonstrating its practicality.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670367",
    "comment": ""
  },
  {
    "title": "Securing Lightning Channels against Rational Miners",
    "author": "Aumayr, Lukas and Avarikioti, Zeta and Maffei, Matteo and Mazumdar, Subhra",
    "abstract": "Payment channel networks (e.g., the Lightning Network in Bitcoin) constitute one of the most popular scalability solutions for blockchains. Their safety relies on parties being online to detect fraud attempts on-chain and being able to timely react by publishing certain transactions on-chain. However, a cheating party may bribe miners in order to censor those transactions, resulting in loss of funds for the cheated party: these attacks are known in the literature as timelock bribing attacks. In this work, we present the first channel construction that does not require parties to be online and, at the same time, is resistant to timelock bribing attacks.We start by proving for the first time that Lightning channels are secure against timelock bribing attacks in the presence of rational channel parties under the assumption that these parties constantly monitor the mempool and never deplete the channel in one direction. The latter underscores the importance of keeping a coin reserve in each channel as implemented in the Lightning Network, albeit for different reasons. We show, however, that the security of the Lightning Network against Byzantine channel parties does not carry over to a setting in which miners are rational and accept timelock bribes.Next, we introduce CRAB, the first Lightning-compatible channel construction that provides security against Byzantine channel parties and rational miners. CRAB leverages miners' incentives to safeguard the channel, thereby also forgoing the unrealistic assumption of channel parties constantly monitoring the mempool.Finally, we show how our construction can be refined to eliminate the major assumption behind payment channels, i.e., the need for online participation. To that end, we present Sleepy CRAB the first provably secure channel construction under rational miners that enables participants to go offline indefinitely. We also provide a proof-of-concept implementation of Sleepy CRAB and evaluate its cost in Bitcoin, thereby demonstrating its practicality.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670373",
    "comment": ""
  },
  {
    "title": "Interactive Multi-Credential Authentication",
    "author": "Maram, Deepak and Kelkar, Mahimna and Eyal, Ittay",
    "abstract": "Authentication is the first, crucial step in securing digital assets like cryptocurrencies and online services like banking. It relies on principals maintaining exclusive access to credentials like cryptographic signing keys, passwords, and physical devices. But both individuals and organizations struggle to manage their credentials, resulting in loss of assets and identity theft.In this work, we study mechanisms with back-and-forth interaction with the principals. For example, a user receives an email notification about sending money from her bank account and is given a period of time to abort.We define the authentication problem, where a mechanism interacts with a user and an attacker. A mechanism's success depends on the scenario, namely, which credentials each principal knows. The profile of a mechanism is the set of scenarios in which it succeeds. The subset relation on profiles defines a partial order on mechanisms. We bound the profile size and discover three types of novel mechanisms that are maximally secure.We show the efficacy of our model by analyzing existing mechanisms and make concrete improvement proposals: Using sticky messages for security notifications, prioritizing credentials when accessing one's bank account, and using one of our maximal mechanisms to improve a popular cryptocurrency wallet. We demonstrate the practicality of our mechanisms by implementing the latter.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670378",
    "comment": ""
  },
  {
    "title": "Towards Fine-Grained Webpage Fingerprinting at Scale",
    "author": "Zhao, Xiyuan and Deng, Xinhao and Li, Qi and Liu, Yunpeng and Liu, Zhuotao and Sun, Kun and Xu, Ke",
    "abstract": "Website Fingerprinting (WF) attacks can effectively identify the websites visited by Tor clients via analyzing encrypted traffic patterns. Existing attacks focus on identifying different websites, but their accuracy dramatically decreases when applied to identify fine-grained webpages, especially when distinguishing among different subpages of the same website. WebPage Fingerprinting (WPF) attacks face the challenges of highly similar traffic patterns and a much larger scale of webpages. Furthermore, clients often visit multiple webpages concurrently, increasing the difficulty of extracting the traffic patterns of each webpage from the obfuscated traffic. In this paper, we propose Oscar, a WPF attack based on multi-label metric learning that identifies different webpages from obfuscated traffic by transforming the feature space. Oscar can extract the subtle differences among various webpages, even those with similar traffic patterns. In particular, Oscar combines proxy-based and sample-based metric learning losses to extract webpage features from obfuscated traffic and identify multiple webpages. We prototype Oscar and evaluate its performance using traffic collected from 1,000 monitored webpages and over 9,000 unmonitored webpages in the real world. Oscar demonstrates an 88.6\\% improvement in the multi-label metric Recall@5 compared to the state-of-the-art attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690211",
    "comment": ""
  },
  {
    "title": "Understanding Routing-Induced Censorship Changes Globally",
    "author": "Bhaskar, Abhishek and Pearce, Paul",
    "abstract": "Internet censorship is pervasive, with significant effort dedicated to understanding what is censored, and where. Prior censorship measurements however have identified significant inconsistencies in their results; experiments show unexplained non-deterministic behaviors thought to be caused by censor load, end-host geographic diversity, or incomplete censorship—inconsistencies which impede reliable, repeatable and correct understanding of global censorship. In this work we investigate the extent to which Equal-cost Multi-path (ECMP) routing is the cause for these inconsistencies, developing methods to measure and compensate for them.We find ECMP routing significantly changes observed censorship across protocols, censor mechanisms, and in 17 countries. We identify that previously observed non-determinism or regional variations are attributable to measurements between fixed end-hosts taking different routes based on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source port changes observed censorship. By developing new route-stable censorship measurement methods that allow consistent measurement of DNS, HTTP, and HTTPS censorship, we find ECMP routing yields censorship changes across 42\\% of IPs and 51\\% of ASes, but that impact is not uniform. We also develop an application-level traceroute tool to construct network paths using specific censored packets, thus identifying numerous causes of differences, ranging from likely failed infrastructure, to routes to the same end-host taking geographically diverse paths which experience differences in censorship en-route. Finally, we examine our results in the context of prior global measurement studies, exploring the applicability of our findings to prior observed variations, and then demonstrating how specific experiments from two studies could be impacted by, and specific results are explainable by, ECMP routing. Our work points to methods for improving future studies, reducing inconsistencies and increasing repeatability.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670336",
    "comment": ""
  },
  {
    "title": "Internet's Invisible Enemy: Detecting and Measuring Web Cache Poisoning in the Wild",
    "author": "Liang, Yuejia and Chen, Jianjun and Guo, Run and Shen, Kaiwen and Jiang, Hui and Hou, Man and Yu, Yue and Duan, Haixin",
    "abstract": "Web cache poisoning (WCP) has posed significant threats to Internet security by causing the cache server to deliver malicious responses to innocent users. This results in widespread denial of access to website resources and potential injection of harmful payloads. However, prior works on WCP vulnerability have been fragmented and conducted in a case-by-case form, lacking a systematic analysis of the threat landscape. In this paper, we fill this research gap by conducting a systematic evaluation of WCP vulnerabilities at scale. We propose HCache, a novel testing methodology to facilitates the widespread identification of WCP vulnerabilities. We evaluated our methodology against Tranco Top 1000 domains and their subdomains, and found that over 1,000 websites across 172 domains, representing 17\\% of the evaluated domains, are vulnerable to WCP. In particular, we have identified 7 new attack vectors stemming from previously unexplored caching headers. We have responsibly disclosed the vulnerabilities to the affected websites and received acknowledgements and bug bounties from world-famous companies, such as Alibaba, Adobe, Huawei, and Microsoft.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690361",
    "comment": ""
  },
  {
    "title": "Inbox Invasion: Exploiting MIME Ambiguities to Evade Email Attachment Detectors",
    "author": "Zhang, Jiahe and Chen, Jianjun and Wang, Qi and Zhang, Hangyu and Wang, Chuhan and Zhuge, Jianwei and Duan, Haixin",
    "abstract": "Email attachments have become a favored delivery vector for malware campaigns. In response, email attachment detectors are widely deployed to safeguard email security. However, an emerging threat arises when adversaries exploit parsing discrepancies between email detectors and clients to evade detection. Currently, uncovering these vulnerabilities still depends on manual, ad hoc methods. In this paper, we perform the first systematic evaluation of email attachment detection against parsing ambiguity vulnerabilities. We propose a novel testing methodology, MIMEminer, to systematically discover evasion vulnerabilities in email systems. We evaluated our methodology against 16 content detectors of popular email services like Gmail and iCloud, and 7 popular email clients like Outlook and Thunderbird. In total, we discovered 19 new evasion methods affecting all tested email services and clients. We further analyzed these vulnerabilities and identified three primary categories of malware evasions. We have responsibly reported those identified vulnerabilities to the affected providers to help with the remediation of such vulnerabilities and received acknowledgments from Google Gmail, Apple iCloud, Coremail, Tencent, Amavis and Perl MIME-tools.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670386",
    "comment": ""
  },
  {
    "title": "Toward Understanding the Security of Plugins in Continuous Integration Services",
    "author": "Li, Xiaofan and Gu, Yacong and Qiao, Chu and Zhang, Zhenkai and Liu, Daiping and Ying, Lingyun and Duan, Haixin and Gao, Xing",
    "abstract": "Mainstream Continuous Integration (CI) platforms have provided the plugin functionality to accelerate the development of CI pipelines. Unfortunately, CI plugins, which are essentially reusable code snippets, also expose new attack surfaces as plugins might be developed by less trusted users. In this paper, we present an in-depth study to understand potential security risks in existing CI plugins. We conduct a comprehensive analysis of plugin implementations on four mainstream CI platforms (GitHub Actions, GitLab CI, CircleCI, and Azure Pipelines), and investigate several weak links in existing plugin distributions and isolation mechanisms. We investigate seven attack vectors that can enable attackers to hijack plugins and distribute malicious code without plugins users being aware, and further exploit hijacked plugins to manipulate the workflow execution. Additionally, we find that plugin dependency (a plugin references other plugins) might further amplify the attack impact of our disclosed attacks. To evaluate the potential impact, we conduct a large-scale measurement on GitHub and GitLab, covering a total of 1,328,912 repositories using the aforementioned CI platforms. Our measurement results show that a large number of repositories and existing plugins, including many widely used ones, are potentially vulnerable to the proposed attacks. We have duly reported the identified vulnerabilities and received positive responses.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670366",
    "comment": ""
  },
  {
    "title": "The Harder You Try, The Harder You Fail: The KeyTrap Denial-of-Service Algorithmic Complexity Attacks on DNSSEC",
    "author": "Heftrig, Elias and Schulmann, Haya and Vogel, Niklas and Waidner, Michael",
    "abstract": "Availability is a major concern in the design of DNSSEC. To ensure availability, DNSSEC follows Postel's Law [RFC1123]: \"Be liberal in what you accept, and conservative in what you send.\" Hence, nameservers should send not just one matching key for a record set, but all the relevant cryptographic material, e.g., all the keys for all the ciphers that they support and all the corresponding signatures. This ensures that validation succeeds, and hence availability, even if some of the DNSSEC keys are misconfigured, incorrect or correspond to unsupported ciphers.We show that this design of DNSSEC is flawed. Exploiting vulnerable recommendations in the DNSSEC standards, we develop a new class of DNSSEC-based algorithmic complexity attacks on DNS, we dub KeyTrap attacks. All popular DNS implementations and services are vulnerable. With just a single DNS packet, the KeyTrap attacks lead to a 2.000.000x spike in CPU instruction count in vulnerable DNS resolvers, stalling some for as long as 16 hours. This devastating effect prompted major DNS vendors to refer to KeyTrap as \"the worst attack on DNS ever discovered\". Exploiting KeyTrap, an attacker could effectively disable Internet access in any system utilizing a DNSSEC-validating resolver.We disclosed KeyTrap to vendors and operators on November 2, 2023, confidentially reporting the vulnerabilities to a closed group of DNS experts, operators and developers from the industry. Since then we have been working with all major vendors to mitigate KeyTrap, repeatedly discovering and assisting in closing weaknesses in proposed patches. Following our disclosure, the industry-wide umbrella CVE-2023-50387 has been assigned, covering the DNSSEC protocol vulnerabilities we present in this work.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670389",
    "comment": ""
  },
  {
    "title": "FuzzCache: Optimizing Web Application Fuzzing Through Software-Based Data Cache",
    "author": "Li, Penghui and Zhang, Mingxue",
    "abstract": "Fuzzing has shown great promise in detecting vulnerabilities in server-side web applications. In this work, we introduce an innovative software-based data cache mechanism that complements and improves all existing web application fuzzing tools. Our key observation is that a great proportion of execution time (e.g., 50\\%) of web applications is spent on fetching data from two major sources: database and network; our in-depth investigation reveals that the same data is often repeatedly fetched across fuzzing trials. We thus design a new solution, FuzzCache, that stores the data into software-based caches, mitigating the need for repeated and expensive data fetches. FuzzCache exposes the cached data across fuzzing trials through inter-process shared memory segments. It also, as the first work, incorporates just-in-time compilation to avoid the performance overhead associated with interpreting PHP code in real time, thereby enhancing execution efficiency.We demonstrate that FuzzCache significantly enhances web application fuzzing performance. In our experiments, we integrated FuzzCache with both a black-box fuzzer (Black-Widow) and a grey-box fuzzer (WebFuzz). The results illustrate that FuzzCache accelerates both black-box and grey-box fuzzing, achieving a throughput increase of 3x to 4x. FuzzCache substantially improves code coverage by an average of 25\\%. Consequently, FuzzCache enables faster vulnerability detection, leading to the discovery of a greater number of vulnerabilities.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670278",
    "comment": ""
  },
  {
    "title": "MiniCAT: Understanding and Detecting Cross-Page Request Forgery Vulnerabilities in Mini-Programs",
    "author": "Zhang, Zidong and Hou, Qinsheng and Ying, Lingyun and Diao, Wenrui and Gu, Yacong and Li, Rui and Guo, Shanqing and Duan, Haixin",
    "abstract": "Mini-programs are lightweight apps running in super apps (such as WeChat, Baidu, Alipay, and TikTok), an emerging paradigm in the era of mobile computing. With the growing popularity of mini-programs, there is an increasing concern for their security and privacy. In essence, mini-programs are WebView-based apps. This means that they may be vulnerable to the same security risks associated with web apps. In this work, we discovered a new mini-program vulnerability called MiniCPRF (Cross-Page Request Forgery in Mini-Programs). The exploit of this vulnerability is easy, and the attack consequences are severe, leading to unauthorized operations, such as free shopping, and the exposure of confidential information, such as credit card numbers. The root causes of MiniCPRF can be attributed to multiple design flaws in both mini-programs and their super apps, including the insecure routing mechanism, lack of message integrity check, and plain-text storage. To evaluate the impacts of MiniCPRF, we designed an automated analysis framework called MiniCAT. It can automatically crawl mini-programs, perform static analysis on them, and generate detection reports. In large-scale real-world evaluations with MiniCAT, we identified that 32.0\\% (13,349/41,726) of analyzable mini-programs are potentially vulnerable to MiniCPRF, including some famous ones with millions of users, such as Sohu and Wenjuanxing. Following the responsible disclosure principle, we have reported verified vulnerable mini-programs to the corresponding vendors and developers, and three real-world cases have been confirmed by CNVD. Additionally, we suggest mitigation strategies to resolve the security issue related to MiniCPRF.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670294",
    "comment": ""
  },
  {
    "title": "SWIDE: A Semantic-aware Detection Engine for Successful Web Injection Attacks",
    "author": "Yang, Ronghai and Wang, Xianbo and Luo, Kaixuan and Lei, Xin and Li, Ke and Xin, Jiayuan and Lau, Wing Cheong",
    "abstract": "Web attacks, a primary vector for system breaches, pose a significant challenge within the cybersecurity landscape. The growing intensity of web attack attempts has led to \"alert fatigue\" where enterprises are inundated by excessive alerts. Although extensive research is being conducted on automated methods for detecting web attacks, it remains an open problem to identify whether the attacks are successful. Towards this end, we present SWIDE (Successful Web Injection Detection Engine), an engine to pinpoint successful web injection attacks (e.g., PHP command injection, SQL injection). This enables enterprises to focus exclusively on those crucial threats. Our methodology builds on two insights: Firstly, while attackers tend to apply payload obfuscation techniques to evade detection, all successful web injection attacks must comply with the programming language syntax to be executable; Secondly, these attacks inevitably produce observable effects, such as returning execution result or creating backdoors for future access by the attacker. Consequently, we leverage advanced syntactic and semantic analysis to 1) detect malicious syntax features in obfuscated payloads and 2) perform semantic analysis of the payload to recover the intention of the attack. With a two-stage design, namely, attack identification and confirmation mechanisms, SWIDE can accurately identify successful attacks, even amidst intricate obfuscations. Unlike proof-of-concept studies, SWIDE has been deployed and validated in real-world environments through collaborations with a cybersecurity firm. Serving 5,045 enterprise users, our system identifies that roughly 15\\% of enterprises have suffered from successful attacks on a weekly basis - an alarmingly high rate. Moreover, we perform a detailed analysis of six months' data and discover 60 zero-day vulnerabilities exploited in the wild, including 12 high-risk ones acknowledged by relevant authorities. These findings underscore the practical effectiveness of SWIDE.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670304",
    "comment": ""
  },
  {
    "title": "Stealing Trust: Unraveling Blind Message Attacks in Web3 Authentication",
    "author": "Yan, Kailun and Zhang, Xiaokuan and Diao, Wenrui",
    "abstract": "As the field of Web3 continues its rapid expansion, the security of Web3 authentication, often the gateway to various Web3 applications, becomes increasingly crucial. Despite its widespread use as a login method by numerous Web3 applications, the security risks of Web3 authentication have not received much attention. This paper investigates the vulnerabilities in the Web3 authentication process and proposes a new type of attack, dubbed blind message attacks. In blind message attacks, attackers trick users into blindly signing messages from target applications by exploiting users' inability to verify the source of messages, thereby achieving unauthorized access to the target application. We have developed Web3AuthChecker, a dynamic detection tool that interacts with Web3 authentication-related APIs to identify vulnerabilities. Our evaluation of real-world Web3 applications shows that a staggering 75.8\\% (22/29) of Web3 authentication deployments are at risk of blind message attacks. In response to this alarming situation, we implemented Web3AuthGuard on the open-source wallet MetaMask to alert users of potential attacks. Our evaluation results show that Web3AuthGuard can successfully raise alerts in 80\\% of the tested Web3 authentications. We have responsibly reported our findings to vulnerable websites and have been assigned two CVE IDs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670323",
    "comment": ""
  },
  {
    "title": "Test Suites Guided Vulnerability Validation for Node.js Applications",
    "author": "Luo, Changhua and Li, Penghui and Meng, Wei and Zhang, Chao",
    "abstract": "Dynamic methods have shown great promise in validating vulnerabilities and generating Proof-of-Concept (PoC) exploits of Node.js applications. They typically rely on dictionaries or specifications to determine the values of request parameters and their relationships. However, they still struggle to generate complex inputs from the provided dictionaries or specifications.This work introduces a novel approach that utilizes existing test suites to automatically generate end-to-end application inputs for vulnerability validation. Our key observation is that Node.js applications often provide comprehensive test suites - in our study, the unit testing code can cover an average of 85\\% of application code - which can hardly be achieved by existing dynamic methods. We thus design a new system, JSGo, that leverages test suites to construct end-to-end test inputs. Since test suites directly invoke application code instead of issuing requests from client-accessible entry points, we cannot simply transform test suites into application inputs. We instead propose a novel trace-guided mutation mechanism based on concolic execution.Our evaluation demonstrates that JSGo could reproduce 20 out of 26 known vulnerabilities, which significantly outperformed the state-of-the-art methods Restler, Miner, Witcher, and Burp by 10, 12, 11, 10 more cases, respectively. We also applied JSGo to validate static analysis results in popular Node.js applications such as hexo. It successfully validated seven vulnerabilities, two of which have been patched because of our reports.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690332",
    "comment": ""
  },
  {
    "title": "ReactAppScan: Mining React Application Vulnerabilities via Component Graph",
    "author": "Guo, Zhiyong and Kang, Mingqing and Venkatakrishnan, V.N. and Gjomemo, Rigel and Cao, Yinzhi",
    "abstract": "React, a single-page application framework, has recently become popular among web developers due to its flexible and convenient management of web application states via a syntax extension to JavaScript, called JSX (JavaScript and XML). Despite its abundant functionalities, the security of React, especially vulnerability detection, still lags: many existing vulnerability detection works do not support JSX let alone React Data Flow introduced by React components. The only exception is CodeQL, which supports JSX syntax. However, CodeQL cannot properly track React Data Flow across different components for detecting vulnerabilities.In this paper, we design a novel framework, called ReactAppScan, which constructs a Component Graph (CoG) for tracking React Data Flow and detecting vulnerabilities following both JavaScript and React data flows. Specifically, ReactAppScan relies on abstract interpretation to build such a component graph via tracking component lifecycles and then detects vulnerabilities via finding paths between sources and sinks. Our evaluation shows that ReactAppScan detects 61 zero-day vulnerabilities in real-world React applications. We have responsibly reported all the vulnerabilities and so far six vulnerabilities have been fixed and two have been acknowledged.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670331",
    "comment": ""
  },
  {
    "title": "Certifiable Black-Box Attacks with Randomized Adversarial Examples: Breaking Defenses with Provable Confidence",
    "author": "Hong, Hanbin and Zhang, Xinyu and Wang, Binghui and Ba, Zhongjie and Hong, Yuan",
    "abstract": "Black-box adversarial attacks have demonstrated strong potential to compromise machine learning models by iteratively querying the target model or leveraging transferability from a local surrogate model.Recently, such attacks can be effectively mitigated by state-of-the-art (SOTA) defenses, e.g., detection via the pattern of sequential queries, or injecting noise into the model. To our best knowledge, we take the first step to study a new paradigm of black-box attacks with provable guarantees -- certifiable black-box attacks that can guarantee the attack success probability (ASP) of adversarial examples before querying over the target model. This new black-box attack unveils significant vulnerabilities of machine learning models, compared to traditional empirical black-box attacks, e.g., breaking strong SOTA defenses with provable confidence, constructing a space of (infinite) adversarial examples with high ASP, and the ASP of the generated adversarial examples is theoretically guaranteed without verification/queries over the target model. Specifically, we establish a novel theoretical foundation for ensuring the ASP of the black-box attack with randomized adversarial examples (AEs). Then, we propose several novel techniques to craft the randomized AEs while reducing the perturbation size for better imperceptibility. Finally, we have comprehensively evaluated the certifiable black-box attacks on the CIFAR10/100, ImageNet, and LibriSpeech datasets, while benchmarking with 16 SOTA black-box attacks, against various SOTA defenses in the domains of computer vision and speech recognition. Both theoretical and experimental results have validated the significance of the proposed attack.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690343",
    "comment": ""
  },
  {
    "title": "Phantom: Untargeted Poisoning Attacks on Semi-Supervised Learning",
    "author": "Knauer, Jonathan and Rieger, Phillip and Fereidooni, Hossein and Sadeghi, Ahmad-Reza",
    "abstract": "Deep Neural Networks (DNNs) can handle increasingly complex tasks, albeit they require rapidly expanding training datasets. Collecting data from platforms with user-generated content, such as social networks, has significantly eased the acquisition of large datasets for training DNNs. Despite these advancements, the manual labeling process remains a substantial challenge in terms of both time and cost. In response, Semi-Supervised Learning (SSL) approaches have emerged, where only a small fraction of the dataset needs to be labeled, leaving the majority unlabeled. However, leveraging data from untrusted sources like social networks also creates new security risks, as potential attackers can easily inject manipulated samples. Previous research on the security of SSL primarily focused on injecting backdoors into trained models, while less attention was given to the more challenging untargeted poisoning attacks. In this paper, we introduce Phantom, the first untargeted poisoning attack in SSL that disrupts the training process by injecting a small number of manipulated images into the unlabeled dataset. Unlike existing attacks, our approach only requires adding few manipulated samples, such as posting images on social networks, without the need to control the victim. Phantom causes SSL algorithms to overlook the actual images' pixels and to rely only on maliciously crafted patterns that Phantom superimposed on the real images. We show Phantom's effectiveness for 6 different datasets and 3 real-world social-media platforms (Facebook, Instagram, Pinterest). Already small fractions of manipulated samples (e.g., 5\\%) reduce the accuracy of the resulting model by 10\\%, with higher percentages leading to a performance comparable to a naive classifier. Our findings demonstrate the threat of poisoning user-generated content platforms, rendering them unsuitable for SSL in specific tasks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690369",
    "comment": ""
  },
  {
    "title": "Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems",
    "author": "Fang, Zheng and Wang, Tao and Zhao, Lingchen and Zhang, Shenyi and Li, Bowen and Ge, Yunjie and Li, Qi and Shen, Chao and Wang, Qian",
    "abstract": "In recent years, extensive research has been conducted on the vulnerability of ASR systems, revealing that black-box adversarial example attacks pose significant threats to real-world ASR systems. However, most existing black-box attacks rely on queries to the target ASRs, which is impractical when queries are not permitted. In this paper, we propose ZQ-Attack, a transfer-based adversarial attack on ASR systems in the zero-query black-box setting. Through a comprehensive review and categorization of modern ASR technologies, we first meticulously select surrogate ASRs of diverse types to generate adversarial examples. Following this, ZQ-Attack initializes the adversarial perturbation with a scaled target command audio, rendering it relatively imperceptible while maintaining effectiveness. Subsequently, to achieve high transferability of adversarial perturbations, we propose a sequential ensemble optimization algorithm, which iteratively optimizes the adversarial perturbation on each surrogate model, leveraging collaborative information from other models. We conduct extensive experiments to evaluate ZQ-Attack. In the over-the-line setting, ZQ-Attack achieves a 100\\% success rate of attack (SRoA) with an average signal-to-noise ratio (SNR) of 21.91dB on 4 online speech recognition services, and attains an average SRoA of 100\\% and SNR of 19.67dB on 16 open-source ASRs. In the over-the-air setting, ZQ-Attack also achieves a 100\\% SRoA with an average SNR of 15.77dB on 2 commercial intelligent voice control devices.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670309",
    "comment": ""
  },
  {
    "title": "SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems",
    "author": "Ma, Oubo and Pu, Yuwen and Du, Linkang and Dai, Yang and Wang, Ruo and Liu, Xiaolei and Wu, Yingcai and Ji, Shouling",
    "abstract": "Recent advancements in multi-agent reinforcement learning (MARL) have opened up vast application prospects, such as swarm control of drones, collaborative manipulation by robotic arms, and multi-target encirclement. However, potential security threats during the MARL deployment need more attention and thorough investigation. Recent research reveals that attackers can rapidly exploit the victim's vulnerabilities, generating adversarial policies that result in the failure of specific tasks. For instance, reducing the winning rate of a superhuman-level Go AI to around 20\\%. Existing studies predominantly focus on two-player competitive environments, assuming attackers possess complete global state observation.In this study, we unveil, for the first time, the capability of attackers to generate adversarial policies even when restricted to partial observations of the victims in multi-agent competitive environments. Specifically, we propose a novel black-box attack (SUB-PLAY) that incorporates the concept of constructing multiple subgames to mitigate the impact of partial observability and suggests sharing transitions among subpolicies to improve attackers' exploitative ability. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under three typical partial observability limitations. Visualization results indicate that adversarial policies induce significantly different activations of the victims' policy networks. Furthermore, we evaluate three potential defenses aimed at exploring ways to mitigate security threats posed by adversarial policies, providing constructive recommendations for deploying MARL in competitive environments.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670293",
    "comment": ""
  },
  {
    "title": "Optimization-based Prompt Injection Attack to LLM-as-a-Judge",
    "author": "Shi, Jiawen and Yuan, Zenghui and Liu, Yinuo and Huang, Yue and Zhou, Pan and Sun, Lichao and Gong, Neil Zhenqiang",
    "abstract": "LLM-as-a-Judge uses a large language model (LLM) to select the best response from a set of candidates for a given question. LLM-as-a-Judge has many applications such as LLM-powered search, reinforcement learning with AI feedback (RLAIF), and tool selection. In this work, we propose JudgeDeceiver, an optimization-based prompt injection attack to LLM-as-a-Judge. JudgeDeceiver injects a carefully crafted sequence into an attacker-controlled candidate response such that LLM-as-a-Judge selects the candidate response for an attacker-chosen question no matter what other candidate responses are. Specifically, we formulate finding such sequence as an optimization problem and propose a gradient based method to approximately solve it. Our extensive evaluation shows that JudgeDeceive is highly effective, and is much more effective than existing prompt injection attacks that manually craft the injected sequences and jailbreak attacks when extended to our problem. We also show the effectiveness of JudgeDeceiver in three case studies, i.e., LLM-powered search, RLAIF, and tool selection. Moreover, we consider defenses including known-answer detection, perplexity detection, and perplexity windowed detection. Our results show these defenses are insufficient, highlighting the urgent need for developing new defense strategies.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690291",
    "comment": ""
  },
  {
    "title": "Neural Dehydration: Effective Erasure of Black-box Watermarks from DNNs with Limited Data",
    "author": "Lu, Yifan and Li, Wenxuan and Zhang, Mi and Pan, Xudong and Yang, Min",
    "abstract": "To protect the intellectual property of well-trained deep neural networks (DNNs), black-box watermarks, which are embedded into the prediction behavior of DNN models on a set of specially-crafted samples and extracted from suspect models using only API access, have gained increasing popularity in both academy and industry. Watermark robustness is usually implemented against attackers who steal the protected model and obfuscate its parameters for watermark removal. However, current robustness evaluations are primarily performed under moderate attacks or unrealistic settings. Existing removal attacks could only crack a small subset of the mainstream black-box watermarks, and fall short in four key aspects: incomplete removal, reliance on prior knowledge of the watermark, performance degradation, and high dependency on data.In this paper, we propose a watermark-agnostic removal attack called Neural Dehydration (abbrev. Dehydra), which effectively erases all ten mainstream black-box watermarks from DNNs, with only limited or even no data dependence. In general, our attack pipeline exploits the internals of the protected model to recover and unlearn the watermark message. We further design target class detection and recovered sample splitting algorithms to reduce the utility loss and achieve data-free watermark removal on five of the watermarking schemes. We conduct comprehensive evaluation of Dehydra against ten mainstream black-box watermarks on three benchmark datasets and DNN architectures. Compared with existing removal attacks, Dehydra achieves strong removal effectiveness across all the covered watermarks, preserving at least 90\\% of the stolen model utility, under the data-limited settings, i.e., less than 2\\% of the training data or even data-free. Our work reveals the vulnerabilities of existing black-box DNN watermarks in realistic settings, highlighting the urgent need for more robust watermarking techniques. To facilitate future studies, we open-source our code in the following repository: https://github.com/LouisVann/Dehydra.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690334",
    "comment": ""
  },
  {
    "title": "DarthShader: Fuzzing WebGPU Shader Translators \\& Compilers",
    "author": "Bernhard, Lukas and Schiller, Nico and Schloegel, Moritz and Bars, Nils and Holz, Thorsten",
    "abstract": "A recent trend towards running more demanding web applications, such as video games or client-side LLMs, in the browser has led to the adoption of the WebGPU standard that provides a cross-platform API exposing the GPU to websites. This opens up a new attack surface: Untrusted web content is passed through to the GPU stack, which traditionally has been optimized for performance instead of security. Worsening the problem, most of WebGPU cannot be run in the tightly sandboxed process that manages other web content, which eases the attacker's path to compromising the client machine. Contrasting its importance, WebGPU shader processing has received surprisingly little attention from the automated testing community. Part of the reason is that shader translators expect highly structured and statically typed input, which renders typical fuzzing mutations ineffective. Complicating testing further, shader translation consists of a complex multi-step compilation pipeline, each stage presenting unique requirements and challenges.In this paper, we propose DarthShader, the first language fuzzer that combines mutators based on an intermediate representation with those using a more traditional abstract syntax tree. The key idea is that the individual stages of the shader compilation pipeline are susceptible to different classes of faults, requiring entirely different mutation strategies for thorough testing. By fuzzing the full pipeline, we ensure that we maintain a realistic attacker model. In an empirical evaluation, we show that our method outperforms the state-of-the-art fuzzers regarding code coverage. Furthermore, an extensive ablation study validates our key design. DarthShader found a total of 39 software faults in all modern browsers Chrome, Firefox, and Safari that prior work missed. For 15 of them, the Chrome team assigned a CVE, acknowledging the impact of our results.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690209",
    "comment": ""
  },
  {
    "title": "OSmart: Whitebox Program Option Fuzzing",
    "author": "Wang, Kelin and Chen, Mengda and He, Liang and Su, Purui and Cai, Yan and Chen, Jiongyi and Zhang, Bin and Feng, Chao and Tang, Chaojing",
    "abstract": "Program options are ubiquitous and serve as a fundamental mechanism for configuring and customizing software behaviors. Given their widespread use, testing program options becomes essential to ensure that the software behaves as expected across various configurations. Existing option-aware fuzzers either mutate options as if they were standard program inputs or employ NLP techniques to deduce relationships among options from the documentation. However, there has not been a whitebox approach that generates option combinations by capturing the inherent execution logic of the program.This paper presents Osmart, a whitebox approach designed to systematically extract program options and effective option combinations that precisely encapsulate the intrinsic execution logic of the program, incorporating both data dependency and control dependency.OSmart successfully inferred 12,560 option combinations from 56 programs. Additionally, OSmart uncovered that more than 67\\% of evaluated programs have undocumented options. By integrated with AFL++, OSmart discovered 40.3\\% more paths, which led to the detection of 51 new bugs and the assignment of 18 CVE IDs. Finally, we also compared OSmart with four state-of-the-art option-aware fuzzers on a public benchmark and our tool achieved higher line coverage in 66.7\\% (20/30) of the evaluated programs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690228",
    "comment": ""
  },
  {
    "title": "Program Environment Fuzzing",
    "author": "Meng, Ruijie and Duck, Gregory J. and Roychoudhury, Abhik",
    "abstract": "Computer programs are not executed in isolation, but rather interact with the execution environment which drives the program behaviors. Software validation methods thus need to capture the effect of possibly complex environmental interactions. Program environments may come from files, databases, configurations, network sockets, human-user interactions, and more. Conventional approaches for environment capture in symbolic execution and model checking employ environment modeling, which involves manual effort. In this paper, we take a different approach based on an extension of greybox fuzzing. Given a program, we first record all observed environmental interactions at the kernel/user-mode boundary in the form of system calls. Next, we replay the program under the original recorded interactions, but this time with selective mutations applied, in order to get the effect of different program environments---all without environment modeling. Via repeated (feedback-driven) mutations over a fuzzing campaign, we can search for program environments that induce crashing behaviors. Our EnvFuzz tool found 33 previously unknown bugs in well-known real-world protocol implementations and GUI applications. Many of these are security vulnerabilities and 16 CVEs were assigned.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690229",
    "comment": ""
  },
  {
    "title": "ProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations with Only Documentation via Large Language Model",
    "author": "Wang, Dawei and Zhou, Geng and Chen, Li and Li, Dan and Miao, Yukai",
    "abstract": "Vulnerabilities related to option combinations pose a significant challenge in software security testing due to their vast search space. Previous research primarily addressed this challenge through mutation or filtering techniques, which inefficiently treated all option combinations as having equal potential for vulnerabilities, thus wasting considerable time on non-vulnerable targets and resulting in low testing efficiency. In this paper, we utilize carefully designed prompt engineering to drive the large language model (LLM) to predict high-risk option combinations (i.e., more likely to contain vulnerabilities) and perform fuzz testing automatically without human intervention. We developed a tool called ProphetFuzz and evaluated it on a dataset comprising 52 programs collected from three related studies. The entire experiment consumed 10.44 CPU years. ProphetFuzz successfully predicted 1748 high-risk option combinations at an average cost of only 8.69 per program. Results show that after 72 hours of fuzzing, ProphetFuzz discovered 364 unique vulnerabilities associated with 12.30\\% of the predicted high-risk option combinations, which was 32.85\\% higher than that found by state-of-the-art in the same timeframe. Additionally, using ProphetFuzz, we conducted persistent fuzzing on the latest versions of these programs, uncovering 140 vulnerabilities, with 93 confirmed by developers and 21 awarded CVE numbers.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690231",
    "comment": ""
  },
  {
    "title": "No Peer, no Cry: Network Application Fuzzing via Fault Injection",
    "author": "Bars, Nils and Schloegel, Moritz and Schiller, Nico and Bernhard, Lukas and Holz, Thorsten",
    "abstract": "Network-facing applications are commonly exposed to all kinds of attacks, especially when connected to the internet. As a result, web servers like Nginx or client applications such as curl make every effort to secure and harden their code to rule out memory safety violations. One would expect this to include regular fuzz testing, as fuzzing has proven to be one of the most successful approaches to uncovering bugs in software. Yet, surprisingly little research has focused on fuzzing network applications. When studying the underlying reasons, we find that the interactive nature of communication, its statefulness, and the protection of exchanged messages (e.g., via encryption or cryptographic signatures) render typical fuzzers ineffective. Attempts to replay recorded messages or modify them on the fly only work for specific targets and often lead to early termination of communication.In this paper, we discuss these challenges in detail, highlighting how the focus of existing work on protocol state space promises little relief. We propose a fundamentally different approach that relies on fault injection rather than modifying messages. Effectively, we force one of the communication peers into a weird state where its output no longer matches the expectations of the target peer, potentially uncovering bugs. Importantly, this weird peer can still properly encrypt/sign the protocol message, overcoming a fundamental challenge of current fuzzers. In effect, we leave the communication system intact but introduce small corruptions. Since we can turn either the server or the client into the weird peer, our approach is the first that can effectively test client-side network applications. In an extensive evaluation of 16 targets, we show that our prototype Fuzztruction-Net significantly outperforms other fuzzers in terms of coverage and bugs found. Overall, Fuzztruction-Net uncovered 23 new bugs in well-tested software, such as the web servers Nginx and Apache HTTPd and the OpenSSH client.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690274",
    "comment": ""
  },
  {
    "title": "FOX: Coverage-guided Fuzzing as Online Stochastic Control",
    "author": "She, Dongdong and Storek, Adam and Xie, Yuchong and Kweon, Seoyoung and Srivastava, Prashast and Jana, Suman",
    "abstract": "Fuzzing is an effective technique for discovering software vulnerabilities by generating random test inputs and executing them against the target program. However, fuzzing large and complex programs remains challenging due to difficulties in uncovering deeply hidden vulnerabilities. This paper addresses the limitations of existing coverage-guided fuzzers, focusing on the scheduler and mutator components. Existing schedulers suffer from information sparsity and the inability to handle fine-grained feedback metrics. The mutators are agnostic of target program branches, leading to wasted computation and slower coverage exploration.To overcome these issues, we propose an end-to-end online stochastic control formulation for coverage-guided fuzzing. Our approach incorporates a novel scheduler and custom mutator that can adapt to branch logic, maximizing aggregate edge coverage achieved over multiple stages. The scheduler utilizes fine-grained branch distance measures to identify frontier branches, where new coverage is likely to be achieved. The mutator leverages branch distance information to perform efficient and targeted seed mutations, leading to robust progress with minimal overhead.We present FOX, a proof-of-concept implementation of our control-theoretic approach, and compare it to industry-standard coverage-guided fuzzers. 6 CPU-years of extensive evaluations on the FuzzBench dataset and complex real-world programs (a total of 38 test programs) demonstrate that FOX outperforms existing state-of-the-art fuzzers, achieving average coverage improvements up to 26.45\\% in real-world standalone programs and 6.59\\% in FuzzBench programs over the state-of-the-art AFL++. In addition, it uncovers 20 unique bugs in popular real-world applications, including eight that are previously unknown, showcasing real-world security impact.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670362",
    "comment": ""
  },
  {
    "title": "Leakage-Resilient Circuit Garbling",
    "author": "Li, Ruiyang and Sun, Yiteng and Guo, Chun and Standaert, Fran\\c{c}ois-Xavier and Wang, Weijia and Wang, Xiao",
    "abstract": "Due to the ubiquitous requirements and performance leap in the past decade, it has become feasible to execute garbling and secure computations in settings sensitive to side-channel attacks, including smartphones, IoTs and dedicated hardwares, and the possibilities have been demonstrated by recent works. To maintain security in the presence of a moderate amount of leaked information about internal secrets, we investigate leakage-resilient garbling. We augment the classical privacy, obliviousness and authenticity notions with leakages of the garbling function, and define their leakage-resilience analogues. We examine popular garbling schemes and unveil additional side-channel weaknesses due to wire label reuse and XOR leakages. We then incorporate the idea of label refreshing into the GLNP garbling scheme of Gueron et al. and propose a variant GLNPLR that provably satisfies our leakage-resilience definitions. Performance comparison indicates that GLNPLR is 60X (using AES-NI) or 5X (without AES-NI) faster than the HalfGates garbling with second order side-channel masking, for garbling AES circuit when the bandwidth is 2Gbps.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690204",
    "comment": ""
  },
  {
    "title": "Secure Multiparty Computation with Lazy Sharing",
    "author": "Li, Shuaishuai and Zhang, Cong and Lin, Dongdai",
    "abstract": "Secure multiparty computation (MPC) protocols enable n parties, each with private inputs, to compute a given function without leaking information beyond the outputs. One of the main approaches to designing efficient MPC protocols is to use secret sharing. In general, secret sharing based MPC contains three phases: input sharing, circuit evaluation, and output recovery. If the adversary corrupts at most t parties, the protocol typically uses (t,n) threshold secret sharing to share the inputs. In this work, we consider a weaker variant of threshold secret sharing called lazy threshold secret sharing (or simply lazy sharing) and show that: Lazy sharing can serve as a viable alternative to threshold secret sharing in MPC without compromising security. Lazy sharing could be generated more efficiently than threshold secret sharing.As a result, replacing threshold secret sharing with lazy sharing can lead to a more efficient input sharing phase. Moreover, we propose that the efficiency of the circuit evaluation phase can also be further improved. To support this claim, we apply lazy sharing to several state-of-the-art MPC protocols and analyze the efficiency gain in various settings. These protocols include the GMW protocol (Goldreich et al., STOC 1987), the AFLNO protocol (Araki et al., CCS 2016), and the SPDZ protocol (Damg\\r{a}rd et al., CRYPTO 2012). By doing so, we analyze the efficiency gains in various settings and highlight the advantages of incorporating lazy sharing into MPC protocols.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690207",
    "comment": ""
  },
  {
    "title": "Coral: Maliciously Secure Computation Framework for Packed and Mixed Circuits",
    "author": "Huang, Zhicong and Lu, Wen-jie and Wang, Yuchen and Hong, Cheng and Wei, Tao and Chen, WenGuang",
    "abstract": "Achieving malicious security with high efficiency in dishonest-majority secure multiparty computation is a formidable challenge. The milestone works SPDZ and TinyOT have spawn a large family of protocols in this direction. For boolean circuits, state-of-the-art works (Cascudo et. al, TCC 2020 and Escudero et. al, CRYPTO 2022) have proposed schemes based on reverse multiplication-friendly embedding (RMFE) to reduce the amortized cost. However, these protocols are theoretically described and analyzed, resulting in a significant gap between theory and concrete efficiency.Our work addresses existing gaps by refining and correcting several issues identified in prior research, leading to the first practically efficient realization of RMFE. We introduce an array of protocol enhancements, including RMFE-based quintuples and (extended) double-authenticated bits, aimed at improving the efficiency of maliciously secure boolean and mixed circuits. The culmination of these efforts is embodied in Coral, a comprehensive framework developed atop the MP-SPDZ library. Through rigorous evaluation across multiple benchmarks, Coral demonstrates a remarkable efficiency gain, outperforming the foremost theoretical approach by Escudero et al. (which incorporates our RMFE foundation albeit lacks our protocol enhancements) by a factor of 16-30\\texttimes{}, and surpassing the leading practical implementation for Frederiksen et al. (ASIACRYPT 2015) by 4-7\\texttimes{}.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690223",
    "comment": ""
  },
  {
    "title": "Sublinear Distributed Product Checks on Replicated Secret-Shared Data over Z2k Without Ring Extensions",
    "author": "Li, Yun and Escudero, Daniel and Duan, Yufei and Huang, Zhicong and Hong, Cheng and Zhang, Chao and Song, Yifan",
    "abstract": "Multiple works have designed or used maliciously secure honest majority MPC protocols over Z2k using replicated secret sharing (e.g. Koti et al. USENIX'21). A recent trend in the design of such MPC protocols is to first execute a semi-honest protocol, and then use a check that verifies the correctness of the computation requiring only sublinear amount of communication in terms of the circuit size. The so-called Galois ring extensions are needed in order to execute such checks over Z2k, but these rings incur incredibly high computation overheads, which completely undermine any potential benefits the ring Z2k had to begin with.In this work we revisit the task of designing sublinear distributed product checks on replicated secret-shared data over Z2k among three parties with an honest majority. We present a novel technique for verifying the correctness of a set of multiplication (in fact, inner product) triples, involving a sublinear cost in terms of the number of multiplications. Most importantly, unlike previous works, our tools do not rely on Galois ring extensions, which are computationally expensive, and only require computation over rings of the form Z2l. In terms of communication, our checks are 3 ~ 5x lighter than existing checks using ring extensions, which is already quite remarkable. However, our most noticeable improvement is in terms of computation: our checks are 17.7 ~ 44.2x better than previous approaches, for many parameter regimes of interest. Our experimental results show that checking a 10 million gate circuit with the 3PC protocol from Boyle et al. (CCS'19) takes about two minutes, while our approach takes only 2.82 seconds.Finally, our techniques are not restricted to the three-party case, and we generalize them to replicated secret-sharing with an arbitrary number of parties n. Even though the share size in this scheme grows exponentially with n, prior works have used it for n=4 or n=5 --- or even general n for feasibility results --- and our distributed checks also represent improvements in these contexts.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690260",
    "comment": ""
  },
  {
    "title": "Secret Sharing with Snitching",
    "author": "Dziembowski, Stefan and Faust, Sebastian and Lizurej, Tomasz and Mielniczuk, Marcin",
    "abstract": "We address the problem of detecting and punishing shareholder collusion in secret-sharing schemes. We do it in the recently proposed cryptographic model called individual cryptography (Dziembowski, Faust, and Lizurej, Crypto 2023), which assumes that there exist tasks that can be efficiently computed by a single machine but distributing this computation across multiple (mutually distrustful devices) is infeasible.  Within this model, we introduce a novel primitive called secret sharing with snitching (SSS), in which each attempt to illegally reconstruct the shared secret S results in a proof that can be used to prove such misbehavior (and, e.g., financially penalize the cheater on a blockchain). This holds in a very strong sense, even if the shareholders attempt not to reconstruct the entire secret~S but only learn some partial information about it. Our notion also captures the attacks performed using multiparty computation protocols (MPCs), i.e., those where the malicious shareholders use MPCs to compute partial information on S. The main idea of SSS is that any illegal reconstruction can be proven and punished, which suffices to discourage illegal secret reconstruction. Hence, our SSS scheme effectively prevents shareholders' collusion. We provide a basic definition of threshold (t-out-of-n) SSS. We then show how to construct it for t = n, and later, we use this construction to build an SSS scheme for an arbitrary t. In order to prove the security of our construction, we introduce a generalization of the random oracle model (Bellare, Rogaway, CCS 1993), which allows modelling hash evaluations made inside MPC.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690296",
    "comment": ""
  },
  {
    "title": "Shortcut: Making MPC-based Collaborative Analytics Efficient on Dynamic Databases",
    "author": "Zhou, Peizhao and Guo, Xiaojie and Chen, Pinzhi and Li, Tong and Lv, Siyi and Liu, Zheli",
    "abstract": "Secure Multi-party Computation (MPC) provides a promising solution for privacy-preserving multi-source data analytics. However, existing MPC-based collaborative analytics systems (MCASs) have unsatisfying performance for scenarios with dynamic databases. Naively running an MCAS on a dynamic database would lead to significant redundant costs and raise performance concerns, due to the substantial duplicate contents between the pre-updating and post-updating databases.In this paper, we propose Shortcut, a framework that can work with MCASs to enable efficient queries on dynamic databases that support data insertion, deletion, and update. The core idea of Shortcut is to materialize previous query results and directly update them via our query result update (QRU) protocol to obtain current query results. We customize several efficient QRU protocols for common SQL operators, including Order-by-Limit, Group-by-Aggregate, Distinct, Join, Select, and Global Aggregate. These protocols are composable to implement a wide range of query functions. In particular, we propose two constant-round protocols to support data insertion and deletion. These protocols can serve as important building blocks of other protocols and are of independent interest. They address the problem of securely inserting/deleting a row into/from an ordered table while keeping the order. Our experiments show that Shortcut outperforms naive MCASs for minor updates arriving in time, which captures the need of many realistic applications (e.g., insurance services, account data management). For example, for a single query after an insertion, Shortcut achieves up to 186.8x improvement over those naive MCASs without our QRU protocols on a dynamic database with 216 ~ 220 rows, which is common in real-life applications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690314",
    "comment": ""
  },
  {
    "title": "Dora: A Simple Approach to Zero-Knowledge for RAM Programs",
    "author": "Goel, Aarushi and Hall-Andersen, Mathias and Kaptchuk, Gabriel",
    "abstract": "Existing protocols for proving the correct execution of a RAM program in zero-knowledge are plagued by a processor expressiveness tradeoff: supporting fewer instructions results in smaller processor circuits (which improves performance), but may result in more program execution steps because non-supported instruction must be emulated over multiple processor steps (diminishing performance).We present Dora, a very simple and concretely efficient zero-knowledge protocol for RAM programs that sidesteps this tension by making it (nearly) free to add additional instructions to the processor. The computational and communication complexity of proving each step of a computation in Dora, is constant in the number of supported instructions. Dora's approach is united by intuitive abstraction we call a ZKBag, a cryptographic primitive constructed from linearly homomorphic commitments that captures the properties of a physical bag. We implement Dora and demonstrate that on commodity hardware it can prove the correct execution of a processor with thousands of instruction, each of which has thousands of gates, in just a few milliseconds per step.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690213",
    "comment": ""
  },
  {
    "title": "Dual Polynomial Commitment Schemes and Applications to Commit-and-Prove SNARKs",
    "author": "Ganesh, Chaya and Nair, Vineet and Sharma, Ashish",
    "abstract": "In this work, we introduce a primitive called a dual polynomial commitment scheme that allows linking together a witness committed to using a univariate polynomial commitment scheme with a witness inside a multilinear polynomial commitment scheme. This yields commit-and-prove (CP) SNARKs with the flexibility of going back and forth between univariate and multilinear encodings of witnesses. This is in contrast to existing CP frameworks that assume compatible polynomial commitment schemes between different components of the proof systems. In addition to application to CP, we also show that our notion yields a version of Spartan with better proof size and verification complexity, at the cost of a more expensive prover.We achieve this via a combination of the following technical contributions: (i) we construct a new univariate commitment scheme in the updatable SRS setting that has better prover complexity than KZG (ii) we construct a new multilinear commitment scheme in the updatable setting that is compatible for linking with our univariate scheme (iii) we construct an argument of knowledge to prove a given linear relationship between two witnesses committed using a two-tiered commitment scheme (Pedersen+AFG) using Dory as a black-box. These constructions are of independent interest.We implement our commitment schemes and report on performance. We also implement the version of Spartan with our dual polynomial commitment scheme and demonstrate that it outperforms Spartan in proof size and verification complexity.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690219",
    "comment": ""
  },
  {
    "title": "Direct Range Proofs for Paillier Cryptosystem and Their Applications",
    "author": "Xie, Zhikang and Liu, Mengling and Xue, Haiyang and Au, Man Ho and Deng, Robert H. and Yiu, Siu-Ming",
    "abstract": "The Paillier cryptosystem is renowned for its applications in electronic voting, threshold ECDSA, multi-party computation, and more, largely due to its additive homomorphism. In these applications, range proofs for the Paillier cryptosystem are crucial for maintaining security, because of the mismatch between the message space in the Paillier system and the operation space in application scenarios.In this paper, we present novel range proofs for the Paillier cryptosystem, specifically aimed at optimizing those for both Paillier plaintext and affine operation. We interpret encryptions and affine operations as commitments over integers, as opposed to solely over ℤN . Consequently, we propose direct range proof for the updated cryptosystem, thereby eliminating the need for auxiliary integer commitments as required by the current state-of-the-art. Our work yields significant improvements: in the range proof for Paillier plaintext, our approach reduces communication overheads by approximately 60\\%, and computational overheads by 30\\% and 10\\% for the prover and verifier, respectively. In the range proof for Paillier affine operation, our method reduces the bandwidth by 70\\%, and computational overheads by 50\\% and 30\\% for the prover and verifier, respectively. Furthermore, we demonstrate that our techniques can be utilized to improve the performance of threshold ECDSA and the DCR-based instantiation of the Naor-Yung CCA2 paradigm.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690261",
    "comment": ""
  },
  {
    "title": "Conan: Distributed Proofs of Compliance for Anonymous Data Collection",
    "author": "Zhou, Mingxun and Fanti, Giulia and Shi, Elaine",
    "abstract": "We consider how to design an anonymous data collection protocol that enforces compliance rules. Imagine that each client contributes multiple data items (e.g., votes, location crumbs, or secret shares of its input) to an abstraction of an anonymous network, which mixes all clients' data items so that the receiver cannot determine which data items belong to the same user. Now, each user must prove to an auditor that the set it contributed satisfies a compliance predicate, without identifying which items it contributed. For example, the auditor may want to ensure that no voter voted for the same candidate twice, or that a user's location crumbs are not too far apart in a given time interval.Our main contribution is a novel anonymous, compliant data collection protocol that realizes the above goal. In comparison with naive approaches such as generic multi-party computation or earlier constructions of collaborative zero-knowledge proofs, the most compelling advantage of our approach is that each client's communication and computation overhead do not grow with respect to the number of clients n. In this sense, we save a factor of at least n over prior work, which allows our technique to scale to applications with a large number of clients, such as anonymous voting and privacy-preserving federated learning.We first describe our protocol using generic cryptographic primitives that can be realized from standard assumptions. We then suggest a concrete instantiation called Conan which we implement and evaluate. In this concrete instantiation, we are willing to employ SNARKs and the random oracle model for better practical efficiency. Notably, in this practical instantiation, each client's additional communication overhead (not counting the overhead of sending its data items over the anonymous network) is only O (1). We evaluated our technique in various application settings, including secure voting, and secure aggregation protocols for histogram, summation, and vector summation. Our evaluation results show that in all scenarios, each client's additional communication overhead is only 2.2KB or 2.6KB, depending on which SNARK implementation we use. Further, each client's computation only 0.2s - 0.5s for almost all cases, except for the vector summation application where the data items are high-dimensional and each client's computation is 8.5-10.6s.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690264",
    "comment": ""
  },
  {
    "title": "Hekaton: Horizontally-Scalable zkSNARKs Via Proof Aggregation",
    "author": "Rosenberg, Michael and Mopuri, Tushar and Hafezi, Hossein and Miers, Ian and Mishra, Pratyush",
    "abstract": "Zero-knowledge Succinct Non-interactive ARguments of Knowledge (zkSNARKs) allow a prover to convince a verifier of the correct execution of a large computation in private and easily-verifiable manner. These properties make zkSNARKs a powerful tool for adding accountability, scalability, and privacy to numerous systems such as blockchains and verifiable key directories. Unfortunately, existing zkSNARKs are unable to scale to large computations due to time and space complexity requirements for the prover algorithm. As a result, they cannot handle real-world instances of the aforementioned applications.In this work, we introduce Hekaton, a zkSNARK that overcomes these barriers and can efficiently handle arbitrarily large computations. We construct Hekaton via a new ''distribute-and-aggregate'' framework that breaks up large computations into small chunks, proves these chunks in parallel in a distributed system, and then aggregates the resulting chunk proofs into a single succinct proof Underlying this framework is a new technique for efficiently handling data that is shared between chunks that we believe could be of independent interest.We implement a distributed prover for Hekaton, and evaluate its performance on a compute cluster. Our experiments show that Hekaton achieves strong horizontal scalability (proving time decreases linearly as we increase the number of nodes in the cluster), and is able to prove large computations quickly: it can prove computations of size 2^35 gates in under an hour, which is much faster than prior work.Finally, we also apply Hekaton to two applications of real-world interest: proofs of batched insertion for a verifiable key directory and proving correctness of RAM computations. In both cases, Hekaton is able to scale to handle realistic workloads with better efficiency than prior work.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690282",
    "comment": ""
  },
  {
    "title": "GRandLine: Adaptively Secure DKG and Randomness Beacon with (Log-)Quadratic Communication Complexity",
    "author": "Bacho, Renas and Lenzen, Christoph and Loss, Julian and Ochsenreither, Simon and Papachristoudis, Dimitrios",
    "abstract": "A randomness beacon is a source of continuous and publicly verifiable randomness which is of crucial importance for many applications. Existing works on randomness beacons suffer from at least one of the following drawbacks: (i) security only against static (i.e., non-adaptive) adversaries, (ii) each epoch takes many rounds of communication, or (iii) computationally expensive tools such as proof-of-work (PoW) or verifiable delay functions (VDF). In this work, we introduce GRandLine, the first adaptively secure randomness beacon protocol that overcomes all these limitations while preserving simplicity and optimal resilience in the synchronous network setting. We achieve our result in two steps. First, we design a novel distributed key generation (DKG) protocol GRand that runs in O(λ n2 log n ) bits of communication but, unlike most conventional DKG protocols, outputs both secret and public keys as group elements. Here, λ denotes the security parameter. Second, following termination of GRand, parties can use their keys to derive a sequence of randomness beacon values, where each random value costs only a single asynchronous round and O(λ n2) bits of communication. We implement GRandLine and evaluate it using a network of up to 64 parties running in geographically distributed AWS instances. Our evaluation shows that GRandLine can produce about 2 beacon outputs per second in a network of 64 parties. We compare our protocol to the state-of-the-art randomness beacon protocols OptRand (NDSS '23), BRandPiper (CCS '21), and Drand, in the same setting and observe that it vastly outperforms them.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690287",
    "comment": ""
  },
  {
    "title": "TokenScout: Early Detection of Ethereum Scam Tokens via Temporal Graph Learning",
    "author": "Wu, Cong and Chen, Jing and Zhao, Ziming and He, Kun and Xu, Guowen and Wu, Yueming and Wang, Haijun and Li, Hongwei and Liu, Yang and Xiang, Yang",
    "abstract": "Decentralized finance has experienced phenomenal growth, revolutionizing the landscape of financial transactions and asset management via blockchain. Yet, this swift growth brings with it substantial challenges, notably the surge in scam tokens, imposing significant security threats on cryptocurrency investments and trading. Existing detection methods of scam token, primarily relying on analyzing contract codes or transaction patterns, struggle to catch increasingly sophisticated tactics employed by scammers. For example, contract-based analysis are unable to identify scams lacking overt malicious code, e.g., most rugpulls, while transaction-based methods generally lack the foresight to early-detect potential risks.In this paper, we present TokenScout, the first temporal temporal graph neural network-based framework for scam token early detection. TokenScout formulates token transfer data as a dynamic temporal attributed multigraph and leverages the temporal graph learning model to learn graph representations. It also builds a graph representation refining model based on contrastive learning to learn a more discriminative representation space for risk identification. We evaluated TokenScout using a comprehensive dataset of 214,084 standard ERC20 tokens from 2015 to February 2023. TokenScout achieves a balanced accuracy of 98.41\\%. Additionally, from March to May 2023, deploying TokenScout on Ethereum effectively identified 706 rugpulls, 174 honeypots, and 90 Ponzi schemes, thereby alerting to potential risks exceeding 240 million.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690234",
    "comment": ""
  },
  {
    "title": "fAmulet: Finding Finalization Failure Bugs in Polygon zkRollup",
    "author": "Li, Zihao and Peng, Xinghao and He, Zheyuan and Luo, Xiapu and Chen, Ting",
    "abstract": "Zero-knowledge layer 2 protocols emerge as a compelling approach to overcoming blockchain scalability issues by processing transactions through the transaction finalization process. During this process, transactions are efficiently processed off the main chain. Besides, both the transaction data and the zero-knowledge proofs of transaction executions are reserved on the main chain, ensuring the availability of transaction data as well as the correctness and verifiability of transaction executions. Hence, any bugs that cause the transaction finalization failure are crucial, as they impair the usability of these protocols and the scalability of blockchains.In this work, we conduct the first systematic study on finalization failure bugs in zero-knowledge layer 2 protocols, and define two kinds of such bugs. Besides, we design fAmulet, the first tool to detect finalization failure bugs in Polygon zkRollup, a prominent zero-knowledge layer 2 protocol, by leveraging fuzzing testing. To trigger finalization failure bugs effectively, we introduce a finalization behavior model to guide our transaction fuzzer to generate and mutate transactions for inducing diverse behaviors across each component (e.g., Sequencer) in the finalization process. Moreover, we define bug oracles according to the distinct bug definitions to accurately detect bugs. Through our evaluation, fAmulet can uncover twelve zero-day finalization failure bugs in Polygon zkRollup, and cover at least 20.8\\% more branches than baselines. Furthermore, through our preliminary study, fAmulet uncovers a zero-day finalization failure bug in Scroll zkRollup, highlighting the generality of fAmulet to be applied to other zero-knowledge layer 2 protocols. At the time of writing, all our uncovered bugs have been confirmed and fixed by Polygon zkRollup and Scroll zkRollup teams.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690243",
    "comment": ""
  },
  {
    "title": "Characterizing Ethereum Address Poisoning Attack",
    "author": "Guan, Shixuan and Li, Kai",
    "abstract": "This paper presents the first comprehensive analysis of the address poisoning attack surged on the Ethereum blockchain. This phishing attack typically exploits the address shortening feature of Ethereum explorers and digital wallets (e.g., Etherscan and MetaMask) by crafting token transfer events with a seemingly correct address to poison victims' transfer history, waiting for them to mistakenly transfer assets to the attacker's address.  To systematically detect and characterize the address poisoning attack, we developed a detection system named Poison-Hunter, which can recognize the attacker's crafted transfers and detect the phishing addresses controlled by the attacker. By applying Poison-Hunter to Ethereum blocks produced from Nov. 2022 to Feb. 2024, we have detected millions of phishing transfers and phishing addresses. Our analysis shows that the attacker has predominantly targeted USDC and USDT token holders and used a phishing address that looks highly similar to a benign one. We also find that the sender of legitimate transfers was the primary target of this attack. Furthermore, by tracing the transaction history of the detected phishing addresses, we reveal that over 1,800 victim addresses have lost crypto assets, with a potential financial loss of up to 144 million US dollars. Among them, about 90 million of loss are confirmed by this work. Finally, our analysis suggests that 98\\% of phishing addresses are controlled by four entities, which collected nearly 92\\% of the total profits. Overall, this paper sheds light on the tactics utilized in the address poisoning attack and its scale and impact on the Ethereum blockchain, emphasizing the urgent need for an effective detection and prevention mechanism against such a phishing activity.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690277",
    "comment": ""
  },
  {
    "title": "FORAY: Towards Effective Attack Synthesis against Deep Logical Vulnerabilities in DeFi Protocols",
    "author": "Wen, Hongbo and Liu, Hanzhi and Song, Jiaxin and Chen, Yanju and Guo, Wenbo and Feng, Yu",
    "abstract": "Blockchain adoption has surged with the rise of Decentralized Finance (DeFi) applications. However, the significant value of digital assets managed by DeFi protocols makes them prime targets for attacks. Current smart contract vulnerability detection tools struggle with DeFi protocols due to deep logical bugs arising from complex financial interactions between multiple smart contracts. These tools primarily analyze individual contracts and resort to brute-force methods for DeFi protocols crossing numerous smart contracts, leading to inefficiency.We introduce FORAY, a highly effective attack synthesis framework against deep logical bugs in DeFi protocols. FORAY proposes a novel attack sketch generation and completion framework. Specifically, instead of treating DeFis as regular programs, we design a domain-specific language (DSL) to lift the low-level smart contracts into their high-level financial operations. Based on our DSL, we first compile a given DeFi protocol into a token flow graph, our graphical representation of DeFi protocols. Then, we design an efficient sketch generation method to synthesize attack sketches for a certain attack goal (e.g., price manipulation, arbitrage, etc.). This algorithm strategically identifies candidate sketches by finding reachable paths in Token Flow Graph (TFG), which is much more efficient than random enumeration. For each candidate sketch written in our DSL, FORAY designs a domain-specific symbolic compilation to compile it into SMT constraints. Our compilation simplifies the constraints by removing redundant smart contract semantics. It maintains the usability of symbolic compilation, yet scales to problems orders of magnitude larger. Finally, the candidates are completed via existing solvers and are transformed into concrete attacks via direct syntax transformation. Through extensive experiments on real-world security incidents, we demonstrate that FORAY significantly outperforms Halmos and ItyFuzz, the state-of-the-art (SOTA) tools for smart contract vulnerability detection, in both effectiveness and efficiency. Specifically, out of 34 benchmark DeFi logical bugs that happened in the last two years, FORAY synthesizes 27 attacks, whereas ItyFuzz and Halmos only synthesize 11 and 3, respectively. Furthermore, FORAY also finds ten zero-day vulnerabilities in the BNB chain. Finally, we demonstrate the effectiveness of our key components and FORAY's capability of avoiding false positives.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690293",
    "comment": ""
  },
  {
    "title": "Towards Automatic Discovery of Denial of Service Weaknesses in Blockchain Resource Models",
    "author": "Luo, Feng and Lin, Huangkun and Li, Zihao and Luo, Xiapu and Luo, Ruijie and He, Zheyuan and Song, Shuwei and Chen, Ting and Luo, Wenxuan",
    "abstract": "nial-of-Service (DoS) attacks at the execution layer represent one of the most severe threats to blockchain systems, compromising availability by depleting the resources of victims. To counteract these attacks, many blockchains have implemented unique resource models that incorporate transaction fees. Nevertheless, historical incidents of DoS attacks demonstrate that these resource model designs remain inadequate. Although there are studies that manually craft DoS attacks on specific blockchains in isolation, none of them can discover DoS weaknesses in blockchains automatically. In this paper, we provide an insight into DoS weaknesses in blockchain resource models, and present a generic and systematic approach to uncover these weaknesses. In our approach, we first identify DoS weaknesses by DoSVER, a novel tool that reasons feasible DoS weaknesses against blockchain resource models by formal verification. The identified DoS weaknesses will be further validated by DoSDET, a new framework that automates the attack synthesis in exploiting the identified DoS weaknesses. We conduct a comprehensive and systematic evaluation by extensive experiments on nine diverse and widely-used blockchains, and discovered 12 DoS weaknesses with corresponding exploitation across the nine blockchains, 10 of which were unveiled for the first time.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690329",
    "comment": ""
  },
  {
    "title": "Blockchain Bribing Attacks and the Efficacy of Counterincentives",
    "author": "Karakostas, Dimitris and Kiayias, Aggelos and Zacharias, Thomas",
    "abstract": "We analyze bribing attacks in Proof-of-Stake distributed ledgers from a game theoretic perspective. In bribing attacks, an adversary offers participants a reward in exchange for instructing them how to behave, with the goal of attacking the protocol's properties. Specifically, our work focuses on adversaries that target blockchain safety. We consider two types of bribing, depending on how the bribes are awarded: i) guided bribing, where the bribe is given as long as the bribed party behaves as instructed; ii) effective bribing, where bribes are conditional on the attack's success, w.r.t. well-defined metrics. We analyze each type of attack in a game theoretic setting and identify relevant equilibria. In guided bribing, we show that the protocol is not an equilibrium and then describe good equilibria, where the attack is unsuccessful, and a negative one, where all parties are bribed such that the attack succeeds. In effective bribing, we show that both the protocol and the \"all bribed\" setting are equilibria. Using the identified equilibria, we then compute bounds on the Prices of Stability and Anarchy. Our results indicate that additional mitigations are needed for guided bribing, so our analysis concludes with incentive-based mitigation techniques, namely slashing and dilution. Here, we present two positive results, that both render the protocol an equilibrium and achieve maximal welfare for all parties, and a negative result, wherein an attack becomes more plausible if it severely affects the ledger's token's market price.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670330",
    "comment": ""
  },
  {
    "title": "Keeping Up with the KEMs: Stronger Security Notions for KEMs and Automated Analysis of KEM-based Protocols",
    "author": "Cremers, Cas and Dax, Alexander and Medinger, Niklas",
    "abstract": "Key Encapsulation Mechanisms (KEMs) are a critical building block for hybrid encryption and modern security protocols, notably in the post-quantum setting. Given the asymmetric public key of a recipient, the primitive establishes a shared secret key between sender and recipient. In recent years, a large number of abstract designs and concrete implementations of KEMs have been proposed, e.g., in the context of the NIST process for post-quantum primitives.In this work, we (i) establish stronger security notions for KEMs, and (ii) develop a symbolic analysis method to analyze security protocols that use KEMs. First, we generalize existing security notions for KEMs in the computational setting, introduce several stronger security notions and prove their relations. Our new properties formalize in which sense outputs of the KEM uniquely determine, i.e., bind, other values. Our new binding properties can be used, e.g., to prove the absence of attacks that were not captured by prior security notions. Among these, we identify a new class of attacks that we coin re-encapsulation attacks.Second, we develop a family of fine-grained symbolic models that correspond to our hierarchy of computational security notions, and are suitable for the automated analysis of KEM-based security protocols. We encode our models as a library in the framework of the Tamarin prover. Given a KEM-based protocol, our approach can automatically derive the minimal binding properties required from the KEM; or, if also given a concrete KEM, can analyze if the protocol meets its security goals. In case studies, Tamarin automatically discovers, e.g., that the key exchange protocol proposed in the original Kyber paper [12] requires stronger properties from the KEM than were proven in [12].",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670283",
    "comment": ""
  },
  {
    "title": "SECOMP: Formally Secure Compilation of Compartmentalized C Programs",
    "author": "Thibault, J\\'{e}r\\'{e}my and Blanco, Roberto and Lee, Dongjae and Argo, Sven and Azevedo de Amorim, Arthur and Georges, A\\\"{\\i}na Linn and Hri\\c{t}cu, C\\u{a}t\\u{a}lin and Tolmach, Andrew",
    "abstract": "Undefined behavior in C often causes devastating security vulnerabilities. One practical mitigation is compartmentalization, which allows developers to structure large programs into mutually distrustful compartments with clearly specified privileges and interactions. In this paper we introduce SECOMP, a compiler for compartmentalized C code that comes with machine-checked proofs guaranteeing that the scope of undefined behavior is restricted to the compartments that encounter it and become dynamically compromised. These guarantees are formalized as the preservation of safety properties against adversarial contexts, a secure compilation criterion similar to full abstraction, and this is the first time such a strong criterion is proven for a mainstream programming language. To achieve this we extend the languages of the CompCert verified C compiler with isolated compartments that can only interact via procedure calls and returns, as specified by cross-compartment interfaces. We adapt the passes and optimizations of CompCert as well as their correctness proofs to this compartment-aware setting. We then use compiler correctness as an ingredient in a larger secure compilation proof that involves several proof engineering novelties, needed to scale formally secure compilation up to a C compiler.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670288",
    "comment": ""
  },
  {
    "title": "Testing Side-channel Security of Cryptographic Implementations against Future Microarchitectures",
    "author": "Barthe, Gilles and B\\\"{o}hme, Marcel and Cauligi, Sunjay and Chuengsatiansup, Chitchanok and Genkin, Daniel and Guarnieri, Marco and Mateos Romero, David and Schwabe, Peter and Wu, David and Yarom, Yuval",
    "abstract": "How will future microarchitectures impact the security of existing cryptographic implementations? As we cannot keep reducing the size of transistors, chip vendors have started developing new microarchitectural optimizations to speed up computation. A recent study (Sanchez Vicarte et al., ISCA 2021) suggests that these optimizations might open the Pandora's box of microarchitectural attacks. However, there is little guidance on how to evaluate the security impact of future optimization proposals.To help chip vendors explore the impact of microarchitectural optimizations on cryptographic implementations, we develop (i) an expressive domain-specific language, called LmSpec, that allows them to specify the leakage model for the given optimization and (ii) a testing framework, called LmTest, to automatically detect leaks under the specified leakage model within the given implementation. Using this framework, we conduct an empirical study of 18 proposed microarchitectural optimizations on 25 implementations of eight cryptographic primitives in five popular libraries. We find that every implementation would contain secret-dependent leaks, sometimes sufficient to recover a victim's secret key, if these optimizations were realized. Ironically, some leaks are possible only because of coding idioms used to prevent leaks under the standard constant-time model.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670319",
    "comment": ""
  },
  {
    "title": "On Kernel's Safety in the Spectre Era (And KASLR is Formally Dead)",
    "author": "Davoli, Davide and Avanzini, Martin and Rezk, Tamara",
    "abstract": "The efficacy of address space layout randomization has been formally demonstrated in a shared-memory model by Abadi et al., contingent on specific assumptions about victim programs. However, modern operating systems, implementing layout randomization in the kernel, diverge from these assumptions and operate on a separate memory model with communication through system calls. In this work, we relax Abadi et al.'s language assumptions while demonstrating that layout randomization offers a comparable safety guarantee in a system with memory separation. However, in practice, speculative execution and side-channels are recognized threats to layout randomization. We show that kernel safety cannot be restored for attackers capable of using side-channels and speculative execution and introduce a new condition, that allows us to formally prove kernel safety in the Spectre era. Our research demonstrates that under this condition, the system remains safe without relying on layout randomization. We also demonstrate that our condition can be sensibly weakened, leading to enforcement mechanisms that can guarantee kernel safety for safe system calls in the Spectre era.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670332",
    "comment": ""
  },
  {
    "title": "The Privacy-Utility Trade-off in the Topics API",
    "author": "Alvim, M\\'{a}rio S. and Fernandes, Natasha and McIver, Annabelle and Nunes, Gabriel H.",
    "abstract": "The ongoing deprecation of third-party cookies by web browser vendors has sparked the proposal of alternative methods to support more privacy-preserving personalized advertising on web browsers and applications. The Topics API is being proposed by Google to provide third-parties with \"coarse-grained advertising topics that the page visitor might currently be interested in\". In this paper, we analyze the re-identification risks for individual Internet users and the utility provided to advertising companies by the Topics API, i.e. learning the most popular topics and distinguishing between real and random topics. We provide theoretical results dependent only on the API parameters that can be readily applied to evaluate the privacy and utility implications of future API updates, including novel general upper-bounds that account for adversaries with access to unknown, arbitrary side information, the value of the differential privacy parameter ε, and experimental results on real-world data that validate our theoretical model.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670368",
    "comment": ""
  },
  {
    "title": "Specification and Verification of Strong Timing Isolation of Hardware Enclaves",
    "author": "Lau, Stella and Bourgeat, Thomas and Pit-Claudel, Cl\\'{e}ment and Chlipala, Adam",
    "abstract": "The process isolation enforceable by commodity hardware and operating systems is too weak to protect secrets from malicious code running on the same machine: attacks exploit timing side channels derived from contention on shared microarchitectural resources to extract secrets. With appropriate hardware support, however, we can construct isolated enclaves and safeguard independent processes from interference through timing side channels, a step towards confidentiality and integrity guarantees.In this paper, we describe our work on formally specifying and verifying that a synthesizable hardware architecture implements strong timing isolation for enclaves. We reason about the cycle-accurate semantics of circuits with respect to a trustworthy formulation of strong isolation based on \"air-gapped machines\" and develop a modular proof strategy that sidesteps the need to prove functional correctness of processors. We apply our method on a synthesizable, multicore, pipelined RISC-V design formalized in Coq.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690203",
    "comment": ""
  },
  {
    "title": "A Causal Explainable Guardrails for Large Language Models",
    "author": "Chu, Zhixuan and Wang, Yan and Li, Longfei and Wang, Zhibo and Qin, Zhan and Ren, Kui",
    "abstract": "Large Language Models (LLMs) have shown impressive performance in natural language tasks, but their outputs can exhibit undesirable attributes or biases. Existing methods for steering LLMs toward desired attributes often assume unbiased representations and rely solely on steering prompts. However, the representations learned from pre-training can introduce semantic biases that influence the steering process, leading to suboptimal results. We propose LLMGuardrail, a novel framework that incorporates causal analysis and adversarial learning to obtain unbiased steering representations in LLMs. LLMGuardrail systematically identifies and blocks the confounding effects of biases, enabling the extraction of unbiased steering representations. Experiments demonstrate LLMGuardrail's effectiveness in steering LLMs toward desired attributes while mitigating biases. Our work contributes to developing safe and reliable LLMs that align with desired attributes.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690217",
    "comment": ""
  },
  {
    "title": "Legilimens: Practical and Unified Content Moderation for Large Language Model Services",
    "author": "Wu, Jialin and Deng, Jiangyi and Pang, Shengyuan and Chen, Yanjiao and Xu, Jiayang and Li, Xinfeng and Xu, Wenyuan",
    "abstract": "Given the societal impact of unsafe content generated by large language models (LLMs), ensuring that LLM services comply with safety standards is a crucial concern for LLM service providers. Common content moderation methods are limited by an effectiveness-and-efficiency dilemma, where simple models are fragile while sophisticated models consume excessive computational resources. In this paper, we reveal for the first time that effective and efficient content moderation can be achieved by extracting conceptual features from chat-oriented LLMs, despite their initial fine-tuning for conversation rather than content moderation. We propose a practical and unified content moderation framework for LLM services, named Legilimens, which features both effectiveness and efficiency. Our red-team model-based data augmentation enhances the robustness of Legilimens against state-of-the-art jailbreaking. Additionally, we develop a framework to theoretically analyze the cost-effectiveness of Legilimens compared to other methodsWe have conducted extensive experiments on five host LLMs, seventeen datasets, and nine jailbreaking methods to verify the effectiveness, efficiency, and robustness of Legilimens against normal and adaptive adversaries. A comparison of Legilimens with both commercial and academic baselines demonstrates the superior performance of Legilimens. Furthermore, we confirm that Legilimens can be applied to few-shot scenarios and extended to multi-label classification tasks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690322",
    "comment": ""
  },
  {
    "title": "SurrogatePrompt: Bypassing the Safety Filter of Text-to-Image Models via Substitution",
    "author": "Ba, Zhongjie and Zhong, Jieming and Lei, Jiachen and Cheng, Peng and Wang, Qinglong and Qin, Zhan and Wang, Zhibo and Ren, Kui",
    "abstract": "Advanced text-to-image models such as DALL⋅E 2, Midjourney, and Stable Diffusion can generate highly realistic images, raising significant concerns regarding the potential proliferation of unsafe content. This includes adult, violent, or deceptive imagery of political figures. Despite claims of rigorous safety mechanisms implemented in these models to restrict the generation of Not-Safe-For-Work (NSFW) content, we successfully devise and exhibit the first prompt attacks on Midjourney, producing abundant photorealistic NSFW images. We reveal the fundamental principles of such prompt attacks and strategically substitute high-risk sections within a suspect prompt to evade closed-source safety measures. Our novel framework, SurrogatePrompt, systematically generates attack prompts, utilizing large language models and image-to-text modules to automate attack prompt creation at scale. Evaluation results disclose an 88\\% success rate in bypassing Midjourney's proprietary safety filter with our attack prompts, leading to counterfeit images depicting political figures in violent scenarios with high probability. We also demonstrate attacks generating explicit adult-themed imagery. Both subjective and objective assessments validate that the images generated from our attack prompts present considerable safety hazards.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690346",
    "comment": ""
  },
  {
    "title": "Moderator: Moderating Text-to-Image Diffusion Models through Fine-grained Context-based Policies",
    "author": "Wang, Peiran and Li, Qiyu and Yu, Longxuan and Wang, Ziyao and Li, Ang and Jin, Haojian",
    "abstract": "We present Moderator, a policy-based model management system that allows administrators to specify fine-grained content moderation policies and modify the weights of a text-to-image (TTI) model to make it significantly more challenging for users to produce images that violate the policies. In contrast to existing general-purpose model editing techniques, which unlearn concepts without considering the associated contexts, Moderator allows admins to specify what content should be moderated, under which context, how it should be moderated, and why moderation is necessary. Given a set of policies, Moderator first prompts the original model to generate images that need to be moderated, then uses these self-generated images to reverse fine-tune the model to compute task vectors for moderation and finally negates the original model with the task vectors to decrease its performance in generating moderated content. We evaluated Moderator with 14 participants to play the role of admins and found they could quickly learn and author policies to pass unit tests in approximately 2.29 policy iterations. Our experiment with 32 stable diffusion users suggested that Moderator can prevent 65\\% of users from generating moderated content under 15 attempts and require the remaining users an average of 8.3 times more attempts to generate undesired content.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690327",
    "comment": ""
  },
  {
    "title": "GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models",
    "author": "Tang, Kunsheng and Zhou, Wenbo and Zhang, Jie and Liu, Aishan and Deng, Gelei and Li, Shuai and Qi, Peigui and Zhang, Weiming and Zhang, Tianwei and Yu, NengHai",
    "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in natural language generation, but they have also been observed to magnify societal biases, particularly those related to gender. In response to this issue, several benchmarks have been proposed to assess gender bias in LLMs. However, these benchmarks often lack practical flexibility or inadvertently introduce biases. To address these shortcomings, we introduce GenderCARE, a comprehensive framework that encompasses innovative Criteria, bias Assessment, Reduction techniques, and Evaluation metrics for quantifying and mitigating gender bias in LLMs. To begin, we establish pioneering criteria for gender equality benchmarks, spanning dimensions such as inclusivity, diversity, explainability, objectivity, robustness, and realisticity. Guided by these criteria, we construct GenderPair, a novel pair-based benchmark designed to assess gender bias in LLMs comprehensively. Our benchmark provides standardized and realistic evaluations, including previously overlooked gender groups such as transgender and non-binary individuals. Furthermore, we develop effective debiasing techniques that incorporate counterfactual data augmentation and specialized fine-tuning strategies to reduce gender bias in LLMs without compromising their overall performance. Extensive experiments demonstrate a significant reduction in various gender bias benchmarks, with reductions peaking at over 90\\% and averaging above 35\\% across 17 different LLMs. Importantly, these reductions come with minimal variability in mainstream language tasks, remaining below 2\\%. By offering a realistic assessment and tailored reduction of gender biases, we hope that our GenderCARE can represent a significant step towards achieving fairness and equity in LLMs. More details are available at https://github.com/kstanghere/GenderCARE-ccs24.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670284",
    "comment": ""
  },
  {
    "title": "Understanding Implosion in Text-to-Image Generative Models",
    "author": "Ding, Wenxin and Li, Cathy Y. and Shan, Shawn and Zhao, Ben Y. and Zheng, Haitao",
    "abstract": "Recent works show that text-to-image generative models are surprisingly vulnerable to a variety of poisoning attacks. Empirical results find that these models can be corrupted by altering associations between individual text prompts and associated visual features. Furthermore, a number of concurrent poisoning attacks can induce \"model implosion,\" where the model becomes unable to produce meaningful images for unpoisoned prompts. These intriguing findings highlight the absence of an intuitive framework to understand poisoning attacks on these models.In this work, we establish the first analytical framework on robustness of image generative models to poisoning attacks, by modeling and analyzing the behavior of the cross-attention mechanism in latent diffusion models. We model cross-attention training as an abstract problem of \"supervised graph alignment\" and formally quantify the impact of training data by the hardness of alignment, measured by an Alignment Difficulty (AD) metric. The higher the AD, the harder the alignment. We prove that AD increases with the number of individual prompts (or concepts) poisoned. As AD grows, the alignment task becomes increasingly difficult, yielding highly distorted outcomes that frequently map meaningful text prompts to undefined or meaningless visual representations. As a result, the generative model implodes and outputs random, incoherent images at large. We validate our analytical framework through extensive experiments, and we confirm and explain the unexpected (and unexplained) effect of model implosion while producing new, unforeseen insights. Our work provides a useful tool for studying poisoning attacks against diffusion models and their defenses.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690205",
    "comment": ""
  },
  {
    "title": "Is Difficulty Calibration All We Need? Towards More Practical Membership Inference Attacks",
    "author": "He, Yu and Li, Boheng and Wang, Yao and Yang, Mengda and Wang, Juan and Hu, Hongxin and Zhao, Xingyu",
    "abstract": "The vulnerability of machine learning models to Membership Inference Attacks (MIAs) has garnered considerable attention in recent years. These attacks determine whether a data sample belongs to the model's training set or not. Recent research has focused on reference-based attacks, which leverage difficulty calibration with independently trained reference models. While empirical studies have demonstrated its effectiveness, there is a notable gap in our understanding of the circumstances under which it succeeds or fails. In this paper, we take a further step towards a deeper understanding of the role of difficulty calibration. Our observations reveal inherent limitations in calibration methods, leading to the misclassification of non-members and suboptimal performance, particularly on high-loss samples. We further identify that these errors stem from an imperfect sampling of the potential distribution and a strong dependence of membership scores on the model parameters. By shedding light on these issues, we propose RAPID: a query-efficient and computation-efficient MIA that directly Re-leverAges the original membershiP scores to mItigate the errors in Difficulty calibration. Our experimental results, spanning 9 datasets and 5 model architectures, demonstrate that RAPID outperforms previous state-of-the-art attacks (e.g., LiRA and Canary offline) across different metrics while remaining computationally efficient. Our observations and analysis challenge the current de facto paradigm of difficulty calibration in high-precision inference, encouraging greater attention to the persistent risks posed by MIAs in more practical scenarios.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690316",
    "comment": ""
  },
  {
    "title": "A Unified Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability",
    "author": "Zhu, Jie and Zha, Jirong and Li, Ding and Wang, Leye",
    "abstract": "Self-supervised learning shows promise in harnessing extensive unlabeled data, but it also confronts significant privacy concerns, especially in vision. In this paper, we aim to perform membership inference on visual self-supervised models in a more realistic setting: self-supervised training method and details are unknown for an adversary when attacking as he usually faces a black-box system in practice. In this setting, considering that self-supervised model could be trained by completely different self-supervised paradigms, e.g., masked image modeling and contrastive learning, with complex training details, we propose a unified membership inference method called PartCrop. It is motivated by the shared part-aware capability among models and stronger part response on the training data. Specifically, PartCrop crops parts of objects in an image to query responses with the image in representation space. We conduct extensive attacks on self-supervised models with different training protocols and structures using three widely used image datasets. The results verify the effectiveness and generalization of PartCrop. Moreover, to defend against PartCrop, we evaluate two common approaches, i.e., early stop and differential privacy, and propose a tailored method called shrinking crop scale range. The defense experiments indicate that all of them are effective. Our code is available at https://github.com/JiePKU/PartCrop.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690202",
    "comment": ""
  },
  {
    "title": "Membership Inference Attacks against Vision Transformers: Mosaic MixUp Training to the Defense",
    "author": "Zhang, Qiankun and Yuan, Di and Zhang, Boyu and Yuan, Bin and Du, Bingqian",
    "abstract": "Vision transformers (ViTs) have demonstrated great success in various fundamental CV tasks, mainly benefiting from their self-attention-based transformer architectures, and the paradigm of pre-training followed by fine-tuning. However, such advantages may lead to significant data privacy risks, such as membership inference attacks (MIAs), which remain unclear. This paper presents the first comprehensive study on MIAs and corresponding defenses against ViTs. Our first contribution is a rollout-attention-based MIA method (RAMIA), based on an experimental observation that the attention, more precisely the rollout attention, behaves disproportionately for members and non-members. We evaluate RAMIA on the standard ViT architecture proposed by Google (ICLR 2021), achieving high accuracy, precision, and recall performance. Further, inspired by another experimental observation on a strong connection between positional embeddings (PEs) and attentions, we propose a novel framework for training ViTs, named Mosaic MixUp Training (MMUT), as a defense against RAMIA. Intuitively, MMUT mixes up private images and public ones at a patch level, and mosaics the corresponding PEs with a global learnable mosaic embedding. Our empirical results show MMUT achieves a much better accuracy-privacy trade-off than some common defense mechanisms. Extensive experiments are conducted to rigorously evaluate both RAMIA and MMUT.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690268",
    "comment": ""
  },
  {
    "title": "Evaluations of Machine Learning Privacy Defenses are Misleading",
    "author": "Aerni, Michael and Zhang, Jie and Tram\\`{e}r, Florian",
    "abstract": "Empirical defenses for machine learning privacy forgo the provable guarantees of differential privacy in the hope of achieving higher utility while resisting realistic adversaries. We identify severe pitfalls in existing empirical privacy evaluations (based on membership inference attacks) that result in misleading conclusions. In particular, we show that prior evaluations fail to characterize the privacy leakage of the most vulnerable samples, use weak attacks, and avoid comparisons with practical differential privacy baselines. In 5 case studies of empirical privacy defenses, we find that prior evaluations underestimate privacy leakage by an order of magnitude. Under our stronger evaluation, none of the empirical defenses we study are competitive with a properly tuned, high-utility DP-SGD baseline (with vacuous provable guarantees).",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690194",
    "comment": ""
  },
  {
    "title": "The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks",
    "author": "Chen, Xiaoyi and Tang, Siyuan and Zhu, Rui and Yan, Shijun and Jin, Lei and Wang, Zihao and Su, Liya and Zhang, Zhikun and Wang, XiaoFeng and Tang, Haixu",
    "abstract": "The rapid advancements of large language models (LLMs) have raised public concerns about the privacy leakage of personally identifiable information (PII) within their extensive training datasets. Recent studies have demonstrated that an adversary could extract highly sensitive privacy data from the training data of LLMs with carefully designed prompts. However, these attacks suffer from the model's tendency to hallucinate and catastrophic forgetting (CF) in the pre-training stage, rendering the veracity of divulged PIIs negligible. In our research, we propose a novel attack, Janus, which exploits the fine-tuning interface to recover forgotten PIIs from the pre-training data in LLMs. We formalize the privacy leakage problem in LLMs and explain why forgotten PIIs can be recovered through empirical analysis on open-source language models. Based upon these insights, we evaluate the performance of Janus on both open-source language models and two latest LLMs, i.e., GPT-3.5-Turbo and LLaMA-2-7b. Our experiment results show that Janus amplifies the privacy risks by over 10 times in comparison with the baseline and significantly outperforms the state-of-the-art privacy extraction attacks including prefix attacks and in-context learning (ICL). Furthermore, our analysis validates that existing fine-tuning APIs provided by OpenAI and Azure AI Studio are susceptible to our Janus attack, allowing an adversary to conduct such an attack at a low cost.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690325",
    "comment": ""
  },
  {
    "title": "A General Framework for Data-Use Auditing of ML Models",
    "author": "Huang, Zonghao and Gong, Neil Zhenqiang and Reiter, Michael K.",
    "abstract": "Auditing the use of data in training machine-learning (ML) models is an increasingly pressing challenge, as myriad ML practitioners routinely leverage the effort of content creators to train models without their permission. In this paper, we propose a general method to audit an ML model for the use of a data-owner's data in training, without prior knowledge of the ML task for which the data might be used. Our method leverages any existing black-box membership inference method, together with a sequential hypothesis test of our own design, to detect data use with a quantifiable, tunable false-detection rate. We show the effectiveness of our proposed framework by applying it to audit data use in two types of ML models, namely image classifiers and foundation models.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690226",
    "comment": ""
  },
  {
    "title": "CountDown: Refcount-guided Fuzzing for Exposing Temporal Memory Errors in Linux Kernel",
    "author": "Bai, Shuangpeng and Zhang, Zhechang and Hu, Hong",
    "abstract": "Kernel use-after-free (UAF) bugs are severe threats to system security due to their complex root causes and high exploitability. We find that 36.1\\% of recent kernel UAF bugs are caused by improper uses of reference counters, dubbed refcount-related UAF bugs. Current kernel fuzzing tools based on code coverage can detect common memory errors, but none of them is aware of the root cause. As a consequence, they only trigger refcount-related UAF bugs passively and coincidentally, and may miss many deep hidden vulnerabilities.To actively trigger refcount-related UAF bugs, in this paper, we propose CountDown, a novel refcount-guided kernel fuzzer. CountDown collects diverse refcount operations from kernel executions and reshapes syscall relations based on commonly accessed refcounts. When generating user-space programs, CountDown prefers to combine syscalls that ever access the same refcounts, aiming to trigger complex refcount behaviors. It also injects refcount-decreasing and refcount-accessing syscalls to intentionally free the refcounted object and trigger invalid accesses through dangling pointers. We test CountDown on mainstream Linux kernels and compare it with popular fuzzers. On average, our tool can detect 66.1\\% more UAF bugs and 32.9\\% more KASAN reports than state-of-the-art tools. CountDown has found nine new kernel memory bugs, where two are fixed and one is confirmed.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690320",
    "comment": ""
  },
  {
    "title": "Top of the Heap: Efficient Memory Error Protection of Safe Heap Objects",
    "author": "Huang, Kaiming and Payer, Mathias and Qian, Zhiyun and Sampson, Jack and Tan, Gang and Jaeger, Trent",
    "abstract": "Heap memory errors remain a major source of software vulnerabilities. Existing memory safety defenses aim at protecting all objects, resulting in high performance cost and incomplete protection. Instead, we propose an approach that accurately identifies objects that are inexpensive to protect, and design a method to protect such objects comprehensively from all classes of memory errors. Towards this goal, we introduce the Uriah system that (1) statically identifies the heap objects whose accesses satisfy spatial and type safety, and (2) dynamically allocates such \"safe\" heap objects on an isolated safe heap to enforce a form of temporal safety while preserving spatial and type safety, called temporal allocated-type safety. Uriah finds 72.0\\% of heap allocation sites produce objects whose accesses always satisfy spatial and type safety in the SPEC CPU2006/2017 benchmarks, 5 server programs, and Firefox, which are then isolated on a safe heap using Uriah allocator to enforce temporal allocated-type safety. Uriah incurs only 2.9\\% and 2.6\\% runtime overhead, along with 9.3\\% and 5.4\\% memory overhead, on the SPEC CPU 2006 and 2017 benchmarks, while preventing exploits on all the heap memory errors in DARPA CGC binaries and 28 recent CVEs. Additionally, using existing defenses to enforce their memory safety guarantees on the unsafe heap objects significantly reduces overhead, enabling the protection of heap objects from all classes of memory errors at more practical costs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690310",
    "comment": ""
  },
  {
    "title": "Safeslab: Mitigating Use-After-Free Vulnerabilities via Memory Protection Keys",
    "author": "Momeu, Marius and Schn\\\"{u}ckel, Simon and Angnis, Kai and Polychronakis, Michalis and Kemerlis, Vasileios P.",
    "abstract": "Restricting dangling pointers from accessing freed memory is a promising technique for mitigating use-after-free vulnerabilities in memory-unsafe programming languages. However, existing solutions suffer from high performance overheads, as they rely on conventional page table manipulation to make dangling pointers inaccessible. In this paper, we present Safeslab: a heap-hardening extension that aims to mitigate use-after-free vulnerabilities via a novel and efficient address aliasing approach. Safeslab assigns multiple virtual aliases to each memory page in the system, and manages their access rights via the recently introduced Memory Protection Keys hardware extension, which is designed to provide a fast alternative to page tables for memory management. This allows Safeslab to drastically reduce the number of page table modifications, while blocking dangling pointers efficiently. We integrated Safeslab into the Linux kernel, replacing its default heap allocator (SLUB). The results of our experimental evaluation with real-world benchmarks show that Safeslab incurs a negligible runtime overhead of up to 4\\% and moderate memory waste.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670279",
    "comment": ""
  },
  {
    "title": "The Illusion of Randomness: An Empirical Analysis of Address Space Layout Randomization Implementations",
    "author": "Binosi, Lorenzo and Barzasi, Gregorio and Carminati, Michele and Zanero, Stefano and Polino, Mario",
    "abstract": "Address Space Layout Randomization (ASLR) is a crucial defense mechanism employed by modern operating systems to mitigate exploitation by randomizing processes? memory layouts. However, the stark reality is that real-world implementations of ASLR are imperfect and subject to weaknesses that attackers can exploit. This work evaluates the effectiveness of ASLR on major desktop platforms, including Linux, MacOS, and Windows, by examining the variability in the placement of memory objects across various processes, threads, and system restarts. In particular, we collect samples of memory object locations, conduct statistical analyses to measure the randomness of these placements and examine the memory layout to find any patterns among objects that could decrease this randomness. The results show that while some systems, like Linux distributions, provide robust randomization, others, like Windows and MacOS, often fail to adequately randomize key areas like executable code and libraries. Moreover, we find a significant entropy reduction in the entropy of libraries after the Linux 5.18 version and identify correlation paths that an attacker could leverage to reduce exploitation complexity significantly. Ultimately, we rank the identified weaknesses based on severity and validate our entropy estimates with a proof-of-concept attack. In brief, this paper provides the first comprehensive evaluation of ASLR effectiveness across different operating systems and highlights opportunities for Operating System (OS) vendors to strengthen ASLR implementations.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690239",
    "comment": ""
  },
  {
    "title": "SeMalloc: Semantics-Informed Memory Allocator",
    "author": "Wang, Ruizhe and Xu, Meng and Asokan, N.",
    "abstract": "Use-after-free (UAF) is a critical and prevalent problem in memory unsafe languages. While many solutions have been proposed, balancing security, run-time cost, and memory overhead (an impossible trinity) is hard.In this paper, we show one way to balance the trinity by passing more semantics about the heap object to the allocator for it to make informed allocation decisions. More specifically, we propose a new notion of thread-, context-, and flow-sensitive 'type', SemaType, to capture the semantics and prototype a SemaType-based allocator that aims for the best trade-off amongst the impossible trinity. In SeMalloc, only heap objects allocated from the same call site and via the same function call stack can possibly share a virtual memory address, which effectively stops type-confusion attacks and makes UAF vulnerabilities harder to exploit. Through extensive empirical evaluation, we show that SeMalloc is realistic: (a) SeMalloc is effective in thwarting all real-world vulnerabilities we tested; (b) benchmark programs run even slightly faster with SeMalloc than the default heap allocator, at a memory overhead averaged from 41\\% to 84\\%; and (c) SeMalloc balances security and overhead strictly better than other closely related works.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670363",
    "comment": ""
  },
  {
    "title": "Crossing Shifted Moats: Replacing Old Bridges with New Tunnels to Confidential Containers",
    "author": "Valdez, Enriquillo and Ahmed, Salman and Gu, Zhongshu and de Dinechin, Christophe and Cheng, Pau-Chen and Jamjoom, Hani",
    "abstract": "The Confidential Containers (CoCo) project, as an open-source community initiative, inherits the system architecture of Kata Containers while integrating confidential computing to protect cloud-native container workloads. However, there exists a misalignment in the threat model and trusted computing base (TCB) between Kata Containers and confidential computing. The shifted trust boundaries could potentially expose a range of vulnerabilities, particularly in scenarios where a malicious actor on the host gains access to the CoCo's unprotected control interface. This paper conducts a thorough examination of CoCo's system architecture, exploring the attack surface resulting from the discord in trust boundaries. We have assessed all API endpoints of CoCo's control interface, categorizing them based on their security properties. Drawing from these insights, we have developed a bifurcation approach to splitting CoCo's control interface. This involves establishing an owner-side controller and minimizing the capabilities of the existing host-side controller. Under this framework, the host-side controller is exclusively responsible for allocating and recycling compute resources, while dedicated workload owners can directly manage their containers through alternative secure tunnels. This approach ensures seamless integration with cloud-native orchestration layers and aligns CoCo with the threat model of confidential computing. By doing so, it effectively prevents untrusted hosts from accessing confidential data and interfering with the execution of workloads within protected domains.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670352",
    "comment": ""
  },
  {
    "title": "Faster FHE-Based Single-Server Private Information Retrieval",
    "author": "Luo, Ming and Liu, Feng-Hao and Wang, Han",
    "abstract": "This work introduces KsPIR, a new practically efficient single-server private information retrieval (PIR) system that outperforms the state-of-the-art Spiral (Menon and Wu, S&P 2022) in terms of server response times. We achieve this by proposing novel dimension folding methods, inspired by recent advancements in fully homomorphic encryption. Our methods offer two significant advantages: firstly, they feature simpler designs that eliminate the need for ciphertext expansion steps in Spiral. Secondly, and more importantly, we propose two types of designs that offer distinct advantages - the first type enables preprocessing of the most resource-intensive computation in the offline stage before receiving the query, thereby optimizing online response time; the second type optimizes overall response time without requiring preprocessing in the offline stage, accomplished through a highly optimized baby-step-giant-step matrix-vector homomorphic multiplication.We conduct comprehensive experiments to evaluate the concrete performance of KsPIR, and the results confirm an approximately 10.7 times faster online throughput than that of Spiral for the first type, and 5.8 times faster overall throughput for the second type.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690233",
    "comment": ""
  },
  {
    "title": "Simple and Practical Amortized Sublinear Private Information Retrieval using Dummy Subsets",
    "author": "Ren, Ling and Mughees, Muhammad Haris and Sun, I",
    "abstract": "Recent works in amortized sublinear Private Information Retrieval (PIR) have demonstrated great potential. Despite the inspiring progress, existing schemes in this new paradigm are still faced with various challenges and bottlenecks, including large client storage, high communication, poor practical efficiency, need for non-colluding servers, or restricted client query sequences. We present simple and practical amortized sublinear stateful private information retrieval schemes without these drawbacks using new techniques in hint construction and usage. In particular, we introduce a dummy set to the client's request to eliminate any leakage or correctness failures. Our techniques can work with two non-colluding servers or a single server. The resulting PIR schemes achieve practical efficiency. The online response overhead is only twice that of simply fetching the desired entry without privacy. For a database with 2^28 entries of 32-byte, each query of our two-server scheme consumes 34 KB of communication and 2.7 milliseconds of computation, and each query of our single-server scheme consumes amortized 47 KB of communication and 4.5 milliseconds of computation. These results are one or more orders of magnitude better than prior works.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690266",
    "comment": ""
  },
  {
    "title": "Unbalanced Private Set Union with Reduced Computation and Communication",
    "author": "Zhang, Cong and Chen, Yu and Liu, Weiran and Peng, Liqiang and Hao, Meng and Wang, Anyu and Wang, Xiaoyun",
    "abstract": "Private set union (PSU) is a cryptographic protocol that allows two parties to compute the union of their sets without revealing anything else. Despite some efficient PSU protocols that have been proposed, they mainly focus on the balanced setting, where the sets held by the parties are of similar size. Recently, Tu et al. (CCS 2023) proposed the first unbalanced PSU protocol which achieves sublinear communication complexity in the size of the larger set.  In this paper, we are interested in improving the efficiency of the unbalanced PSU protocol. We find that oblivious key-value store (OKVS) data structure plays an essential role in the most recently proposed PSU constructions and formalize unbalanced PSU as an OKVS decoding process with sublinear communication. Our key insight lies in when OKVS satisfies sparsity property, obtaining the necessary decoding information precisely aligns with the batch private information retrieval (BatchPIR) problem. We give two concrete constructions of unbalanced PSU protocols based on different OKVS encoding strategies. The first is based on oblivious PRF (OPRF) and a newly introduced cryptographic protocol called permuted private equality test, while the second is based on re-randomizable public key encryption. Both our two constructions achieve sublinear communication complexity in the size of the larger set.  We implement our two unbalanced PSU protocols and compare them with the state-of-the-art unbalanced PSU of Tu et al. Experiments show that our protocols achieve a 1.3-5.6times speedup in running time and 2.1-11.8\\texttimes{} shrinking in communication cost, depending on set sizes and network environments.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690308",
    "comment": ""
  },
  {
    "title": "ThorPIR: Single Server PIR via Homomorphic Thorp Shuffles",
    "author": "Fisch, Ben and Lazzaretti, Arthur and Liu, Zeyu and Papamanthou, Charalampos",
    "abstract": "Private Information Retrieval (PIR) is a two player protocol where the client, given some query x ε [N], interacts with the server, which holds a N-bit string DB, in order to privately retrieve DB[x]. In this work, we focus on the single-server client-preprocessing model, initially proposed by Corrigan-Gibbs and Kogan (EUROCRYPT 2020), where the client and server first run a joint preprocessing algorithm, after which the client can retrieve elements from DB privately in time sublinear in N. Most known constructions of single-server client-preprocessing PIR follow one of two paradigms: They feature either (1) a linear-bandwidth offline phase where the client downloads the whole database from the server, or (2) a sublinear-bandwidth offline phase where however the server has to compute a large-depth (Ωλ(N)) circuit under fully-homomorphic encryption (FHE) in order to execute the preprocessing phase.In this paper, we propose ThorPIR, a single-server client preprocessing PIR scheme which achieves both sublinear offline bandwidth (asymptotically and concretely) and a low-depth, highly parallelizable preprocessing circuit. Our main insight is to use and significantly optimize the concrete circuit-depth of a much more efficient shuffling technique needed during preprocessing, called Thorp shuffle. A Thorp shuffle satisfies a weaker security property (e.g., compared to an AES permutation) which is ''just enough'' for our construction. We estimate that with a powerful server (e.g., hundreds of thousands of GPUs), ThorPIR's end-to-end preprocessing time is faster than any prior work. Additionally, compared to prior FHE-based works with sublinear bandwidth, our construction is at least around 10,000 times faster.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690326",
    "comment": ""
  },
  {
    "title": "Respire: High-Rate PIR for Databases with Small Records",
    "author": "Burton, Alexander and Menon, Samir Jordan and Wu, David J.",
    "abstract": "Private information retrieval (PIR) is a key building block in many privacy-preserving systems, and recent works have made significant progress on reducing the concrete computational costs of single-server PIR. However, existing constructions have high communication overhead, especially for databases with small records. In this work, we introduce Respire, a lattice-based PIR scheme tailored for databases of small records. To retrieve a single record from a database with over a million 256-byte records, the Respire protocol requires just 6.1 KB of online communication; this is a 5.9x reduction compared to the best previous lattice-based scheme. Moreover, Respire naturally extends to support batch queries. Compared to previous communication-efficient batch PIR schemes, Respire achieves a 3.4-7.1x reduction in total communication while maintaining comparable throughput (200-400 MB/s). The design of Respire relies on new query compression and response packing techniques based on ring switching in homomorphic encryption.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690328",
    "comment": ""
  },
  {
    "title": "Actively Secure Private Set Intersection in the Client-Server Setting",
    "author": "Sun, Yunqing and Katz, Jonathan and Raykova, Mariana and Schoppmann, Phillipp and Wang, Xiao",
    "abstract": "Private set intersection (PSI) allows two parties to compute the intersection of their sets without revealing anything else. In some applications of PSI, a server holds a large set and runs a PSI protocol with multiple clients, each with its own smaller set. In this setting, existing protocols fall short: they either achieve only semi-honest security, or else require the server to run the protocol from scratch for each execution.We design an efficient protocol for this setting with simulation-based security against malicious adversaries. In our protocol, the server publishes a one-time, linear-size encoding of its set. Then, multiple clients can independently execute a PSI protocol with the server, with complexity linear in the size of each client's set. To learn the intersection, a client can download the server's encoding, which can be accelerated via content-distribution or peer-to-peer networks since the same encoding is used by all clients; alternatively, clients can fetch only the relevant parts of the encoding using verifiable private information retrieval. A key ingredient of our protocol is an efficient instantiation of an oblivious verifiable unpredictable function, which may be of independent interest.Our implementation shows that our protocol is highly efficient. For a server holding 108 elements and each client holding 103 elements, the size of the server's encoding is 800MB; an execution of the protocol uses 60MB of communication, runs in under 5s in a WAN network with 120 Mbps bandwidth, and costs only 0.017 USD when utilizing network-caching infrastructures, a 5\\texttimes{} saving compared to a state-of-the-art PSI protocol.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690349",
    "comment": ""
  },
  {
    "title": "Functional Adaptor Signatures: Beyond All-or-Nothing Blockchain-based Payments",
    "author": "Vanjani, Nikhil and Soni, Pratik and Thyagarajan, Sri AravindaKrishnan",
    "abstract": "In scenarios where a seller holds sensitive data x, like employee / patient records or ecological data, and a buyer seeks to obtain an evaluation of specific function f on this data, solutions in trustless digital environments like blockchain-based Web3 systems typically fall into two categories: (1) Smart contract-powered solutions and (2) cryptographic solutions leveraging tools such as adaptor signatures. The former approach offers atomic transactions where the buyer learns the function evaluation f(x) (and not x entirely) upon payment. However, this approach is often inefficient, costly, lacks privacy for the seller's data, and is incompatible with systems that do not support smart contracts with required functionalities. In contrast, the adaptor signature-based approach addresses all of the above issues but comes with an \"all-or-nothing\" guarantee, where the buyer fully extracts x and does not support functional extraction of the sensitive data. In this work, we aim to bridge the gap between these approaches, developing a solution that enables fair functional sales of information while offering improved efficiency, privacy, and compatibility similar to adaptor signatures.Towards this, we propose functional adaptor signatures (FAS) a novel cryptographic primitive that achieves all the desired properties as listed above. Using FAS, the seller can publish an advertisement committing to x. The buyer can pre-sign the payment transaction w.r.t. a function f, and send it along with the transaction to the seller. The seller adapts the pre-signature into a valid (buyer's) signature and posts the payment and the adapted signature on the blockchain to get paid. Finally, using the pre-signature and the posted signature, the buyer efficiently extracts f(x), and completes the sale. We formalize the security properties of FAS, among which is a new notion called witness privacy to capture seller's privacy, which ensures the buyer does not learn anything beyond f(x). We present multiple variants of witness privacy, namely, witness hiding, witness indistinguishability, and zero-knowledge, to capture varying levels of leakage about x beyond f(x) to a malicious buyer.We introduce two efficient constructions of FAS supporting linear functions (like statistics/aggregates, kernels in machine learning, etc.), that satisfy the strongest notion of witness privacy. One construction is based on prime-order groups and compatible with Schnorr signatures for payments, and the other is based on lattices and compatible with a variant of Lyubashevsky's signature scheme. A central conceptual contribution of our work lies in revealing a surprising connection between functional encryption, a well-explored concept over the past decade, and adaptor signatures, a relatively new primitive in the cryptographic landscape. On a technical level, we avoid heavy cryptographic machinery and achieve improved efficiency, by making black-box use of building blocks like inner product functional encryption (IPFE) while relying on certain security-enhancing techniques for the IPFE in a non-black-box manner. We implement our FAS construction for Schnorr signatures and show that for reasonably sized seller witnesses, the different operations are quite efficient even for commodity hardware.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690240",
    "comment": ""
  },
  {
    "title": "Blind Multisignatures for Anonymous Tokens with Decentralized Issuance",
    "author": "Karantaidou, Ioanna and Renawi, Omar and Baldimtsi, Foteini and Kamarinakis, Nikolaos and Katz, Jonathan and Loss, Julian",
    "abstract": "We propose the first constructions of anonymous tokens with decentralized issuance. Namely, we consider a dynamic set of signers/issuers; a user can obtain a token from any subset of the signers, which is publicly verifiable and unlinkable to the issuance process. To realize this new primitive we formalize the notion of blind multi-signatures (BMS), which allow a user to interact with multiple signers to obtain a (compact) signature; even if all the signers collude they are unable to link a signature to an interaction with any of them. We then present two BMS constructions, one based on BLS signatures and a second based on discrete logarithms without pairings. We prove security of both our constructions in the Algebraic Group Model. We also provide a proof-of-concept implementation and show that it has low-cost verification, which is the most critical operation in blockchain applications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690364",
    "comment": ""
  },
  {
    "title": "Practical Post-Quantum Signatures for Privacy",
    "author": "Argo, Sven and G\\\"{u}neysu, Tim and Jeudy, Corentin and Land, Georg and Roux-Langlois, Adeline and Sanders, Olivier",
    "abstract": "The transition to post-quantum cryptography has been an enormous challenge and effort for cryptographers over the last decade, with impressive results such as the future NIST standards. However, the latter has so far only considered central cryptographic mechanisms (signatures or KEM) and not more advanced ones, e.g., targeting privacy-preserving applications. Of particular interest is the family of solutions called blind signatures, group signatures and anonymous credentials, for which standards already exist, and which are deployed in billions of devices. Such a family does not have, at this stage, an efficient post-quantum counterpart although very recent works improved this state of affairs by offering two different alternatives: either one gets a system with rather large elements but a security proved under standard assumptions or one gets a more efficient system at the cost of ad-hoc interactive assumptions or weaker security models. Moreover, all these works have only considered size complexity without implementing the quite complex building blocks their systems are composed of. In other words, the practicality of such systems is still very hard to assess, which is a problem if one envisions a post-quantum transition for the corresponding systems/standards.In this work, we propose a construction of so-called signature with efficient protocols (SEP), which is the core of such privacy-preserving solutions. By revisiting the approach by Jeudy et al. (Crypto 2023) we manage to get the best of the two alternatives mentioned above, namely short sizes with no compromise on security. To demonstrate this, we plug our SEP in an anonymous credential system, achieving credentials of less than 80 KB. In parallel, we fully implemented our system, and in particular the complex zero-knowledge framework of Lyubashevsky et al. (Crypto'22), which has, to our knowledge, not be done so far. Our work thus not only improves the state-of-the-art on privacy-preserving solutions, but also significantly improves the understanding of efficiency and implications for deployment in real-world systems.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670297",
    "comment": ""
  },
  {
    "title": "Reckle Trees: Updatable Merkle Batch Proofs with Applications",
    "author": "Papamanthou, Charalampos and Srinivasan, Shravan and Gailly, Nicolas and Hishon-Rezaizadeh, Ismael and Salumets, Andrus and Golemac, Stjepan",
    "abstract": "We propose Reckle trees, a new vector commitment based on succinct RECursive arguments and MerKLE trees. Reckle trees' distinguishing feature is their support for succinct batch proofs that are updatable - enabling new applications in the blockchain setting where a proof needs to be computed and efficiently maintained over a moving stream of blocks. Our technical approach is based on embedding the computation of the batch hash inside the recursive Merkle verification via a hash-based accumulator called canonical hashing. Due to this embedding, our batch proofs can be updated in logarithmic time, whenever a Merkle leaf (belonging to the batch or not) changes, by maintaining a data structure that stores previously-computed recursive proofs. Assuming enough parallelism, our batch proofs are also computable in O(log n) parallel time - independent of the size of the batch. As a natural extension of Reckle trees, we also introduce Reckle+ trees. Reckle+ trees provide updatable and succinct proofs for certain types of Map/Reduce computations. In this setting, a prover can commit to a memory M and produce a succinct proof for a Map/Reduce computation over a subset I of M. The proof can be efficiently updated whenever I or M changes.We present and experimentally evaluate two applications of Reckle+ trees, dynamic digest translation and updatable BLS aggregation. In dynamic digest translation we are maintaining a proof of equivalence between Merkle digests computed with different hash functions, e.g., one with a SNARK-friendly Poseidon and the other with a SNARK-unfriendly Keccak. In updatable BLS aggregation we maintain a proof for the correct aggregation of a t-aggregate BLS key, derived from a t-subset of a Merkle-committed set of individual BLS keys. Our evaluation using Plonky2 shows that Reckle trees and Reckle+ trees have small memory footprint, significantly outperform previous approaches in terms of updates (10\\texttimes{} to 15\\texttimes{}) and verification (4.78\\texttimes{} to 1485\\texttimes{}) time, enable applications that were not possible before due to huge costs involved (Reckle trees are up to 200\\texttimes{} faster), and have similar aggregation performance with previous implementations of batch proofs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670354",
    "comment": ""
  },
  {
    "title": "Provable Security for PKI Schemes",
    "author": "Wr\\'{o}tniak, Sara and Leibowitz, Hemi and Syta, Ewa and Herzberg, Amir",
    "abstract": "PKI schemes provide a critical foundation for applied cryptographic protocols. However, there are no rigorous security specifications for realistic PKI schemes, and therefore, no PKI schemes were proven secure. Cryptographic systems that use PKI are analyzed by adopting overly simplified models of PKI, often simply assuming securely-distributed public keys. This is problematic given the extensive reliance on PKI, the multiple failures of PKI systems, and the complexity of both proposed and deployed systems, which involve complex requirements and models.We present game-based security specifications for PKI schemes and analyze important and widely deployed PKIs: PKIX and two variants of Certificate Transparency (CT). These PKIs are based on the X.509v3 standard and its CRL revocation mechanism. Our analysis identified a few subtle vulnerabilities and provides reduction-based proofs showing that the PKIs ensure specific requirements under specific models (assumptions). To our knowledge, this is the first reduction-based proof of security for a realistic PKI scheme, e.g., supporting certificate chains.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670374",
    "comment": ""
  },
  {
    "title": "Fast Two-party Threshold ECDSA with Proactive Security",
    "author": "Koziel, Brian and Gordon, S. Dov and Gentry, Craig",
    "abstract": "We present a new construction of two-party, threshold ECDSA, building on a 2017 scheme of Lindell and improving his scheme in several ways.ECDSA signing is notoriously hard to distribute securely, due to non-linearities in the signing function. Lindell's scheme uses Paillier encryption to encrypt one party's key share and handle these non-linearities homomorphically, while elegantly avoiding any expensive zero knowledge proofs over the Paillier group during the signing process. However, the scheme pushes that complexity into key generation. Moreover, avoiding ZK proofs about Paillier ciphertexts during signing comes with a steep price -- namely, the scheme requires a \"global abort\" when a malformed ciphertext is detected, after which an entirely new key must be generated.We overcome all of these issues with a proactive Refresh procedure. Since the Paillier decryption key is part of the secret that must be proactively refreshed, our first improvement is to radically accelerate key generation by replacing one of Lindell's ZK proofs -- which requires 80 Paillier ciphertexts for statistical security 2-40 -- with a much faster \"weak\" proof that requires only 2 Paillier ciphertexts, and which proves a weaker statement about a Paillier ciphertext that we show is sufficient in the context of our scheme. Secondly, our more efficient key generation procedure also makes frequent proactive Refreshes practical. Finally, we show that adding noise to one party's key share suffices to avoid the need to reset the public verification key when certain bad behavior is detected. Instead, we prove that our Refresh procedure, performed after each detection, suffices for addressing the attack, allowing the system to continue functioning without disruption to applications that rely on the verification key.Our scheme is also very efficient, competitive with the best constructions that do not provide proactive security, and state-of-the-art among the few results that do. Our optimizations to ECDSA key generation speed up runtime and improve bandwidth over Lindell's key generation by factors of 7 and 13, respectively. Our Key Generation protocol requires 20\\% less bandwidth than existing constructions, completes in only 3 protocol messages, and executes much faster than all but OT-based key generation. For ECDSA signing, our extra Refresh protocol does add a 10X latency and 5X bandwidth overhead compared to Lindell. However, this still fits in 150 ms runtime and about 5.4 KB of messages when run in our AWS cluster benchmark.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670387",
    "comment": ""
  },
  {
    "title": "Are We Getting Well-informed? An In-depth Study of Runtime Privacy Notice Practice in Mobile Apps",
    "author": "Li, Shuai and Yang, Zhemin and Nan, Yuhong and Yu, Shutian and Zhu, Qirui and Yang, Min",
    "abstract": "Under the General Data Protection Regulation (GDPR), mobile app developers are required to inform users of necessary information at the time when user data is collected (called users' \"Right-to-be-Informed\"). This is typically done by app developers via providing runtime privacy notices (RPNs for short). However, given the heterogeneous privacy data types and data access patterns in modern apps, it is not clear to what extent apps (app developers) effectively fulfill this compliance requirement in practice.In this paper, we perform the first systematic study of current RPN practices in mobile apps. Our research endeavors to comprehend (1) the ecosystem of RPN, (2) potential gaps between legal requirements and RPN practices, and (3) the underlying reasons for such gaps. To achieve this, we design an automated pipeline - RENO that can effectively identify, extract, and analyze RPN at a large scale. With the help of RENO, we investigated 4,656 mobile apps selected from 19 European Union countries. Our analysis reveals a number of interesting findings. For example, 77.10\\% of user data collection behaviors lack RPNs. Among those provided RPNs, 86.35\\% of them have no more than three required notice elements when GDPR requires seven. In addition, to further understand the reasons behind such gaps, we perform a notification campaign and ask for feedback from the app developers. Indeed, the collected responses highlighted several critical reasons. For instance, a substantial proportion of app developers regard RPN as an optional complement to their privacy policies as RPNs are not strictly enforced by app stores. Our study shows the pressing need for better transparency in user data collection delivered by RPN.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670377",
    "comment": ""
  },
  {
    "title": "Graphical vs. Deep Generative Models: Measuring the Impact of Differentially Private Mechanisms and Budgets on Utility",
    "author": "Ganev, Georgi and Xu, Kai and De Cristofaro, Emiliano",
    "abstract": "Generative models trained with Differential Privacy (DP) can produce synthetic data while reducing privacy risks. However, navigating their privacy-utility tradeoffs makes finding the best models for specific settings/tasks challenging. This paper bridges this gap by profiling how DP generative models for tabular data distribute privacy budgets across rows and columns, which is one of the primary sources of utility degradation. We compare graphical and deep generative models, focusing on the key factors contributing to how privacy budgets are spent, i.e., underlying modeling techniques, DP mechanisms, and data dimensionality.Through our measurement study, we shed light on the characteristics that make different models suitable for various settings and tasks. For instance, we find that graphical models distribute privacy budgets horizontally and thus cannot handle relatively wide datasets for a fixed training time; also, the performance on the task they were optimized for monotonically increases with more data but could also overfit. Deep generative models spend their budgets per iteration, so their behavior is less predictable with varying dataset dimensions, but are more flexible as they could perform better if trained on more features. Moreover, low levels of privacy (ε≥100) could help some models generalize, achieving better results than without applying DP. We believe our work will aid the deployment of DP synthetic data techniques by navigating through the best candidate models vis-\\`{a}-vis the dataset features, desired privacy levels, and downstream tasks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690215",
    "comment": ""
  },
  {
    "title": "A Qualitative Analysis of Practical De-Identification Guides",
    "author": "Guo, Wentao and Kishore, Aditya and Aviv, Adam J. and Mazurek, Michelle L.",
    "abstract": "De-identifying microdata is necessary yet difficult. Myriad techniques exist, which reduce risk and preserve utility to varying, often unclear extents. We conducted a thematic analysis of 38 online de-identification guides for practitioners, to understand what content they contain and how they are designed to support decision-making and execution. We highlight trends and differences between guides, and we find some concerning patterns, including inconsistent definitions of key terms, gaps in coverage of threats to de-identification, and areas for improvement in usability. We identify directions for future research and suggest changes to de-identification guidance in order to better support practitioners in conducting effective de-identification.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690270",
    "comment": ""
  },
  {
    "title": "A First Look at Security and Privacy Risks in the RapidAPI Ecosystem",
    "author": "Liao, Song and Cheng, Long and Luo, Xiapu and Song, Zheng and Cai, Haipeng and Yao, Danfeng (Daphne) and Hu, Hongxin",
    "abstract": "With the emergence of the open API ecosystem, third-party developers can publish their APIs on the API marketplace, significantly facilitating the development of cutting-edge features and services. The RapidAPI platform is currently the largest API marketplace and it provides over 40,000 APIs, which have been used by more than 4 million developers. However, such open API also raises security and privacy concerns associated with APIs hosted on the platform. In this work, we perform the first large-scale analysis of 32,089 APIs on the RapidAPI platform. By searching in the GitHub code and Android apps, we find that 3,533 RapidAPI keys, which are important and used in API request authorization, have been leaked in the wild. These keys can be exploited to launch various attacks, such as Resource Exhaustion Running, Theft of Service, Data Manipulation, and User Data Breach attacks. We also explore risks in API metadata that can be abused by adversaries. Due to the lack of a strict certification system, adversaries can manipulate the API metadata to perform typosquatting attacks on API URLs, impersonate other developers or renowned companies, and publish spamming APIs on the platform. Lastly, we analyze the privacy non-compliance of APIs and applications, e.g., Android apps, that call these APIs with data collection. We find that 1,709 APIs collect sensitive data and 94\\% of them dont provide a complete privacy policy. For the Android apps that call these APIs, 50\\% of them in our study have privacy non-compliance issues.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690294",
    "comment": ""
  },
  {
    "title": "Measuring Compliance Implications of Third-party Libraries' Privacy Label Disclosure Guidelines",
    "author": "Xiao, Yue and Zhang, Chaoqi and Qin, Yue and Alharbi, Fares Fahad S and Xing, Luyi and Liao, Xiaojing",
    "abstract": "Privacy label disclosure guideline, which specifies the data usage practices of third-party libraries (TPL), is a valuable resource for iOS app developers to accurately complete their iOS privacy labels. This is particularly important given the mandatory requirement for all apps on the App Store to disclose their data practices via privacy labels. However, it is essential to ensure the accuracy and compliance of these guidelines to ensure that accurate TPL data usage has been provided to app developers. Despite the significance of these guidelines, there is little understanding of how accurate and compliant they are in reflecting the actual data practices of third-party libraries used in iOS apps. To address this issue, our study implements a tool called Colaine to automatically check the compliance of privacy label disclosure guidelines, taking into account the configurable data practices in TPLs. Colaine analyzed 107 TPLs associated with 1,605 different configurations, shedding light on the prevalence and seriousness of privacy label disclosure guideline non-compliance issues.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670371",
    "comment": ""
  },
  {
    "title": "Trust, Because You Can't Verify: Privacy and Security Hurdles in Education Technology Acquisition Practices",
    "author": "Kelso, Easton and Soneji, Ananta and Rahaman, Sazzadur and Shoshitaishvili, Yan and Hasan, Rakibul",
    "abstract": "The education technology (EdTech) landscape is expanding rapidly in higher education institutes (HEIs). This growth brings enormous complexity. Protecting the extensive data collected by these tools is crucial for HEIs as data breaches and misuses can have dire security and privacy consequences for the data subjects, particularly students, who are often compelled to use these tools. This urges an in-depth understanding of HEI and EdTech vendor dynamics, which is largely understudied.To address this gap, we conducted a semi-structured interview study with 13 participants who are in EdTech leadership roles at seven HEIs. Our study uncovers the EdTech acquisition process in the HEI context, the consideration of security and privacy issues throughout that process, the pain points of HEI personnel in establishing adequate protection mechanisms in service contracts, and their struggle in holding vendors accountable due to a lack of visibility into their system and power-asymmetry, among other reasons. We discuss certain observations about the status quo and conclude with recommendations for HEIs, researchers, and regulatory bodies to improve the situation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690353",
    "comment": ""
  },
  {
    "title": "\"Do Anything Now\": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models",
    "author": "Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang",
    "abstract": "The misuse of large language models (LLMs) has drawn significant attention from the general public and LLM vendors. One particular type of adversarial prompt, known as jailbreak prompt, has emerged as the main attack vector to bypass the safeguards and elicit harmful content from LLMs. In this paper, employing our new framework JailbreakHub, we conduct a comprehensive analysis of 1,405 jailbreak prompts spanning from December 2022 to December 2023. We identify 131 jailbreak communities and discover unique characteristics of jailbreak prompts and their major attack strategies, such as prompt injection and privilege escalation. We also observe that jailbreak prompts increasingly shift from online Web communities to prompt-aggregation websites and 28 user accounts have consistently optimized jailbreak prompts over 100 days. To assess the potential harm caused by jailbreak prompts, we create a question set comprising 107,250 samples across 13 forbidden scenarios. Leveraging this dataset, our experiments on six popular LLMs show that their safeguards cannot adequately defend jailbreak prompts in all scenarios. Particularly, we identify five highly effective jailbreak prompts that achieve 0.95 attack success rates on ChatGPT (GPT-3.5) and GPT-4, and the earliest one has persisted online for over 240 days. We hope that our study can facilitate the research community and LLM vendors in promoting safer and regulated LLMs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670388",
    "comment": ""
  },
  {
    "title": "Breaching Security Keys without Root: FIDO2 Deception Attacks via Overlays exploiting Limited Display Authenticators",
    "author": "Mahdad, Ahmed Tanvir and Jubur, Mohammed and Saxena, Nitesh",
    "abstract": "Two-factor authentication (2FA) systems aim to secure user accounts, provided that either the password or the second factor device remains uncompromised. However, in this research, we challenge this perception and analyze the security of FIDO2 hardware security keys, which are increasingly used in 2FA and passwordless systems. Specifically, we develop an attack framework, analyze the underlying protocols of FIDO2, and examine the associated OS-level security. Through practical demonstrations, we illustrate how adversaries can exploit this framework and OS-level security measures to execute our designed attack, known as FIDOLA (<u>FI</u>DO2 <u>D</u>eception Attack via <u>O</u>verlays exploiting <u>L</u>imited Display <u>A</u>uthenticators).Our attack framework injects hidden login sessions, either into the same service the user intends to authenticate with or into a different service. It deceives users into approving the attackers request using the limited display of authenticators. This cross-service attack raises concerns about compromising more sensitive accounts (e.g., financial) when users log into less sensitive ones. Our attack poses a practical and fundamental threat not addressed in the FIDO specification or prior research. Unlike prior research, our demonstration exposes FIDO2 authenticator vulnerabilities in real-world 2FA and passwordless setups, where OS-level security mitigates traditional concurrent attacks (simultaneous authentication attempts by the attacker). To assess our attacks effectiveness, we conducted a user study, revealing that users approved approximately 95.55\\% of cross-service attacks when presented with a screen overlay.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690286",
    "comment": ""
  },
  {
    "title": "The Not-So-Silent Type: Vulnerabilities in Chinese IME Keyboards' Network Security Protocols",
    "author": "Knockel, Jeffrey and Wang, Mona and Reichert, Zo\\\"{e}",
    "abstract": "Popular Chinese Input Method Editor (IME) keyboards almost universally feature cloud-based features that improve character prediction when typing. Handling such sensitive data (i.e., keystrokes) in transit demands security in transit. In this work, we perform a comprehensive security measurement of the Chinese IME keyboard ecosystem, investigating the network security of keystrokes sent in transit by popular Chinese IME keyboards from nine vendors. We studied the three most popular third-party keyboards, comprising 95.9\\% of the third-party keyboard market share in China, as well as the default Chinese IME keyboards pre-installed on six popular Android mobile device manufacturers in China. We found that the vast majority of IME keyboards utilize proprietary, non-TLS network encryption protocols. Our measurement revealed critical vulnerabilities in these encryption protocols from eight out of the nine vendors in which network attackers could completely reveal the contents of users' keystrokes in transit. We estimate that up to one billion users were affected by these vulnerabilities. Finally, we provide recommendations to various stakeholders to limit the harm from this existing set of vulnerabilities, as well as to prevent future vulnerabilities of this kind.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690302",
    "comment": ""
  },
  {
    "title": "Demystifying RCE Vulnerabilities in LLM-Integrated Apps",
    "author": "Liu, Tong and Deng, Zizhuang and Meng, Guozhu and Li, Yuekang and Chen, Kai",
    "abstract": "Large Language Models (LLMs) show promise in transforming software development, with a growing interest in integrating them into more intelligent apps. Frameworks like LangChain aid LLM-integrated app development, offering code execution utility/APIs for custom actions. However, these capabilities theoretically introduce Remote Code Execution (RCE) vulnerabilities, enabling remote code execution through prompt injections. No prior research systematically investigates these frameworks' RCE vulnerabilities or their impact on applications and exploitation consequences. Therefore, there is a huge research gap in this field.In this study, we propose LLMSmith to detect, validate and exploit the RCE vulnerabilities in LLM-integrated frameworks and apps. To achieve this goal, we develop two novel techniques, including 1) a lightweight static analysis to construct call chains to identify RCE vulnerabilities in frameworks; 2) a systematical prompt-based exploitation method to verify and exploit the found vulnerabilities in LLM-integrated apps. This technique involves various strategies to control LLM outputs, trigger RCE vulnerabilities and launch subsequent attacks. Our research has uncovered a total of 20 vulnerabilities in 11 LLM-integrated frameworks, comprising 19 RCE vulnerabilities and 1 arbitrary file read/write vulnerability. Of these, 17 have been confirmed by the framework developers, with 13 vulnerabilities being assigned CVE IDs, 6 of which have a CVSS score of 9.8, and we were also awarded a bug bounty of 1350. For the 51 apps potentially affected by RCE, we successfully executed attacks on 17 apps, 16 of which are vulnerable to RCE and 1 to SQL injection. Furthermore, we conduct a comprehensive analysis of these vulnerabilities and construct practical attacks to demonstrate the hazards in reality, e.g., app output hijacking, user data leakage, even the potential to take full control of systems. Last, we propose several mitigation measures for both framework and app developers to counteract such attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690338",
    "comment": ""
  },
  {
    "title": "GAZEploit: Remote Keystroke Inference Attack by Gaze Estimation from Avatar Views in VR/MR Devices",
    "author": "Wang, Hanqiu and Zhan, Zihao and Shan, Haoqi and Dai, Siqi and Panoff, Maximilian and Wang, Shuo",
    "abstract": "The advent and growing popularity of Virtual Reality (VR) and Mixed Reality (MR) solutions have revolutionized the way we interact with digital platforms. The cutting-edge gaze-controlled typing methods, now prevalent in high-end models of these devices, e.g., Apple Vision Pro, have not only improved user experience but also mitigated traditional keystroke inference attacks that relied on hand gestures, head movements and acoustic side-channels. However, this advancement has paradoxically given birth to a new, potentially more insidious cyber threat, GAZEploit.  In this paper, we unveil GAZEploit, a novel eye-tracking based attack specifically designed to exploit these eye-tracking information by leveraging the common use of virtual appearances in VR applications. This widespread usage significantly enhances the practicality and feasibility of our attack compared to existing methods. GAZEploit takes advantage of this vulnerability to remotely extract gaze estimations and steal sensitive keystroke information across various typing scenarios-including messages, passwords, URLs, emails, and passcodes. Our research, involving 30 participants, achieved over 80\\% accuracy in keystroke inference. Alarmingly, our study also identified over 15 top-rated apps in the Apple Store as vulnerable to the GAZEploit attack, emphasizing the urgent need for bolstered security measures for this state-of-the-art VR/MR text entry method.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690285",
    "comment": ""
  },
  {
    "title": "VPVet: Vetting Privacy Policies of Virtual Reality Apps",
    "author": "Zhan, Yuxia and Meng, Yan and Zhou, Lu and Xiong, Yichang and Zhang, Xiaokuan and Ma, Lichuan and Chen, Guoxing and Pei, Qingqi and Zhu, Haojin",
    "abstract": "Virtual reality (VR) apps can harvest a wider range of user data than web/mobile apps running on personal computers or smartphones. Existing law and privacy regulations emphasize that VR developers should inform users of what data are collected/used/shared (CUS) through privacy policies. However, privacy policies in the VR ecosystem are still in their early stages, and many developers fail to write appropriate privacy policies that comply with regulations and meet user expectations. In this paper, we propose VPVet to automatically vet privacy policy compliance issues for VR apps. VPVet first analyzes the availability and completeness of a VR privacy policy and then refines its analysis based on three key criteria: granularity, minimization, and consistency of CUS statements. Our study establishes the first and currently largest VR privacy policy dataset named VRPP, consisting of privacy policies of 11,923 different VR apps from 10 mainstream platforms. Our vetting results reveal severe privacy issues within the VR ecosystem, including the limited availability and poor quality of privacy policies, along with their coarse granularity, lack of adaptation to VR traits and the inconsistency between CUS statements in privacy policies and their actual behaviors. We open-source VPVet system along with our findings at repository https://github.com/kalamoo/PPAudit, aiming to raise awareness within the VR community and pave the way for further research in this field.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690321",
    "comment": ""
  },
  {
    "title": "Collapse Like A House of Cards: Hacking Building Automation System Through Fuzzing",
    "author": "Zhang, Yue and Ling, Zhen and Cash, Michael and Zhang, Qiguang and Morales-Gonzalez, Christopher and Sun, Qun Zhou and Fu, Xinwen",
    "abstract": "Building Automation Systems (BAS) play a pivotal role in modern smart buildings, integrating sensors, controllers, and software to manage crucial functions such as HVAC, lighting, and more. The global smart building market is on the rise, underscoring the importance of securing BAS networks. This paper introduces the Building Automation System Evaluator (BASE), a specialized fuzzer designed to assess the security of BAS networks. BAS networks typically involve a BAS client communicating with a BAS server through BAS protocols (e.g., BACnet, KNX), each presenting unique challenges in BAS network fuzzing. These challenges encompass complex packet structures and sequencing in BAS protocols, closed-source clients with indeterminable code coverage, and unobservable server status with limited throughput. BASE automatically identifies protocol structures, dynamically instruments clients for code coverage analysis, and monitors responses for new coverage areas. Collected timestamps are used to estimate the input scan intervals of servers, optimizing throughput. We evaluated BASE on various BAS servers and clients, uncovering 13 new vulnerabilities. Furthermore, we present three attack case studies, highlighting the real-world security implications of these vulnerabilities in BAS systems, such as delayed fire detection, loss of climate control, and security breaches. We reported our findings to the respective vendors, who acknowledged the implications, and some have subsequently patched their systems based on our reports.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690216",
    "comment": ""
  },
  {
    "title": "Watch the Rhythm: Breaking Privacy with Accelerometer at the Extremely-Low Sampling Rate of 5Hz",
    "author": "Yao, Qingsong and Liu, Yuming and Sun, Xiongjia and Dong, Xuewen and Ji, Xiaoyu and Ma, Jianfeng",
    "abstract": "Considering the threat from on-board eavesdropping with smartphone motion sensors, Android 12 has limited the maximum sampling rate of motion sensors to 200Hz for zero-privilege access to prevent potential wiretapping. Unfortunately, there have been some attacks targeting 200Hz, making it not a safe sampling rate any more. Smartphone manufacturers may further reduce the maximum sampling rate of the accelerometer in response to this privacy concern. It can be expected that, the maximum sampling rate will gradually decrease to a very low level, as the battle between manufacturers and adversaries continues. Existing on-board eavesdropping approaches, utilizing spectral features, cannot provide acceptable accuracy at very low sampling rates, not even at 50Hz.Therefore, this paper explores the feasibility of using the on-board accelerometer for privacy breaking with an extremely-low sampling rate, specifically, 5Hz. 5Hz is a minimum sampling rate to meet normal use, otherwise the applications can only choose to work without the accelerometer. Since the lowest fundamental frequency for humans is around 85Hz, such a low sampling rate poses a significant challenge for sound recognition. According to Nyquist's law, it seems impossible to capture 85Hz with the sampling rate of 5Hz. Fortunately, we observe that the rhythm features, including pause rhythm and intensity rhythm, of accelerometer data are relatively stable at various sampling rates. On this basis, we propose an eavesdropping approach with the accelerometer at an extremely-low sampling rate. Introducing the rhythm features, we achieve an accuracy of 95.09\\% at 50Hz and 78.66\\% at 5Hz for scene recognition. The accuracy is 90.60\\% at 50Hz and 47\\% at 5Hz for Chinese digits recognition, plus 96.63\\% at 50Hz and 58.67\\% at 5Hz for popular Chinese cities recognition. Furthermore, we achieve determination for typical places like bar, metro, bus, car, and quiet room, by analyzing the vibration of surroundings, with an average accuracy of 91.28\\%. Combining place determination with eavesdropping, our approach poses a serious threat to personal privacy. Since 5Hz is generally used for screen orientation detection, our attack can hide in any kind of application, not just in game or sport applications. We also suggest some countermeasures.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690370",
    "comment": ""
  },
  {
    "title": "CAPSID: A Private Session ID System for Small UAVs",
    "author": "Li, Yueshen and Jin, Jianli and Levchenko, Kirill",
    "abstract": "The US Federal Aviation Administration (FAA) has recently mandated that small unmanned aerial vehicles (UAVs) be equipped with a transmitter that broadcasts the UAV's serial number, location, and altitude. The inclusion of a unique identifier in the form of a UAV serial number has stoked fears that the identifier will be used to track UAV operators and has even led some UAV operators to file a lawsuit against the FAA.In this paper, we propose CAPSID, an implementation of the FAA session ID concept that provides message authentication-something current Remote ID implementations lack-and strong operator anonymity. The FAA (or its equivalent in other jurisdictions) retains the ability to de-anonymize operators, but only in circumstances prescribed by law. To make this possible, CAPSID introduces a partially trusted third party, the Custodian, that serves as the bridge between anonymous identifiers and true operator identity. The Custodian ensures that the legal requirements for de-anonymization are met, preventing unnecessary mass collection of personally identifying information by a government agency.We formally verify the message authentication property of CAPSID using a cryptographic protocol checker and provide a formal proof of identifier non-linkability, even in the presence of corrupt (but non-colluding) authorities.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690324",
    "comment": ""
  },
  {
    "title": "MaskPrint: Take the Initiative in Fingerprint Protection to Mitigate the Harm of Data Breach",
    "author": "Yan, Yihui and Yang, Zhice",
    "abstract": "The privacy of fingerprints is a growing concern due to the risk of data breaches and subsequent attacks. A key issue is that the information of the same fingerprint may exist on multiple devices, and device-level protection mechanisms are fundamentally limited in their coverage. Consequently, information leakage from any device potentially affects all enrolled fingerprint recognition devices. In this paper, we introduce a novel fingerprint enrollment method called MaskPrint, which allows users to enroll in various fingerprint recognition systems using distinct information. This approach can largely mitigate the risk of data breaches, providing a user-transparent, device-agnostic fingerprint protection measure. Our method involves collecting the original fingerprint information, selecting a minimum feature set, synthesizing protective fingerprints, and fabricating physical ones for enrollment. Users can complete these procedures on their own. We validate the effectiveness and usability of MaskPrint on commercial fingerprint recognition systems.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670364",
    "comment": ""
  },
  {
    "title": "Precio: Private Aggregate Measurement via Oblivious Shuffling",
    "author": "Anderson, Erik and Chase, Melissa and Durak, F. Bet\\\"{u}l and Laine, Kim and Weng, Chenkai",
    "abstract": "We introduce Precio, a new secure aggregation method for computing layered histograms and sums over secret shared data in a client-server setting. Precio is motivated by ad conversion measurement scenarios, where online advertisers and ad networks want to measure the performance of ad campaigns without requiring privacy-invasive techniques, such as third-party cookies.Precio has linear (time and communication) complexity in the number of data points and guarantees differentially private outputs. We formally analyze its security and privacy and present a thorough performance evaluation. The protocol supports much larger domains than Prio. It supports much more flexible aggregates than the DPF-based solution and in some settings has up to four orders of magnitude better performance.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670280",
    "comment": ""
  },
  {
    "title": "Formal Privacy Proof of Data Encoding: The Possibility and Impossibility of Learnable Encryption",
    "author": "Xiao, Hanshen and Suh, G. Edward and Devadas, Srinivas",
    "abstract": "We initiate a formal study on the concept of learnable obfuscation and aim to answer the following question: is there a type of data encoding that maintains the \"learnability\" of encoded samples, thereby enabling direct model training on transformed data, while ensuring the privacy of both plaintext and the secret encoding function? This long-standing open problem has prompted many efforts to design such an encryption function, for example, NeuraCrypt and TransNet. Nonetheless, all existing constructions are heuristic without formal privacy guarantees, and many successful reconstruction attacks are known on these constructions assuming an adversary with substantial prior knowledge.We present both generic possibility and impossibility results pertaining to learnable obfuscation. On one hand, we demonstrate that any non-trivial, property-preserving transformation which enables effectively learning over encoded samples cannot offer cryptographic computational security in the worst case. On the other hand, from the lens of information-theoretical security, we devise a series of new tools to produce provable and useful privacy guarantees from a set of heuristic obfuscation methods, including matrix masking, data mixing and permutation, through noise perturbation. Under the framework of PAC Privacy, we show how to quantify the leakage from the learnable obfuscation built upon obfuscation and perturbation methods against adversarial inference. Significantly sharpened utility-privacy tradeoffs are achieved compared to state-of-the-art accounting methods when measuring privacy against data reconstruction and membership inference attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670277",
    "comment": ""
  },
  {
    "title": "SpecGuard: Specification Aware Recovery for Robotic Autonomous Vehicles from Physical Attacks",
    "author": "Dash, Pritam and Chan, Ethan and Pattabiraman, Karthik",
    "abstract": "Robotic Autonomous Vehicles (RAVs) rely on their sensors for perception, and follow strict mission specifications (e.g., altitude, speed, and geofence constraints) for safe and timely operations. Physical attacks can corrupt the RAVs' sensors, resulting in mission failures. Recovering RAVs from such attacks demands robust control techniques that maintain compliance with mission specifications even under attacks to ensure the RAV's safety and timely operations.We propose SpecGuard, a technique that complies with mission specifications and performs safe recovery of RAVs. There are two innovations in SpecGuard. First, it introduces an approach to incorporate mission specifications and learn a recovery control policy using Deep Reinforcement Learning (Deep-RL). We design a compliance-based reward structure that reflects the RAV's complex dynamics and enables SpecGuard to satisfy multiple mission specifications simultaneously. Second, SpecGuard incorporates state reconstruction, a technique that minimizes attack induced sensor perturbations. This reconstruction enables effective adversarial training, and optimizing the recovery control policy for robustness under attacks. We evaluate SpecGuard in both virtual and real RAVs, and find that it achieves 92\\% recovery success rate under attacks on different sensors, without any crashes or stalls. SpecGuard achieves 2X higher recovery success than prior work, and incurs about 15\\% performance overhead on real RAVs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690210",
    "comment": ""
  },
  {
    "title": "VisionGuard: Secure and Robust Visual Perception of Autonomous Vehicles in Practice",
    "author": "Han, Xingshuo and Wang, Haozhao and Zhao, Kangqiao and Deng, Gelei and Xu, Yuan and Liu, Hangcheng and Qiu, Han and Zhang, Tianwei",
    "abstract": "Modern Autonomous Vehicles (AVs) implement the Visual Perception Module (VPM) to perceive their surroundings. This VPM adopts various Deep Neural Network (DNN) models to process the data collected from cameras and LiDAR. Prior studies have shown that these models are vulnerable to physical adversarial examples (PAEs), which pose a critical safety risk to the autonomous driving task. While a few defense methods have been proposed to safeguard AVs, most of them only target a limited set of attack types and specific scenarios, making them impractical for real-world protection.In this paper, we introduce VisionGuard, a novel and practical methodology to comprehensively detect and mitigate various types of PAEs to the VPM. The key of VisionGuard is to leverage the spatiotemporal inconsistency property of PAEs to detect anomalies. It predicts the motion states from historical ones and compares them with the current driving states to identify any motion inconsistency caused by physical attacks. We evaluate 9 state-of-the-art PAEs against both camera and camera-LiDAR fusion-based object classification \\& detection models. Experimental results in both simulation and physical world validate the effectiveness and robustness of VisionGuard. Codes, demo videos and appendix can be found on our anonymous website: https://sites.google.com/view/visionguard.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670296",
    "comment": ""
  },
  {
    "title": "PhyScout: Detecting Sensor Spoofing Attacks via Spatio-temporal Consistency",
    "author": "Xu, Yuan and Deng, Gelei and Han, Xingshuo and Li, Guanlin and Qiu, Han and Zhang, Tianwei",
    "abstract": "Existing defense approaches against sensor spoofing attacks suffer from the limitations of limited specific attack types, requiring GPU computation, exhibiting considerable detection latency and struggling with the interpretability of corner cases. We developed PhyScout, a holistic sensor spoofing defense framework to overcome the above limitations. Our framework capitalizes on the observation that human drivers can rapidly and accurately identify spoofing attacks by performing spatio-temporal consistency checks of their environment. We commence by defining the generalized conflicts that different sensor spoofing attacks produce regarding the spatio-temporal consistency. These conflicts are subsequently unified and formalized through a least squares problem approach. This process is modeled using image-based feature point extraction and matching techniques, followed by the design of a risk identification method for each conflict.We evaluate PhyScout across various environments, including simulators, datasets, and real-world scenarios. Compared to existing defense solutions, PhyScout offers rapid identification of sensor attacks (within 100ms) with low performance overhead (CPU-based), and conflict visualization. It demonstrates a fresh paradigm in autonomous vehicle security and presents new avenues for future research in robust and efficient defense mechanisms against sensor spoofing attacks. More video demos are at our anonymous website https://sites.google.com/view/physcout.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670290",
    "comment": ""
  },
  {
    "title": "ERACAN: Defending Against an Emerging CAN Threat Model",
    "author": "Tang, Zhaozhou and Serag, Khaled and Zonouz, Saman and Celik, Z. Berkay and Xu, Dongyan and Beyah, Raheem",
    "abstract": "The Controller Area Network (CAN) is a pivotal communication protocol extensively utilized in vehicles, aircraft, factories, and diverse cyber-physical systems (CPSs). The extensive CAN security literature resulting from decades of wide usage may create an impression of thorough scrutiny. However, a closer look reveals its reliance on a specific threat model with a limited range of abilities. Notably, recent works show that this model is outdated and that a more potent and versatile model could soon become the norm, prompting the need for a new defense paradigm. Unfortunately, the security impact of this emerging model on CAN systems has not received sufficient attention, and the defense systems addressing it are almost nonexistent. In this paper, we introduce ERACAN, the first comprehensive defense system against this new threat model. We first begin with a threat analysis to ensure that ERACAN comprehensively understands this model's capabilities, evasion tactics, and propensity to enable new attacks or enhance existing ones. ERACAN offers versatile protection against this spectrum of threats, providing attack detection, classification, and optional prevention abilities. We implement and evaluate ERACAN on a testbed and a real vehicle's CAN bus to demonstrate its low latency, real-time operation, and protective capabilities. ERACAN achieves detection rates of 100\\% and 99.7\\%+ for all attacks launched by the conventional and the enhanced threat models, respectively.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690267",
    "comment": ""
  },
  {
    "title": "Elephants Do Not Forget: Differential Privacy with State Continuity for Privacy Budget",
    "author": "Jin, Jiankai and Chuengsatiansup, Chitchanok and Murray, Toby and Rubinstein, Benjamin I. P. and Yarom, Yuval and Ohrimenko, Olga",
    "abstract": "Current implementations of differentially-private (DP) systems either lack support to track the global privacy budget consumed on a dataset, or fail to faithfully maintain the state continuity of this budget. We show that failure to maintain a privacy budget enables an adversary to mount replay, rollback and fork attacks --- obtaining answers to many more queries than what a secure system would allow. As a result the attacker can reconstruct secret data that DP aims to protect --- even if DP code runs in a Trusted Execution Environment (TEE). We propose ElephantDP, a system that aims to provide the same guarantees as a trusted curator in the global DP model would, albeit set in an untrusted environment. Our system relies on a state continuity module to provide protection for the privacy budget and a TEE to faithfully execute DP code and update the budget. To provide security, our protocol makes several design choices including the content of the persistent state and the order between budget updates and query answers. We prove that ElephantDP provides liveness (i.e., the protocol can restart from a correct state and respond to queries as long as the budget is not exceeded) and DP confidentiality (i.e., an attacker learns about a dataset as much as it would from interacting with a trusted curator). Our implementation and evaluation of the protocol use Intel SGX as a TEE to run the DP code and a network of TEEs to maintain state continuity. Compared to an insecure baseline, we observe 1.1--3.2\\texttimes{} overheads and lower relative overheads for complex DP queries.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670281",
    "comment": ""
  },
  {
    "title": "ProBE: Proportioning Privacy Budget for Complex Exploratory Decision Support",
    "author": "Lahjouji, Nada and Ghayyur, Sameera and He, Xi and Mehrotra, Sharad",
    "abstract": "This paper studies privacy in the context of complex decision support queries composed of multiple conditions on different aggregate statistics combined using disjunction and conjunction operators. Utility requirements for such queries necessitate the need for private mechanisms that guarantee a bound on the false negative and false positive errors. This paper formally defines complex decision support queries and their accuracy requirements, and provides algorithms that proportion the existing budget to optimally minimize privacy loss while supporting a bounded guarantee on the accuracy. Our experimental results on multiple real-life datasets show that our algorithms successfully maintain such utility guarantees, while also minimizing privacy loss.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670394",
    "comment": ""
  },
  {
    "title": "Almost Instance-optimal Clipping for Summation Problems in the Shuffle Model of Differential Privacy",
    "author": "Dong, Wei and Luo, Qiyao and Fanti, Giulia and Shi, Elaine and Yi, Ke",
    "abstract": "Differentially private mechanisms achieving worst-case optimal error bounds (e.g., the classical Laplace mechanism) are well-studied in the literature. However, when typical data are far from the worst case, instance-specific error bounds---which depend on the largest value in the dataset---are more meaningful. For example, consider the sum estimation problem, where each user has an integer xi from the domain {0,1,...,U} and we wish to estimate ∑i xi. This has a worst-case optimal error of O(U/ε), while recent work has shown that the clipping mechanism can achieve an instance-optimal error of O(maxi xi ⋅ log log U /ε). Under the shuffle model, known instance-optimal protocols are less communication-efficient. The clipping mechanism also works in the shuffle model, but requires two rounds: Round one finds the clipping threshold, and round two does the clipping and computes the noisy sum of the clipped data. In this paper, we show how these two seemingly sequential steps can be done simultaneously in one round using just 1+o(1) messages per user, while maintaining the instance-optimal error bound. We also extend our technique to the high-dimensional sum estimation problem and sparse vector aggregation (a.k.a. frequency estimation under user-level differential privacy).",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690225",
    "comment": ""
  },
  {
    "title": "Securing Floating-Point Arithmetic for Noise Addition",
    "author": "Holohan, Naoise and Braghin, Stefano and Suliman, Mohamed",
    "abstract": "Floating-point arithmetic is ubiquitous across computing, with its wide range of values, large and small, making it the preferred tool for storing, analysing, and manipulating numerical data. Its flexibility comes at the cost of additional risks in some security/privacy-aware settings. In this paper, we discuss the threat of information leakage caused by floating-point arithmetic when adding noise to sensitive values, which can allow the sensitive information to be recovered (e.g., in differential privacy). We present a solution, Mantissa Bit Manipulation (MBM), that is orders of magnitude faster than the current state-of-the-art, applicable to most continuous probability distributions and to all floating-point number formats.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690347",
    "comment": ""
  },
  {
    "title": "Distributed PIR: Scaling Private Messaging via the Users' Machines",
    "author": "Tovey, Elkana and Weiss, Jonathan and Gilad, Yossi",
    "abstract": "This paper presents a new architecture for metadata-private messaging that counters scalability challenges by offloading most computations to the clients. At the core of our design is a distributed private information retrieval (PIR) protocol, where the responder delegates its work to alleviate PIR's computational bottleneck and catches misbehaving delegates by efficiently verifying their results. We introduce DPIR, a messaging system that uses distributed PIR to let a server storing messages delegate the work to the system's clients, such that each client contributes proportional processing to the number of messages it reads. The server removes clients returning invalid results, which DPIR leverages to integrate an incentive mechanism for honest client behavior by conditioning messaging through DPIR on correctly processing PIR requests from other users. The result is a metadata-private messaging system that asymptotically improves scalability over prior work with the same threat model. We show through experiments on a prototype implementation that DPIR concretely improves performance by 3.25\\texttimes{} and 4.31\\texttimes{} over prior work [3, 5] and that the performance gap grows with the user base~size.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670350",
    "comment": ""
  },
  {
    "title": "Bytes to Schlep? Use a FEP: Hiding Protocol Metadata with Fully Encrypted Protocols",
    "author": "Fenske, Ellis and Johnson, Aaron",
    "abstract": "Fully Encrypted Protocols (FEPs) have arisen in practice as a technique to avoid network censorship. Such protocols are designed to produce messages that appear completely random. This design hides communications metadata, such as version and length fields, and makes it difficult to even determine what protocol is being used. Moreover, these protocols frequently support padding to hide the length of protocol fields and the contained message. These techniques have relevance well beyond censorship circumvention, as protecting protocol metadata has security and privacy benefits for all Internet communications. The security of FEP designs depends on cryptographic assumptions, but neither security definitions nor proofs exist for them. We provide novel security definitions that capture the metadata-protection goals of FEPs. Our definitions are given in both the datastream and datagram settings, which model the ubiquitous TCP and UDP interfaces available to protocol designers. We prove relations among these new notions and existing security definitions. We further present new FEP constructions and prove their security. Finally, we survey existing FEP candidates and characterize the extent to which they satisfy FEP security. We identify novel ways in which these protocols are identifiable, including their responses to the introduction of data errors and the sizes of their smallest protocol messages.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690198",
    "comment": ""
  },
  {
    "title": "Robust and Reliable Early-Stage Website Fingerprinting Attacks via Spatial-Temporal Distribution Analysis",
    "author": "Deng, Xinhao and Li, Qi and Xu, Ke",
    "abstract": "Website Fingerprinting (WF) attacks identify the websites visited by users by performing traffic analysis, compromising user privacy. Particularly, DL-based WF attacks demonstrate impressive attack performance. However, the effectiveness of DL-based WF attacks relies on the collected complete and pure traffic during the page loading, which impacts the practicality of these attacks. The WF performance is rather low under dynamic network conditions and various WF defenses, particularly when the analyzed traffic is only a small part of the complete traffic. In this paper, we propose Holmes, a robust and reliable early-stage WF attack. Holmes utilizes temporal and spatial distribution analysis of website traffic to effectively identify websites in the early stages of page loading. Specifically, Holmes develops adaptive data augmentation based on the temporal distribution of website traffic and utilizes a supervised contrastive learning method to extract the correlations between the early-stage traffic and the pre-collected complete traffic. Holmes accurately identifies traffic in the early stages of page loading by computing the correlation of the traffic with the spatial distribution information, which ensures robust and reliable detection according to early-stage traffic. We extensively evaluate Holmes using six datasets. Compared to nine existing DL-based WF attacks, Holmes improves the F1-score of identifying early-stage traffic by an average of 169.18\\%. Furthermore, we replay the traffic of visiting real-world dark web websites. Holmes successfully identifies dark web websites when the ratio of page loading on average is only 21.71\\%, with an average precision improvement of 169.36\\% over the existing WF attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670272",
    "comment": ""
  },
  {
    "title": "HomeRun: High-efficiency Oblivious Message Retrieval, Unrestricted",
    "author": "Jia, Yanxue and Madathil, Varun and Kate, Aniket",
    "abstract": "In the realm of privacy-preserving blockchain applications such as Zcash, oblivious message retrieval (OMR) enables recipients to privately access messages directed to them on blockchain nodes (or bulletin board servers). OMR prevents servers from linking a message and its corresponding recipient's address, thereby safeguarding recipient privacy. Several OMR schemes have emerged recently to meet the demands of these privacy-centric blockchains; however, we observe that existing solutions exhibit shortcomings in various critical aspects and may only achieve certain objectives inefficiently, sometimes relying on trusted hardware, thereby impacting their practical utility. This work introduces a novel OMR protocol, HomeRun, that leverages two semi-honest, non-colluding servers to excel in both performance and security attributes as compared to the current state-of-the-art.HomeRun stands out by providing unlinkability across multiple requests for the same recipient's address. Moreover, it does not impose a limit on the number of pertinent messages that can be received by a recipient, which thwarts \"message balance exhaustion'' attacks and enhances system usability. HomeRun also empowers servers to regularly delete the retrieved messages and the associated auxiliary data, which mitigates the constantly increasing computation costs and storage costs incurred by servers. Remarkably, none of the existing solutions offer all of these features collectively. Finally, thanks to our judicious use of highly efficient cryptographic building blocks, HomeRun is highly performant: Specifically, the total runtime of servers in HomeRun is 3830 \\texttimes{} less than that in the work by Liu et al. (CRYPTO '22) based on fully-homomorphic encryption, and at least 1459 \\texttimes{} less than that in the design by Madathil et al. (USENIX Security '22) based on two semi-honest and non-colluding servers, using a single thread in a WAN setting.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670381",
    "comment": ""
  },
  {
    "title": "RANsacked: A Domain-Informed Approach for Fuzzing LTE and 5G RAN-Core Interfaces",
    "author": "Bennett, Nathaniel and Zhu, Weidong and Simon, Benjamin and Kennedy, Ryon and Enck, William and Traynor, Patrick and Butler, Kevin R. B.",
    "abstract": "Cellular network infrastructure serves as the backbone of modern mobile wireless communication. As such, cellular cores must be proactively secured against external threats to ensure reliable service. Compromised base station attacks against the core are a rising threat to cellular networks, while user device inputs have long been considered as an attack vector; despite this, few techniques exist to comprehensively test RAN-Core interfaces against malicious input. In this work, we devise a fuzzing framework that performantly fuzzes cellular interfaces accessible from a base station or user device, overcoming several challenges in fuzzing specific to LTE/5G network components. We also introduce ASNFuzzGen, a tool that compiles ASN.1 specifications into structure-aware fuzzing modules, thereby facilitating effective fuzzing exploration of complex cellular protocols. We run fuzzing campaigns against seven open-source and commercial cores and discover 119 vulnerabilities, with 93 CVEs assigned. Our results reveal common implementation mistakes across several cores that lead to vulnerabilities, and the successful coordination of patches for these vulnerabilities across several vendors demonstrates the practical impact ASNFuzzGen has on hardening user-exposed cellular systems.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670320",
    "comment": ""
  },
  {
    "title": "J\\\"{a}ger: Automated Telephone Call Traceback",
    "author": "Adei, David and Madathil, Varun and Prasad, Sathvik and Reaves, Bradley and Scafuro, Alessandra",
    "abstract": "Unsolicited telephone calls that facilitate fraud or unlawful telemarketing continue to overwhelm network users and the regulators who prosecute them. The first step in prosecuting phone abuse is traceback --- identifying the call originator. This fundamental investigative task currently requires hours of manual effort per call. In this paper, we introduce J\\\"{a}ger, a distributed secure call traceback system. J\\\"{a}ger can trace a call in a few seconds, even with partial deployment, while cryptographically preserving the privacy of call parties, carrier trade secrets like peers and call volume, and limiting the threat of bulk analysis. We establish definitions and requirements of secure traceback, then develop a suite of protocols that meet these requirements using witness encryption, oblivious pseudorandom functions, and group signatures. We prove these protocols secure in the universal composibility framework. We then demonstrate that J\\\"{a}ger has low compute and bandwidth costs per call, and these costs scale linearly with call volume. J\\\"{a}ger provides an efficient, secure, privacy-preserving system to revolutionize telephone abuse investigation with minimal costs to operators.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690290",
    "comment": ""
  },
  {
    "title": "Strong Privacy-Preserving Universally Composable AKA Protocol with Seamless Handover Support for Mobile Virtual Network Operator",
    "author": "Alnashwan, Rabiah and Yang, Yang and Dong, Yilu and Gope, Prosanta and Abdolmaleki, Behzad and Hussain, Syed Rafiul",
    "abstract": "Consumers seeking a new mobile plan have many choices in the present mobile landscape. The Mobile Virtual Network Operator (MVNO) has recently gained considerable attention among these options. MVNOs offer various benefits, making them an appealing choice for a majority of consumers. These advantages encompass flexibility, access to cutting-edge technologies, enhanced coverage, superior customer service, and substantial cost savings. Even though MVNO offers several advantages, it also creates some security and privacy concerns for the customer simultaneously. For instance, in the existing solution, MVNO needs to hand over all the sensitive details, including the users' identities and master secret keys of their customers, to a mobile operator (MNO) to validate the customers while offering any services. This allows MNOs to have unrestricted access to the MVNO subscribers' location and mobile data, including voice calls, SMS, and Internet, which the MNOs frequently sell to third parties (e.g., advertisement companies and surveillance agencies) for more profit. Although critical for mass users, such privacy loss has been historically ignored due to the lack of practical and privacy-preserving solutions for registration and handover procedures in cellular networks. In this paper, we propose a universally composable authentication and handover scheme with strong user privacy support, where each MVNO user can validate a mobile operator (MNO) and vice-versa without compromising user anonymity and unlinkability support. Here, we anticipate that our proposed solution will most likely be deployed by the MVNO(s) to ensure enhanced privacy support to their customer(s).",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690331",
    "comment": ""
  },
  {
    "title": "Untangling the Knot: Breaking Access Control in Home Wireless Mesh Networks",
    "author": "Zhou, Xin'an and Deng, Qing and Pu, Juefei and Man, Keyu and Qian, Zhiyun and Krishnamurthy, Srikanth V.",
    "abstract": "Home wireless mesh networks (WMNs) are increasingly gaining popularity for their superior extensibility and signal coverage compared to traditional single-AP wireless networks. In particular, there is a single gateway node and multiple extender nodes that cooperate to provide wireless coverage. We observe that there is no comprehensive research conducted on the security aspects of the control plane of such networks. For example, this decentralized architecture enables each extender node to independently authenticate wireless clients by synchronizing access control policies from the gateway node. However, this synchronization unexpectedly opens an attack surface which has not been scrutinized.In our research, we conduct an empirical study investigating devices and protocols of six popular home wireless mesh network vendors, focusing on the attack surface introduced by the access policy synchronization. Interestingly, we find that the exact protocols used to support such functionalities vary by vendors, despite the existence of the EasyMesh standard that vendors could opt-in. Furthermore, we find a number of serious security flaws, including but not limited to malicious clients retaining their network access indefinitely and direct compromises of gateway and extender nodes in some cases. These issues arise due to the lack of coordination across different layers of protocols that work together to support the control plane. We reported all of our findings to the affected vendors and they have acknowledged the issues and are working towards fixes (most of the vendors have released patches). Finally, we discuss trade-offs in different existing designs, suggest alternative solutions, and summarize lessons learned from the research.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670380",
    "comment": ""
  },
  {
    "title": "BlueSWAT: A Lightweight State-Aware Security Framework for Bluetooth Low Energy",
    "author": "Che, Xijia and He, Yi and Feng, Xuewei and Sun, Kun and Xu, Ke and Li, Qi",
    "abstract": "Bluetooth Low Energy (BLE) is a short-range wireless communication technology for resource-constrained IoT devices. Unfortunately, BLE is vulnerable to session-based attacks, where previous packets construct exploitable conditions for subsequent packets to compromise connections. Defending against session-based attacks is challenging because each step in the attack sequence is legitimate when inspected individually. In this paper, we present BlueSWAT, a lightweight state-aware security framework for protecting BLE devices. To perform inspection on the session level rather than individual packets, BlueSWAT leverages a finite state machine (FSM) to monitor sequential actions of connections at runtime. Patterns of session-based attacks are modeled as malicious transition paths in the FSM. To overcome the heterogeneous IoT environment, we develop a lightweight eBPF framework to facilitate universal patch distribution across different BLE architectures and stacks, without requiring device reboot. We implement BlueSWAT on 5 real-world devices with different chips and stacks to demonstrate its cross-device adaptability. On our dataset with 101 real-world BLE vulnerabilities, BlueSWAT can mitigate 76.1\\% of session-based attacks, outperforming other defense frameworks. In our end-to-end application evaluation, BlueSWAT introduces an average of 0.073\\% memory overhead and negligible latency.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670397",
    "comment": ""
  },
  {
    "title": "State Machine Mutation-based Testing Framework for Wireless Communication Protocols",
    "author": "Rashid, Syed Md Mukit and Wu, Tianwei and Tu, Kai and Ishtiaq, Abdullah Al and Tanvir, Ridwanul Hasan and Dong, Yilu and Chowdhury, Omar and Hussain, Syed Rafiul",
    "abstract": "This paper proposes Proteus, a protocol state machine, property-guided, and budget-aware automated testing approach for discovering logical vulnerabilities in wireless protocol implementations. Proteus maintains its budget awareness by generating test cases (i.e., each being a sequence of protocol messages) that are not only meaningful (i.e., the test case mostly follows the desirable protocol flow except for some controlled deviations) but also have a high probability of violating the desirable properties. To demonstrate its effectiveness, we evaluated Proteus in two different protocol implementations, namely 4G LTE and BLE, across 23 consumer devices (11 for 4G LTE and 12 for BLE). Proteus discovered 25 unique issues, including 112 instances. Affected vendors have positively acknowledged 14 vulnerabilities through 5 CVEs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690312",
    "comment": ""
  },
  {
    "title": "Peeking through the window: Fingerprinting Browser Extensions through Page-Visible Execution Traces and Interactions",
    "author": "Agarwal, Shubham and Fass, Aurore and Stock, Ben",
    "abstract": "Browser extensions are third-party add-ons that provide myriads of features to their users while browsing on the Web. Extensions often interact with the websites a user visits and perform various operations such as DOM-based manipulation, script injections, and so on. However, this also enables nefarious websites to track their visitors by fingerprinting extensions. Researchers in the past have shown that extensions are susceptible to fingerprinting based on the resources they include, the styles they deploy, or the DOM-based modifications they perform. Fortunately, the current extension ecosystem contains safeguards against many such known issues through appropriate defense mechanisms.We present the first study to investigate the fingerprinting characteristics of extension-injected code in pages' JavaScript namespace and through other observable side-effects like changed cookies. Doing so, we find that many extensions inject JavaScript that pollutes the applications' global namespace by registering variables. It also enables the attacker application to monitor the execution of the injected code by overwriting the JavaScript APIs and capturing execution traces through the stacktrace, the set of APIs invoked, etc. Further, extensions also store data on the client side and perform event-driven functionalities that aid in attribution. Through our tests, we find 2,747 Chrome and 572 Firefox extensions to be susceptible to fingerprinting. Unfortunately, none of the existing defense mechanisms prevent extensions from being fingerprinted through our proposed vectors. Therefore, we also suggest potential measures for developers and browser vendors to safeguard the extension ecosystem against such fingerprinting attempts.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670339",
    "comment": ""
  },
  {
    "title": "Understanding Cross-Platform Referral Traffic for Illicit Drug Promotion",
    "author": "Zha, Mingming and Lin, Zilong and Tang, Siyuan and Liao, Xiaojing and Nan, Yuhong and Wang, XiaoFeng",
    "abstract": "The promotion of illegal drugs has become increasingly prevalent on popular social media platforms such as TikTok, Instagram, and YouTube. Within this ecosystem, miscreants utilize cross-platform referral traffic to advertise and promote illicit drugs. They start by posting illicit drug-promoting comments on upstream social media platforms, attracting potential drug buyers, and then redirecting these buyers to downstream platforms where the actual drug sales take place. To the best of our knowledge, little has been done so far to understand this cross-platform referral traffic for illicit drug promotion and selling on social media platforms, not to mention any effort to systematically identify such referral traffic on social media platforms. In this paper, we designed an automated pipeline for detecting illicit referral traffic and identified 154,753 drug-referral comments and 3,253 drug sellers. Based upon the dataset, we presented the first systematic study on the ecosystem of such cross-platform illicit drug promotion and selling businesses, which sheds light on the strategies and campaigns of illicit drug promotion. These findings provide valuable insights into the broader impact of illicit drug trading activities and highlight the need for increased attention to addressing the associated security concerns in social media platforms.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670383",
    "comment": ""
  },
  {
    "title": "Characterizing and Mitigating Phishing Attacks at ccTLD Scale",
    "author": "Moura, Giovane C. M. and Daniels, Thomas and Bosteels, Maarten and Castro, Sebastian and M\\\"{u}ller, Moritz and Wabeke, Thymen and van den Hout, Thijs and Korczy\\'{n}ski, Maciej and Smaragdakis, Georgios",
    "abstract": "Phishing on the web is a model of social engineering and an attack vector for getting access to sensitive and financial data of individuals and corporations. Phishing has been identified as one of the prime cyber threats in recent years. With the goal to effectively identify and mitigate phishing as early as possible, we present in this paper a longitudinal analysis of phishing attacks from the vantage point of three country-code top-level domain (ccTLD) registries that manage more than 8 million active domains -- namely the Netherlands' .nl, Ireland's .ie, and Belgium's .be. We perform a longitudinal analysis on phishing attacks spanning up to 10 years, based on more than 28 thousand phishing domains. Our results show two major attack strategies: national companies and organizations are far more often impersonated using malicious registered domains under their country's own ccTLD, which enables better mimicry of the impersonated company. In stark contrast, international companies are impersonated using any domains that can be compromised, reducing overall mimicry but bearing no registration and financial costs. Although most research works focus on detecting new domain names, we show that 80\\% of phishing attacks in the studied ccTLDs employ compromised domain names. We find banks, financial institutions, and high-tech giant companies at the top of the most impersonated targets. We also show the impact of ccTLDs' registration and abuse handling policies on preventing and mitigating phishing attacks, and that mitigation is complex and performed at both web and DNS level at different intermediaries. Last, our results provide a unique opportunity for ccTLDs to compare and revisit their policies and impacts, with the goal of improving mitigation procedures.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690192",
    "comment": ""
  },
  {
    "title": "The Big Brother's New Playground: Unmasking the Illusion of Privacy in Web Metaverses from a Malicious User's Perspective",
    "author": "Mengascini, Andrea and Aurelio, Ryan and Pellegrino, Giancarlo",
    "abstract": "Metaverses are virtual worlds where users can engage in social exchanges, collaborate, or play games. Their clients now are JavaScript programs that run inside modern web browsers. They implement functionalities typical of multiplayer video games, like 3D and physics engines, requiring them to maintain complex data structures of objects in the browser's memory. Unfortunately, these objects can be accessed and manipulated by malicious users, allowing them to learn about events beyond the ones rendered on screen or to hijack the physics of the metaverse to spy on other users.In this paper, we propose one of the first comprehensive security assessments for web clients of metaverse platforms. We begin with a survey and selection of three metaverse platforms and introduce a software-centric threat modeling approach designed to identify the security-relevant entities. Then, we propose a JavaScript global object snapshot diffing technique to identify in-memory objects correlated with the attribute and design 10 attacks, of which eight successfully executed against at least one of the metaverses, enabling a malicious user to perform audio/video surveillance or continuous user position tracking - to mention a few - who could exacerbate current threats posed by stalkers and online abusers. Finally, we discuss the implications of our attacks should the metaverse become a business tool and possible solutions.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690249",
    "comment": ""
  },
  {
    "title": "Blocking Tracking JavaScript at the Function Granularity",
    "author": "Amjad, Abdul Haddi and Munir, Shaoor and Shafiq, Zubair and Gulzar, Muhammad Ali",
    "abstract": "Modern websites extensively rely on JavaScript to implement both functionality and tracking. Existing privacy-enhancing content-blocking tools struggle against mixed scripts, which simultaneously implement both functionality and tracking. Blocking such scripts would break functionality, and not blocking them would allow tracking. We propose Not.js, a fine-grained JavaScript blocking tool that operates at the function-level granularity. Not.js's strengths lie in analyzing the dynamic execution context, including the call stack and calling context of each JavaScript function, and then encoding this context to build a rich graph representation. Not.js trains a supervised machine learning classifier on a webpage's graph representation to first detect tracking at the function-level and then automatically generates surrogate scripts that preserve functionality while removing tracking. Our evaluation of Not.js on the top-10K websites demonstrates that it achieves high precision (94\\%) and recall (98\\%) in detecting tracking functions, outperforming the state-of-the-art while being robust against off-the-shelf JavaScript obfuscation. Fine-grained detection of tracking functions allows Not.js to automatically generate surrogate scripts, which our evaluation shows that successfully remove tracking functions without causing major breakage. Our deployment of Not.js shows that mixed scripts are present on 62.3\\% of the top-10K websites, with 70.6\\% of the mixed scripts being third-party that engage in tracking activities such as cookie ghostwriting.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670329",
    "comment": ""
  },
  {
    "title": "Unbundle-Rewrite-Rebundle: Runtime Detection and Rewriting of Privacy-Harming Code in JavaScript Bundles",
    "author": "Ali, Mir Masood and Snyder, Peter and Kanich, Chris and Haddadi, Hamed",
    "abstract": "This work presents Unbundle-Rewrite-Rebundle (URR), a system for detecting privacy-harming portions of bundled JavaScript code and rewriting that code at runtime to remove the privacy-harming behavior without breaking the surrounding code or overall application. URR is a novel solution to the problem of JavaScript bundles, where websites pre-compile multiple code units into a single file, making it impossible for content filters and ad-blockers to differentiate between desired and unwanted resources. Where traditional content filtering tools rely on URLs, URR analyzes the code at the AST level, and replaces harmful AST sub-trees with privacy-and-functionality maintaining alternatives.We present an open-sourced implementation of URR as a Firefox extension and evaluate it against JavaScript bundles generated by the most popular bundling system (Webpack) deployed on the Tranco 10k. We evaluate URR by precision (1.00), recall (0.95), and speed (0.43s per script) when detecting and rewriting three representative privacy-harming libraries often included in JavaScript bundles, and find URR to be an effective approach to a large-and-growing blind spot unaddressed by current privacy tools.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690262",
    "comment": ""
  },
  {
    "title": "ProFake: Detecting Deepfakes in the Wild against Quality Degradation with Progressive Quality-adaptive Learning",
    "author": "Xu, Huiyu and Wang, Yaopeng and Wang, Zhibo and Ba, Zhongjie and Liu, Wenxin and Jin, Lu and Weng, Haiqin and Wei, Tao and Ren, Kui",
    "abstract": "Despite the promising advances in deepfake detection on current datasets, detecting visual deepfakes in real-world scenarios (e.g., deepfake videos and live streaming on YouTube) remains a challenge due to the inherent quality degradation such as unpredictable compression employed by social media platforms. Such degradation perturbs discernible forgery clues and diminishes the effectiveness of deepfake detection methods, raising a critical safety concern to the misuse of forgery faces in real-world scenarios. In this paper, we aim to understand the impacts of real-world degradation on the robustness of deepfake detection. Particularly, we investigate the risk of degraded deepfakes towards their detection on two real-world scenarios (i.e., deepfake videos and deepfake live streaming on social media platforms). By measuring the effects of real-world degradations on the performance and representation capabilities of detection models, we reveal that real-world deepfakes can be simulated via common degradation operations (e.g., JPEG compression) as they are perceptually similar to deepfake detectors. By analyzing the training dynamics under different sequences of training samples, we observe that the training order of deepfakes progressing from non-degraded (easy) to heavily degraded (hard) enhances the adaptability of detection models to various degradation in real-world scenarios. Drawing from these observations, we present a novel deepfake detection method ProFake to enhance the robustness of deepfake detection against real-world quality degradations. ProFake enables quality-adaptive learning via progressively degrade, detect and assign weights for the training samples driven by the feedback of model performance and image quality, which ensures that our model gradually focuses on more challenging samples to achieve quality-adaptive deepfake detection. Extensive experiments show that compared with existing methods, ProFake improves deepfake detection accuracy by an average of over 10 \\% in real-world scenarios and by an average of over 30 \\% in heavily degraded scenarios, while maintaining comparable performance in detecting high-quality deepfakes.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690238",
    "comment": ""
  },
  {
    "title": "Trident of Poseidon: A Generalized Approach for Detecting Deepfake Voices",
    "author": "Doan, Thien-Phuc and Dinh-Xuan, Hung and Ryu, Taewon and Kim, Inho and Lee, Woongjae and Hong, Kihun and Jung, Souhwan",
    "abstract": "Deepfakes, an increasingly prevalent form of information attack, pose serious threats to security and privacy. Deepfake voice attacks, in particular, have the potential to cause widespread disruption, creating an urgent need for an effective detection system. In this research, we propose the Trident of Poseidon - a novel set of triad training strategies aimed at enhancing the generalizability of deepfake voice detection models. Our solution comprises three key components: (1) Supervised Contrastive Learning, (2) Hard Negative Mining by Audio Re-synthesizing, and (3) Effective Proactive Batch Sampling. Together, these enable the model to learn more robust features. Our extensive experiments demonstrate that our approach outperforms existing methods in both in-domain and out-of-domain testing scenarios, making significant strides toward securing digital media against deepfake voice attacks.Furthermore, we conducted a deeper analysis to explore whether deepfake voices can be categorized into families. By identifying the factors that contribute to the formation of a deepfake voice family, we can better organize a deepfake voice corpus, thereby reducing the effort needed to combat the arms race challenge. Finally, to promote practical utility and community-wide adoption, we have made our solution publicly available as a web application available on deepfake.aisrc.technology, where users can utilize this tool to test for potential deepfake voices.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690311",
    "comment": ""
  },
  {
    "title": "On the Detectability of ChatGPT Content: Benchmarking, Methodology, and Evaluation through the Lens of Academic Writing",
    "author": "Liu, Zeyan and Yao, Zijun and Li, Fengjun and Luo, Bo",
    "abstract": "With ChatGPT under the spotlight, utilizing large language models (LLMs) to assist academic writing has drawn a significant amount of debate in the community. In this paper, we aim to present a comprehensive study of the detectability of ChatGPT-generated content within the academic literature, particularly focusing on the abstracts of scientific papers, to offer holistic support for the future development of LLM applications and policies in academia. Specifically, we first present GPABench2, a benchmarking dataset of over 2.8 million comparative samples of human-written, GPT-written, GPT-completed, and GPT-polished abstracts of scientific writing in computer science, physics, and humanities and social sciences. Second, we explore the methodology for detecting ChatGPT content. We start by examining the unsatisfactory performance of existing ChatGPT detecting tools and the challenges faced by human evaluators (including more than 240 researchers or students). We then test the hand-crafted linguistic features models as a baseline and develop a deep neural framework named CheckGPT to better capture the subtle and deep semantic and linguistic patterns in ChatGPT written literature. Last, we conduct comprehensive experiments to validate the proposed CheckGPT framework in each benchmarking task over different disciplines. To evaluate the detectability of ChatGPT content, we conduct extensive experiments on the transferability, prompt engineering, and robustness of CheckGPT.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670392",
    "comment": ""
  },
  {
    "title": "MGTBench: Benchmarking Machine-Generated Text Detection",
    "author": "He, Xinlei and Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Zhang, Yang",
    "abstract": "Nowadays, powerful large language models (LLMs) such as ChatGPT have demonstrated revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering. Consequently, the detection of machine-generated texts (MGTs) is becoming increasingly crucial as LLMs become more advanced and prevalent. These models have the ability to generate human-like language, making it challenging to discern whether a text is authored by a human or a machine. This raises concerns regarding authenticity, accountability, and potential bias. However, existing methods for detecting MGTs are evaluated using different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework that encompasses various methodologies. Furthermore, it remains unclear how existing detection methods would perform against powerful LLMs.In this paper, we fill this gap by proposing the first benchmark framework for MGT detection against powerful LLMs, named MGTBench. Extensive evaluations on public datasets with curated texts generated by various powerful LLMs such as ChatGPT-turbo and Claude demonstrate the effectiveness of different detection methods. Our ablation study shows that a larger number of words in general leads to better performance and most detection methods can achieve similar performance with much fewer training samples. Additionally, our findings reveal that metric-based/model-based detection methods exhibit better transferability across different LLMs/datasets. Furthermore, we delve into a more challenging task: text attribution, where the goal is to identify the originating model of a given text, i.e., whether it is a specific LLM or authored by a human. Our findings indicate that the model-based detection methods still perform well in the text attribution task. To investigate the robustness of different detection methods, we consider three adversarial attacks, namely paraphrasing, random spacing, and adversarial perturbations. We discover that these attacks can significantly diminish detection effectiveness, underscoring the critical need for the development of more robust detection methods. We envision that MGTBench will serve as a benchmark tool to accelerate future investigations involving the evaluation of powerful MGT detection methods on their respective datasets and the development of more advanced MGT detection methods.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670344",
    "comment": ""
  },
  {
    "title": "PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs)",
    "author": "Nazzal, Mahmoud and Khalil, Issa and Khreishah, Abdallah and Phan, NhatHai",
    "abstract": "The capability of generating high-quality source code using large language models (LLMs) reduces software development time and costs. However, recent literature and our empirical investigation in this work show that while LLMs can generate functioning code, they inherently tend to introduce security vulnerabilities, limiting their potential. This problem is mainly due to their training on massive open-source corpora exhibiting insecure and inefficient programming practices. Therefore, automatic optimization of LLM prompts for generating secure and functioning code is a demanding need. This paper introduces PromSec, an algorithm for <u>prom</u>pt optimization for <u>sec</u>ure and functioning code generation using LLMs. In PromSec, we combine 1) code vulnerability clearing using a generative adversarial graph neural network, dubbed as gGAN, to fix and reduce security vulnerabilities in generated codes and 2) code generation using an LLM into an interactive loop, such that the outcome of the gGAN drives the LLM with enhanced prompts to generate secure codes while preserving their functionality. Introducing a new contrastive learning approach in gGAN, we formulate the code-clearing and generation loop as a dual-objective optimization problem, enabling PromSec to notably reduce the number of LLM inferences. As a result, PromSec becomes a cost-effective and practical solution for generating secure and functioning codes.Extensive experiments conducted on Python and Java code datasets confirm that PromSec effectively enhances code security while upholding its intended functionality. Our experiments show that despite the comprehensive application of a state-of-the-art approach, it falls short in addressing all vulnerabilities within the code, whereas PromSec effectively resolves each of them. Moreover, PromSec achieves more than an order-of-magnitude reduction in operational time, number of LLM queries, and security analysis costs. Furthermore, prompts optimized with PromSec for a certain LLM are transferable to other LLMs across programming languages and generalizable to unseen vulnerabilities in training. This study presents an essential step towards improving the trustworthiness of LLMs for secure and functioning code generation, significantly enhancing their large-scale integration in real-world software code development practices.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690298",
    "comment": ""
  },
  {
    "title": "Dye4AI: Assuring Data Boundary on Generative AI Services",
    "author": "Wang, Shu and Sun, Kun and Zhai, Yan",
    "abstract": "Generative artificial intelligence (AI) is versatile for various applications, but security and privacy concerns with third-party AI vendors hinder its broader adoption in sensitive scenarios. Hence, it is essential for users to validate the AI trustworthiness and ensure the security of data boundaries. In this paper, we present a dye testing system named Dye4AI, which injects crafted trigger data into human-AI dialogue and observes AI responses towards specific prompts to diagnose data flow in AI model evolution. Our dye testing procedure contains 3 stages: trigger generation, trigger insertion, and trigger retrieval. First, to retain both uniqueness and stealthiness, we design a new trigger that transforms a pseudo-random number to a intelligible format. Second, with a custom-designed three-step conversation strategy, we insert each trigger item into dialogue and confirm the model memorizes the new trigger knowledge in the current session. Finally, we routinely try to recover triggers with specific prompts in new sessions, as triggers can present in new sessions only if AI vendors leverage user data for model fine-tuning. Extensive experiments on six LLMs demonstrate our dye testing scheme is effective in ensuring the data boundary, even for models with various architectures and parameter sizes. Also, larger and premier models tend to be more suitable for Dye4AI, e.g., trigger can be retrieved in OpenLLaMa-13B even with only 2 insertions per trigger item. Moreover, we analyze the prompt selection in dye testing, providing insights for future testing systems on generative AI services.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670299",
    "comment": ""
  },
  {
    "title": "Rust for Embedded Systems: Current State and Open Problems",
    "author": "Sharma, Ayushi and Sharma, Shashank and Tanksalkar, Sai Ritvik and Torres-Arias, Santiago and Machiry, Aravind",
    "abstract": "Embedded software is used in safety-critical systems such as medical devices and autonomous vehicles, where software defects, including security vulnerabilities, have severe consequences. Most embedded codebases are developed in unsafe languages, specifically C/C++, and are riddled with memory safety vulnerabilities. To prevent such vulnerabilities, Rust, a performant memory-safe systems language, provides an optimal choice for developing embedded software. Rust interoperability enables developing Rust applications on top of existing C codebases. Despite this, even the most resourceful organizations continue to develop embedded software in C/C++.  This paper performs the first systematic study to holistically understand the current state and challenges of using Rust for embedded systems. Our study is organized across three research questions. We collected a dataset of 6,408 Rust embedded software spanning various categories and 6 Static Application Security Testing (SAST) tools. We performed a systematic analysis of our dataset and surveys with 225 developers to investigate our research questions. We found that existing Rust software support is inadequate, SAST tools cannot handle certain features of Rust embedded software, resulting in failures, and the prevalence of advanced types in existing Rust software makes it challenging to engineer interoperable code. In addition, we found various challenges faced by developers in using Rust for embedded systems development.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690275",
    "comment": ""
  },
  {
    "title": "BaseMirror: Automatic Reverse Engineering of Baseband Commands from Android's Radio Interface Layer",
    "author": "Li, Wenqiang and Wen, Haohuang and Lin, Zhiqiang",
    "abstract": "In modern mobile devices, baseband is an integral component running on top of cellular processors to handle crucial radio communications. However, recent research reveals significant vulnerabilities in these basebands, posing serious security risks like remote code execution. Yet, effectively scrutinizing basebands remains a daunting task, as they run closed-source and proprietary software on vendor-specific chipsets. Existing analysis methods are limited by their dependence on manual processes and heuristic approaches, reducing their scalability. This paper introduces a novel approach to unveil security issues in basebands from a unique perspective: to uncover vendor-specific baseband commands from the Radio Interface Layer (RIL), a hardware abstraction layer interfacing with basebands. To demonstrate this concept, we have designed and developed BaseMirror, a static binary analysis tool to automatically reverse engineer baseband commands from vendor-specific RIL binaries. It utilizes a bidirectional taint analysis algorithm to adeptly identify baseband commands from an enhanced control flow graph enriched with reconstructed virtual function calls. Our methodology has been applied to 28 vendor RIL libraries, encompassing a wide range of Samsung Exynos smartphone models on the market. Remarkably, BaseMirror has uncovered 873 unique baseband commands undisclosed to the public. Based on these results, we develop an automated attack discovery framework to successfully derive and validate 8 zero-day vulnerabilities that trigger denial of cellular service and arbitrary file access on a Samsung Galaxy A53 device. These findings have been reported and confirmed by Samsung and a bug bounty was awarded to us.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690254",
    "comment": ""
  },
  {
    "title": "CanCal: Towards Real-time and Lightweight Ransomware Detection and Response in Industrial Environments",
    "author": "Wang, Shenao and Dong, Feng and Yang, Hangfeng and Xu, Jingheng and Wang, Haoyu",
    "abstract": "Ransomware attacks have emerged as one of the most significant cybersecurity threats. Despite numerous methods proposed for detecting and defending against ransomware, existing approaches face two fundamental limitations in large-scale industrial applications: (1) Behavior-based detection engines suffer from the enormous overhead of monitoring all processes and resource constraints for model inference, failing to meet the requirements for real-time detection; (2) Decoy-based detection engines generate an overwhelming number of false positives in large-scale industrial clusters, leading to intolerable disruptions to critical processes and excessive inspection efforts from security analysts. To address these challenges, we propose CanCal, a real-time and lightweight ransomware detection system. Specifically, instead of indiscriminately analyzing all processes, CanCal selectively filters suspicious processes by the monitoring layers and then performs in-depth behavioral analysis to isolate ransomware activities from benign operations, minimizing alert fatigue while ensuring lightweight computational and storage overhead. The experimental results on a large-scale industrial environment (1,761 ransomware, ~ 3 million events, continuous test over 5 months) indicate that CanCal achieves a remarkable 99.65\\% true positive rate on 555,678 unknown ransomware behavior events, with near-zero false positives. CanCal is as effective as state-of-the-art techniques while enabling rapid inference within 30ms and real-time response within a maximum of 3 seconds. CanCal dramatically reduces average CPU utilization by 91.04\\% (from 6.7\\% to 0.6\\%) and peak CPU utilization by 76.69\\% (from 26.6\\% to 6.2\\%), while avoiding 76.50\\% (from 3,192 to 750) of the inspection efforts from security analysts. By the time of this writing, CanCal has been integrated into a commercial product and successfully deployed on 3.32 million endpoints for over a year. From March 2023 to April 2024, CanCal successfully detected and thwarted 61 ransomware attacks. A detailed manual forensic analysis of 27 ransomware attacks from March to June 2023 (including 13 n-day exploits and 5 high-risk zero-day attacks) demonstrates the effectiveness of CanCal in combating sophisticated and unknown ransomware threats in real-world scenarios.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690269",
    "comment": ""
  },
  {
    "title": "RIoTFuzzer: Companion App Assisted Remote Fuzzing for Detecting Vulnerabilities in IoT Devices",
    "author": "Liu, Kaizheng and Yang, Ming and Ling, Zhen and Zhang, Yue and Lei, Chongqing and Luo, Junzhou and Fu, Xinwen",
    "abstract": "Due to the diversity of architectures and peripherals of Internet of Things (IoT) systems, blackbox fuzzing stands out as a prime option for discovering vulnerabilities of IoT devices. Existing blackbox fuzzing tools often rely on companion apps to generate valid fuzzing packets. However, existing methods encounter the challenges of bypassing the cloud server side validation when it comes to fuzz devices that rely on cloud-based communication. Moreover, they tend to concentrate their efforts on Java components within Android companion apps, limiting their effectiveness in assessing non-Java components such as JavaScript-based mini-apps. In this paper, we introduce a novel blackbox fuzzing method, named RIoTFuzzer, designed to remotely uncover vulnerabilities of IoT devices with the assistance of companion apps, particularly those powered by All-in-one Apps with the JavaScript-based mini-apps feature enabled. Our approach utilizes document-based control command extraction, hybrid analysis for mutation point identification and side-channel-guided fuzzing to effectively address the challenges of fuzzing IoT devices remotely. We apply RIoTFuzzer to 27 IoT devices on prominent platforms and discovered 11 vulnerabilities. All of them have been acknowledged by the corresponding vendors. 8 have been confirmed by the vendors and have been assigned 4 CVE IDs. Our experiment results also demonstrate that side-channel-guided fuzzing can significantly enhance the efficiency of fuzzing packets sent to IoT devices, with an average increase of 76.62\\% and a maximum increase of 362.62\\%.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670342",
    "comment": ""
  },
  {
    "title": "OctopusTaint: Advanced Data Flow Analysis for Detecting Taint-Based Vulnerabilities in IoT/IIoT Firmware",
    "author": "Qasem, Abdullah and Debbabi, Mourad and Soeanu, Andrei",
    "abstract": "The widespread integration of Internet of Things (IoT) and Industrial IoT (IIoT) devices in respectively home and business environments offers both benefits and perils. While these devices, such as IP cameras and network routers improve operational efficiency with their user-friendly web interfaces, they also broaden the potential for cybersecurity vulnerabilities. Recent studies highlight the vulnerability of these devices to taint-based attacks, demonstrating that even attackers with limited permissions can gain control of a device. Current state-of-the-art solutions for mitigating these risks primarily utilize Dynamic Symbolic Execution (DSE). Although effective, DSE is computationally costly and challenging for large-scale analysis. Besides, during inspection, these approaches typically exhibit over-taint behavior by producing a large number of alerts, many of which are false positives due to ineffective handling of sanitization measures that might be in place. To overcome these limitations, we introduce OctopusTaint, an innovative static-based taint analysis approach that integrates advanced data flow analysis with backtracking techniques. OctopusTaint is distinguished by its integration of a sanitization inspection module and sophisticated post-processing filters. These features are specifically designed to minimize false positives effectively while ensuring the accurate identification of genuine security threats. OctopusTaint also excels in tracking transformed tainted inputs across NVRAM, identifying new user-defined taint source functions while addressing the challenges associated with indirect calls and aliasing. Through comparative performance evaluations, OctopusTaint demonstrates superior performance over the current state-of-the-art solutions, SaTC, EmTaint, and MangoDFA. It reports genuine extra tainted sinks in considerable less time (24\\% faster). Furthermore, OctopusTaint identifies 82\\% of tainted sinks within EmTaint 's labeled dataset while exhibiting its advanced capability in sanitization inspection. It correctly flags as sanitized 320 sinks, which were misidentified as genuine alerts by EmTaint. Furthermore, OctopusTaint uncovers additional candidates overlooked by EmTaint, leveraging its enhanced detection mechanisms for new taint sources. OctopusTaint successfully identifies 142 n -day vulnerabilities previously reported by SaTC and EmTaint, in addition to discovering dozens of potential 0-day candidates.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690307",
    "comment": ""
  },
  {
    "title": "AutoPatch: Automated Generation of Hotpatches for Real-Time Embedded Devices",
    "author": "Salehi, Mohsen and Pattabiraman, Karthik",
    "abstract": "Real-time embedded devices like medical or industrial devices are increasingly targeted by cyber-attacks. Prompt patching is crucial to mitigate the serious consequences of such attacks on these devices. Hotpatching is an approach to apply a patch to mission-critical embedded devices without rebooting them. However, existing hotpatching approaches require developers to manually write the hotpatch for target systems, which is time-consuming and error-prone.To address these issues, we propose AutoPatch, a new hotpatching technique that automatically generates functionally equivalent hotpatches via static analysis of the official patches. AutoPatch introduces a new software triggering approach that supports diverse embedded devices, and preserves the functionality of the official patch. In contrast to prior work, AutoPatch does not rely on hardware support for triggering patches, or on executing patches in specialized virtual machines. We implemented AutoPatch using the LLVM compiler, and evaluated its efficiency, effectiveness and generality using 62 real CVEs on four embedded devices with different specifications and architectures running popular RTOSes. We found that AutoPatch can fix more than 90\\% of CVEs, and resolve the vulnerability successfully. The results revealed an average total delay of less than 12.7 μs for fixing the vulnerabilities, representing a performance improvement of 50\\% over RapidPatch, a state-of-the-art approach. Further, our memory overhead, on average, was slightly lower than theirs (23\\%). Finally, AutoPatch was able to generate hotpatches for all four devices without any modifications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690255",
    "comment": ""
  },
  {
    "title": "Obfuscated Key Exchange",
    "author": "G\\\"{u}nther, Felix and Stebila, Douglas and Veitch, Shannon",
    "abstract": "Censorship circumvention tools enable clients to access endpoints in a network despite the presence of a censor. Censors use a variety of techniques to identify content they wish to block, including filtering traffic patterns that are characteristic of proxy or circumvention protocols and actively probing potential proxy servers. Circumvention practitioners have developed fully encrypted protocols (FEPs), intended to have traffic that appears indistinguishable from random. A FEP is typically composed of a key exchange protocol to establish shared secret keys, and then a secure channel protocol to encrypt application data; both must avoid revealing to observers that an obfuscated protocol is in use.We formalize the notion of obfuscated key exchange, capturing the requirement that a key exchange protocol's traffic \"looks random\" and that it resists active probing attacks, in addition to ensuring secure session keys and authentication. We show that the Tor network's obfs4 protocol satisfies this definition. We then show how to extend the obfs4 design to defend against stronger censorship attacks and present a quantum-safe obfuscated key exchange protocol. To instantiate our quantum-safe protocol using the ML-KEM (Kyber) standard, we present Kemeleon, a new mapping between ML-KEM public keys/ciphertexts and uniform byte strings.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690220",
    "comment": ""
  },
  {
    "title": "Quarantined-TreeKEM: A Continuous Group Key Agreement for MLS, Secure in Presence of Inactive Users",
    "author": "Chevalier, C\\'{e}line and Lebrun, Guirec and Martinelli, Ange and Taleb, Abdul Rahman",
    "abstract": "The recently standardized secure group messaging protocol Messaging Layer Security (MLS) is designed to ensure asynchronous communications within large groups, with an almost-optimal communication cost and the same security level as point-to-point secure messaging protocols such as Signal. In particular, the core sub-protocol of MLS, a Continuous Group Key Agreement (CGKA) called TreeKEM, must generate a common group key that respects the fundamental security properties of post-compromise security and forward secrecy which mitigate the effects of user corruption over timeMost research on CGKAs has focused on how to improve these two security properties. However, post-compromise security and forward secrecy require the active participation of respectively all compromised users and all users within the group. Inactive users - who remain offline for long periods - do not update anymore their encryption keys and therefore represent a vulnerability for the entire group. This issue has already been identified in the MLS standard, but no solution, other than expelling these inactive users after some disconnection time, has been found.We propose here a CGKA protocol based on TreeKEM and fully compatible with the MLS standard, that implements a quarantine mechanism for the inactive users in order to mitigate the risk induced by these users during their inactivity period and before they are removed from the group. That mechanism indeed updates the inactive users' encryption keys on their behalf and secures these keys with a secret sharing scheme. If some of the inactive users eventually reconnect, their quarantine stops and they are able to recover all the messages that were exchanged during their offline period. Our Quarantined-TreeKEM protocol thus increases the security of original TreeKEM, with a very limited - and sometimes negative - communication overhead.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690265",
    "comment": ""
  },
  {
    "title": "Complete Knowledge: Preventing Encumbrance of Cryptographic Secrets",
    "author": "Kelkar, Mahimna and Babel, Kushal and Daian, Philip and Austgen, James and Buterin, Vitalik and Juels, Ari",
    "abstract": "Most cryptographic protocols model a player's knowledge of secrets in a simple way. Informally, the player knows a secret in the sense that she can directly furnish it as a (private) input to a protocol, e.g., to digitally sign a message.  The growing availability of Trusted Execution Environments (TEEs) and multiparty computation (MPC), however, undermines this model of knowledge. Such tools can encumber a secret sk and permit a chosen player to access sk conditionally, without actually knowing sk. By permitting selective access to sk by an adversary, encumbrance of secrets can enable vote-selling in cryptographic voting schemes, illegal sale of credentials for online services, and erosion of deniability in anonymous messaging systems. Unfortunately, existing proof-of-knowledge protocols fail to demonstrate that a secret is unencumbered. We therefore introduce and formalize a new notion called complete knowledge (CK). A proof (or argument) of CK shows that a prover does not just know a secret, but also has fully unencumbered knowledge, i.e., unrestricted ability to use the secret.  We introduce two practical CK schemes that use special-purpose hardware, specifically TEEs and off-the-shelf mining ASICs. We prove the security of these schemes and explore their practical deployment with a complete, open-source, end-to-end prototype with smart-contract verification that supports both. We show how CK can address encumbrance attacks identified in previous work. Finally, we introduce two new applications enabled by CK that involve proving ownership of blockchain assets.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690273",
    "comment": ""
  },
  {
    "title": "The Insecurity of Masked Comparisons: SCAs on ML-KEM's FO-Transform",
    "author": "Hermelink, Julius and Ning, Kai-Chun and Petri, Richard and Strieder, Emanuele",
    "abstract": "NIST released the draft standard for ML-KEM, and we can expect its widespread use in the embedded world in the near future. Several side-channel attacks have been proposed, and one line of research has focused on attacks against the comparison step of the FO-transform. A work published at TCHES 2022 stressed the need for secure higher-order masked comparisons beyond the t-probing model and proposed a higher-order masked comparison method. Subsequently, D'Anvers, Van Beirendonck, and Verbauwhede improved upon the performance of several previous proposals; their higher-order masked algorithm currently achieves the highest performance for masked comparisons. In this work, we show that while this proposal is secure in the t-probing model, its security in practice is questionable. We first propose an approximate template attack that requires only a small number of traces for profiling and has an exceptionally high noise tolerance. We demonstrate that, without knowledge of the targeted values, a vertical analysis of the distribution of certain points of interest can replace the profiling phase. Finally, we explain how a decryption failure oracle may be constructed from a single trace.We prove that these attacks are not affected by higher masking orders for noise levels that by far prevent previous profiled attacks on ML-KEM. Further, we provide simulations showing that even under extreme noise levels, the attacks are not prevented by realistic masking orders.Additionally, we carry out the attacks on multiple physical devices to stress the practicality of our attack. We discuss the underlying causes for our attack, demonstrate the difficulty of securing the FO-transform in ML-KEM, draw conclusions about the (in-)sufficiency of t-probing security in this context, and highlight an open gap in securing ML-KEM on embedded devices.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690339",
    "comment": ""
  },
  {
    "title": "Password-Protected Key Retrieval with(out) HSM Protection",
    "author": "Faller, Sebastian and Handirk, Tobias and Hesse, Julia and Horv\\'{a}th, M\\'{a}t\\'{e} and Lehmann, Anja",
    "abstract": "Password-protected key retrieval (PPKR) enables users to store and retrieve high-entropy keys from a server securely. The process is bootstrapped from a human-memorizable password only, addressing the challenge of how end-users can manage cryptographic key material. The core security requirement is protection against a corrupt server, which should not be able to learn the key or offline- attack it through the password protection. PPKR is deployed at a large scale with the WhatsApp Backup Protocol (WBP), allowing users to access their encrypted messaging history when switching to a new device. Davies et al. (Crypto'23) formally analyzed the WBP, proving that it satisfies most of the desired security. The WBP uses the OPAQUE protocol for password-based key exchange as a building block and relies on the server using a hardware security module (HSM) for most of its protection. In fact, the security analysis assumes that the HSM is incorruptible - rendering most of the heavy cryptography in the WBP obsolete. In this work, we explore how provably secure and efficient PPKR can be built that either relies strongly on an HSM - but then takes full advantage of that - or requires less trust assumption for the price of more advanced cryptography. To this end, we expand the definitional work by Davies et al. to allow the analysis of PPKR with fine-grained HSM corruption, such as leakage of user records or attestation keys. For each scenario, we aim to give minimal PPKR solutions. For the strongest corruption setting, namely a fully corrupted HSM, we propose a protocol with a simpler design and better efficiency than the WBP. We also fix an attack related to client authentication that was identified by Davies et al.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690358",
    "comment": ""
  },
  {
    "title": "Non-Transferable Anonymous Tokens by Secret Binding",
    "author": "Durak, F. Bet\\\"{u}l and Marco, Laurane and Talayhan, Abdullah and Vaudenay, Serge",
    "abstract": "Non-transferability (NT) is a security notion which ensures that credentials are only used by their intended owners. Despite its importance, it has not been formally treated in the context of anonymous tokens (AT) which are lightweight anonymous credentials. In this work, we consider a client who \"buys\" access tokens which are forbidden to be transferred although anonymously redeemed. We extensively study the trade-offs between privacy (obtained through anonymity) and security in AT through the notion of non-transferability. We formalise new security notions, design a suite of protocols with various flavors of NT, prove their security, and implement the protocols to assess their efficiency. Finally, we study the existing anonymous credentials which offer NT, and show that they cannot automatically be used as AT without security and complexity implications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670338",
    "comment": ""
  },
  {
    "title": "DPad-HE: Towards Hardware-friendly Homomorphic Evaluation using 4-Directional Manipulation",
    "author": "Tang, Wenxu and Zheng, Fangyu and Fan, Guang and Zhou, Tian and Lin, Jingqiang and Jing, Jiwu",
    "abstract": "Module Learning with Errors (MLWE) based approaches for Fully Homomorphic Encryption (FHE) have garnered attention due to their potential to enhance hardware-friendliness and implementation efficiency. However, despite these advantages, their overall performance still trails behind traditional schemes based on Ring Learning with Errors (RLWE). This indicates that while MLWE-based constructions hold promise, there remain significant challenges to overcome in bridging the performance gap with RLWE-based FHE schemes. By uncovering the reasons for the unsatisfactory performance of prior schemes and pinpointing the fundamental differences in the design of MLWE-based FHE compared to traditional approaches, the paper introduces DPad-HE with a novel design incorporating manipulation in the module rank dimension. The newly introduced operations, rank-up, and rank-down, effectively regulate the scale of gadget decomposition, reducing the computational workload of key-switching by several times. Taking CKKS as a case study, the evaluation showcases the comprehensive advantages of DPad-HE over the state-of-the-art MLWE-based scheme, resulting in a performance boost of 1.26\\texttimes{} to 5.71\\texttimes{}, a reduction in key size from 1/3 to 3/4, with enhanced noise control. To test the hardware-friendliness of the solution, DPad-HE is also implemented on GPU. Notably, DPad-HE demonstrates that, for the first time, the execution latency of MLWE-based schemes can achieve comparable performance with traditional RLWE ones, especially on the GPU platform where a speedup up to 1.41\\texttimes{} is witnessed. Additionally, this paper provides a lightweight conversion method between RLWE and MLWE ciphertexts, allowing for flexible selection of RLWE and MLWE settings during a single complete evaluation process. This opens up new possibilities for both RLWE-based and MLWE-based FHEs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690280",
    "comment": ""
  },
  {
    "title": "Rhombus: Fast Homomorphic Matrix-Vector Multiplication for Secure Two-Party Inference",
    "author": "He, Jiaxing and Yang, Kang and Tang, Guofeng and Huang, Zhangjie and Lin, Li and Wei, Changzheng and Yan, Ying and Wang, Wei",
    "abstract": "We present Rhombus, a new secure matrix-vector multiplication (MVM) protocol in the semi-honest two-party setting, which is able to be seamlessly integrated into existing privacy-preserving machine learning (PPML) frameworks and serve as the basis of secure computation in linear layers. Rhombus adopts RLWE-based homomorphic encryption (HE) with coefficient encoding, which allows messages to be chosen from not only a field Fp but also a ring Z2l, where the latter supports faster computation in non-linear layers. To achieve better efficiency, we develop an input-output packing technique that reduces the communication cost incurred by HE with coefficient encoding by about 21\\texttimes{}, and propose a split-point picking technique that reduces the number of rotations to that sublinear in the matrix dimension. Compared to the recent protocol HELiKs by Balla and Koushanfar (CCS'23), our implementation demonstrates that Rhombus improves the whole performance of an MVM protocol by a factor of 7.4x ~ 8x, and improves the end-to-end performance of secure two-party inference of ResNet50 by a factor of 4.6x ~ 18x.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690281",
    "comment": ""
  },
  {
    "title": "Attacks Against the IND-CPAD Security of Exact FHE Schemes",
    "author": "Cheon, Jung Hee and Choe, Hyeongmin and Passel\\`{e}gue, Alain and Stehl\\'{e}, Damien and Suvanto, Elias",
    "abstract": "A recent security model for fully homomorphic encryption (FHE), called IND-CPAD security and introduced by Li and Micciancio [Eurocrypt'21], strengthens IND-CPA security by giving the attacker access to a decryption oracle for ciphertexts for which it should know the underlying plaintexts. This includes ciphertexts that it (honestly) encrypted and those obtained from the latter by evaluating circuits that it chose. Li and Micciancio singled out the CKKS FHE scheme for approximate data [Asiacrypt'17] by giving an IND-CPAD attack on it and claiming that IND-CPA security and IND-CPAD security coincide for exact FHE schemes.We correct the widespread belief according to which IND-CPA^D attacks are specific to approximate homomorphic computations. Indeed, the equivalency formally proved by Li and Micciancio assumes that the schemes have a negligible probability of incorrect decryption. However, almost all competitive implementations of exact FHE schemes give away strong correctness by analyzing correctness heuristically and allowing noticeable probabilities of incorrect decryption.We exploit this imperfect correctness to mount efficient non-adaptive indistinguishability and key-recovery attacks against all major exact FHE schemes. We illustrate their strength by implementing them for BFV using OpenFHE and simulating an attack for the default parameter set of the CGGI implementation of TFHE-rs (the attack experiment is too expensive to be run on commodity desktops, because of the cost of CGGI bootstrapping). Our attacks extend to CKKS for discrete data, and threshold versions of the exact FHE schemes, when the correctness is similarly loose.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690341",
    "comment": ""
  },
  {
    "title": "VERITAS: Plaintext Encoders for Practical Verifiable Homomorphic Encryption",
    "author": "Chatel, Sylvain and Knabenhans, Christian and Pyrgelis, Apostolos and Troncoso, Carmela and Hubaux, Jean-Pierre",
    "abstract": "Homomorphic encryption has become a practical solution for protecting the privacy of computations on sensitive data. However, existing homomorphic encryption pipelines do not guarantee the correctness of the computation result in the presence of a malicious adversary. We propose two plaintext encodings compatible with state-of-the-art fully homomorphic encryption schemes that enable practical client-verification of homomorphic computations while supporting all the operations required for modern privacy-preserving analytics. Based on these encodings, we introduce VERITAS, a ready-to-use library for the verification of computations executed over encrypted data. VERITAS is the first library that supports the verification of any homomorphic operation. We demonstrate its practicality for various applications and, in particular, we show that it enables verifiability of homomorphic analytics with less than 3x computation overhead compared to the homomorphic encryption baseline.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670282",
    "comment": ""
  },
  {
    "title": "Simpler and Faster BFV Bootstrapping for Arbitrary Plaintext Modulus from CKKS",
    "author": "Kim, Jaehyung and Seo, Jinyeong and Song, Yongsoo",
    "abstract": "Bootstrapping is currently the only known method for constructing fully homomorphic encryptions. In the BFV scheme specifically, bootstrapping aims to reduce the error of a ciphertext while preserving the encrypted plaintext. The existing BFV bootstrapping methods follow the same pipeline, relying on the evaluation of a digit extraction polynomial to annihilate the error located in the least significant digits. However, due to its strong dependence on performance, bootstrapping could only utilize a limited form of plaintext modulus, such as a power of a small prime number.In this paper, we present a novel approach to instantiate BFV bootstrapping, distinct from the previous digit extraction-based method. The core idea of our bootstrapping is to utilize CKKS bootstrapping as a subroutine, so the performance of our method mainly depends on the underlying CKKS bootstrapping rather than the plaintext modulus.We implement our method at a proof-of-concept level to provide concrete benchmark results. When performing the bootstrapping operation for a 51-bits plaintext modulus, our method improves the previous digit extraction-based method by a factor of 37.9 in latency and 29.4 in throughput. Additionally, we achieve viable bootstrapping performance for large plaintext moduli, such as 144-bits and 234-bits, which has never been measured before.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670302",
    "comment": ""
  },
  {
    "title": "New Secret Keys for Enhanced Performance in (T)FHE",
    "author": "Bergerat, Loris and Chillotti, Ilaria and Ligier, Damien and Orfila, Jean-Baptiste and Roux-Langlois, Adeline and Tap, Samuel",
    "abstract": "Fully Homomorphic Encryption has known impressive improvements in the last 15 years, going from a technology long thought to be impossible to an existing family of encryption schemes able to solve a plethora of practical use cases related to the privacy of sensitive information. Recent results mainly focus on improving techniques within the traditionally defined framework of GLWE-based schemes, but the recent CPU implementation improvements are mainly incremental. To keep improving this technology, one solution is to modify the aforementioned framework, by using slightly different hardness assumptions.In this paper, we identify two limitations with (T)FHE: (i) there is no fine-grained control over the size of a GLWE secret key, which is traditionally composed of k polynomials with N=2α >1 coefficients; (ii) for security reasons one cannot use a noise variance smaller than a certain σmin so, for all ciphertext modulus q ∈ N, there exists an integer nplateau such that, with any secret key of size k ⋅ N ≥ nplateau, one cannot control their level of security, resulting in unnecessary big security levels.To overcome the aforementioned limitations, we introduce two new types of secret keys for GLWE-based cryptosystems, that can be used separately or together. We explain why these new secret keys are as secure as the traditional ones and we detail all the improvements that they bring to existing FHE algorithms alongside new algorithms especially efficient with these new keys. We provide many comparisons with state-of-the-art TFHE techniques with traditional secret keys, and some benchmarks showing computational speed-ups between 1.3 and 2.4 while keeping the same level of security and failure probability (correctness). Furthermore, the size of the key switching and bootstrapping keys is also reduced with this contribution by factors ranging from 1.5 to 2.7.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670376",
    "comment": ""
  },
  {
    "title": "Payout Races and Congested Channels: A Formal Analysis of Security in the Lightning Network",
    "author": "Weintraub, Ben and Kumble, Satwik Prabhu and Nita-Rotaru, Cristina and Roos, Stefanie",
    "abstract": "The Lightning Network, a payment channel network with a market cap of over 192M USD, is designed to resolve Bitcoin's scalability issues through fast off-chain transactions. There are multiple Lightning Network client implementations, all of which conform to the same textual specifications known as BOLTs. Several vulnerabilities have been manually discovered, but to-date there have been few works systematically analyzing the security of the Lightning Network.In this work, we take a foundational approach to analyzing the security of the Lightning Network with the help of formal methods. Based on the BOLTs' specifications, we build a detailed formal model of the Lightning Network's single-hop payment protocol and verify it using the Spin model checker. Our model captures both concurrency and error semantics of the payment protocol. We then define several security properties which capture the correct intermediate operation of the protocol, ensuring that the outcome is always certain to both channel peers, and using them we re-discover a known attack previously reported in the literature along with a novel attack, referred to as a Payout Race. A Payout Race consists of a particular sequence of events that can lead to an ambiguity in the protocol in which innocent users can unwittingly lose funds. We confirm the practicality of this attack by reproducing it in a local testbed environment.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670315",
    "comment": ""
  },
  {
    "title": "DoubleUp Roll: Double-spending in Arbitrum by Rolling It Back",
    "author": "Sun, Zhiyuan and Li, Zihao and Peng, Xinghao and Luo, Xiapu and Jiang, Muhui and Zhou, Hao and Zhang, Yinqian",
    "abstract": "Optimistic rollup protocols are widely adopted as the most popular blockchain scaling solutions. As a dominant implementation, Arbitrum has boasted a total locked value exceeding 18 billion USD, highlighting the significance of optimistic rollups in blockchain ecosystem. Despite their popularity, little research has been done on the security of optimistic rollup protocols, and potential vulnerabilities on them remain unknown.In this work, we unveil three novel double spending attacks on Arbitrum, each enabling an attacker to steal funds from cross-chain applications on Arbitrum. To facilitate these double spending attacks, we introduce an attack to induce manipulable delays in the transaction rollup process and propose a cost optimization solution to reduce further transaction fees associated with the attacks. Our investigations broaden the exploitation of our double spending attacks to another leading optimistic rollup protocol, Optimism, highlighting the generability of our proposed attacks. Through extensive experiments on a local test network, we demonstrated that our attacks lead to severe malicious effects, such as fund losses from double spending. From late 2022 to early 2023, we reported these vulnerabilities to the Arbitrum and Optimism teams. All the issues were acknowledged and resolved, and our research safeguarded billions of dollars at risk, earning us half a million dollars in bug bounty rewards.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690256",
    "comment": ""
  },
  {
    "title": "Rolling in the Shadows: Analyzing the Extraction of MEV Across Layer-2 Rollups",
    "author": "Ferreira Torres, Christof and Mamuti, Albin and Weintraub, Ben and Nita-Rotaru, Cristina and Shinde, Shweta",
    "abstract": "The emergence of decentralized finance has transformed asset trading on the blockchain, making traditional financial instruments more accessible while also introducing a series of exploitative economic practices known as Maximal Extractable Value (MEV). Concurrently, decentralized finance has embraced rollup-based Layer-2 solutions to facilitate asset trading at reduced transaction costs compared to Layer-1 solutions such as Ethereum. However, rollups lack a public mempool like Ethereum, making the extraction of MEV more challenging.In this paper, we investigate the prevalence and impact of MEV on Ethereum and prominent rollups such as Arbitrum, Optimism, and zkSync over a nearly three-year period. Our analysis encompasses various metrics including volume, profits, costs, competition, and response time to MEV opportunities. We discover that MEV is widespread on rollups, with trading volume comparable to Ethereum. We also find that, although MEV costs are lower on rollups, profits are also significantly lower compared to Ethereum. Additionally, we examine the prevalence of sandwich attacks on rollups. While our findings did not detect any sandwiching activity on popular rollups, we did identify the potential for cross-layer sandwich attacks facilitated by transactions that are sent across rollups and Ethereum. Consequently, we propose and evaluate the feasibility of three novel attacks that exploit cross-layer transactions, revealing that attackers could have already earned approximately 2 million USD through cross-layer sandwich attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690259",
    "comment": ""
  },
  {
    "title": "Sui Lutris: A Blockchain Combining Broadcast and Consensus",
    "author": "Blackshear, Sam and Chursin, Andrey and Danezis, George and Kichidis, Anastasios and Kokoris-Kogias, Lefteris and Li, Xun and Logan, Mark and Menon, Ashok and Nowacki, Todd and Sonnino, Alberto and Williams, Brandon and Zhang, Lu",
    "abstract": "Sui Lutris is the first smart-contract platform to sustainably achieve sub-second finality. It achieves this significant decrease by employing consensusless agreement not only for simple payments but for a large variety of transactions. Unlike prior work, Sui Lutris neither compromises expressiveness nor throughput and can run perpetually without restarts. Sui Lutris achieves this by safely integrating consensuless agreement with a high-throughput consensus protocol that is invoked out of the critical finality path but ensures that when a transaction is at risk of inconsistent concurrent accesses, its settlement is delayed until the total ordering is resolved. Building such a hybrid architecture is especially delicate during reconfiguration events, where the system needs to preserve the safety of the consensusless path without compromising the long-term liveness of potentially misconfigured clients. We thus develop a novel reconfiguration protocol, the first to provably show the safe and efficient reconfiguration of a consensusless blockchain. Sui Lutris is currently running in production and underpins the Sui smart-contract platform. Combined with the use of Objects instead of accounts it enables the safe execution of smart contracts that expose objects as a first-class resource. In our experiments Sui Lutris achieves latency lower than 0.5 seconds for throughput up to 5,000 certificates per second (150k ops/s with transaction blocks), compared to the state-of-the-art real-world consensus latencies of 3 seconds. Furthermore, it gracefully handles validators crash-recovery and does not suffer visible performance degradation during reconfiguration.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670286",
    "comment": ""
  },
  {
    "title": "Random Beacons in Monte Carlo: Efficient Asynchronous Random Beacon without Threshold Cryptography",
    "author": "Bandarupalli, Akhil and Bhat, Adithya and Bagchi, Saurabh and Kate, Aniket and Reiter, Michael K.",
    "abstract": "Regular access to unpredictable and bias-resistant randomness is important for applications such as blockchains, voting, and secure distributed computing. Distributed random beacon protocols address this need by distributing trust across multiple nodes, with the majority of them assumed to be honest. Numerous applications across the blockchain space have led to the proposal of several distributed random beacon protocols, with some already implemented. However, many current random beacon systems rely on threshold cryptographic setups or exhibit high computational costs, while others expect the network to be partial or bounded synchronous. To overcome these limitations, we propose HashRand, a computation and communication-efficient asynchronous random beacon protocol that only demands secure hash and pairwise secure channels to generate beacons. HashRand has a per-node amortized communication complexity of O (λn log(n)) bits per beacon. The computational efficiency of HashRand is attributed to the two orders of magnitude lower time of a one-way Hash computation compared to discrete log exponentiation. Interestingly, besides reduced overhead, HashRand achieves Post-Quantum security by leveraging the secure Hash function against quantum adversaries, setting it apart from other random beacon protocols that use discrete log cryptography. In a geo-distributed testbed of n = 136 nodes, HashRand produces 78 beacons per minute, which is at least 5\\texttimes{} higher than Spurt [IEEE S&P'22]. We also demonstrate the practical utility of HashRand by implementing a Post-Quantum secure Asynchronous SMR protocol, which has a response rate of over 135k transactions per second at a latency of 2.3 seconds over a WAN for n = 16 nodes.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670326",
    "comment": ""
  },
  {
    "title": "Scalable and Adaptively Secure Any-Trust Distributed Key Generation and All-hands Checkpointing",
    "author": "Feng, Hanwen and Mai, Tiancheng and Tang, Qiang",
    "abstract": "The classical distributed key generation protocols (DKG) are resurging due to their widespread applications in blockchain. While efforts have been made to improve DKG communication, practical large-scale deployments are still yet to come due to various challenges, including the heavy overhead (particularly broadcast) in adversarial cases. In this paper, we propose a practical DKG for DLog-based cryptosystems, which achieves (quasi-)linear computation and communication per-node cost with the help of a common coin, even in the face of the maximal amount of Byzantine nodes. Moreover, our protocol is secure against adaptive adversaries, which can corrupt less than half of all nodes. The key to our improvements lies in delegating the most costly operations to an Any-Trust group together with a set of techniques for adaptive security. Moreover, we present a generic transformer that enables us to efficiently deploy a conventional distributed protocol like our DKG, even when the participants have different weights.Our DKG leads to a fully practical instantiation of Filecoin's checkpointing mechanism, in which all validators of a Proof-of-Stake (PoS) blockchain periodically run DKG and threshold signing to create checkpoints on Bitcoin, to enhance the security of the PoS chain. In comparison with the recent checkpointing approach of Babylon (Oakland, 2023), ours enjoys a significantly smaller cost of Bitcoin transaction fees. For 212 validators, our cost is merely 0.4\\% of that incurred by Babylon's approach.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690253",
    "comment": ""
  },
  {
    "title": "Skipping the Security Side Quests: A Qualitative Study on Security Practices and Challenges in Game Development",
    "author": "Klostermeyer, Philip and Amft, Sabrina and H\\\"{o}ltervennhoff, Sandra and Krause, Alexander and Busch, Niklas and Fahl, Sascha",
    "abstract": "The video game market is one of the biggest for software products. Video game development has progressed in the last decades to complex and multifaceted endeavors. Games-as-a-Service significantly impacted distribution and gameplay, requiring providers and developers to consider factors beyond game functionality, including security and privacy. New security challenges emerged, including authentication, payment security, and user data or asset protection. However, the security community lacks in-depth insights into the security experiences, challenges, and practices of modern video game development. This paper aims to address this gap in research and highlights the criticality of considering security in the process.Therefore, we conducted 20 qualitative, semi-structured interviews with various roles of professional and skilled video game development experts, investigating awareness, priorities, knowledge, and practices regarding security in the industry through their first-hand experiences. We find that stakeholders are aware of the urgency of security and related issues. However, they often face obstacles, including a lack of money, time, and knowledge, which force them to put security issues lower in priority. We conclude our work by recommending how the game industry can incorporate security into its development processes while balancing other resources and priorities and illustrating ideas for future research.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690190",
    "comment": ""
  },
  {
    "title": "Selling Satisfaction: A Qualitative Analysis of Cybersecurity Awareness Vendors' Promises",
    "author": "Hielscher, Jonas and Sch\\\"{o}ps, Markus and Opdenbusch, Jens and Reichmann, Felix and Gutfleisch, Marco and Marky, Karola and Parkin, Simon",
    "abstract": "Security awareness and training (SAT) vendors operate in a growing multi-billion dollar market. They publish various marketing promises on their websites to their customers -- organizations of all sizes. This paper investigates how these promises align with customers' needs, how they relate to human-centered security challenges highlighted in prior research, and what narrative is presented regarding the role of employees (as SAT recipients). We also investigate the level of transparency in vendor promises, as to whether it constitutes an information asymmetry. We gathered search terms from n=30 awareness professionals to perform an automated Google search and scraping of SAT vendors' websites. We then performed a thematic analysis of 2,476 statements on 156 websites from 59 vendors. We found that the messaging from SAT vendors precisely targets customers' need for easy-to-implement and compliance-fulfilling SAT products; how SAT products are offered also means that some of the impacts of SAT go unmentioned and are transferred to the customer, such as user support. In this vendor-customer relationship, employees are portrayed as a source of weaknesses, needing an indefinite amount of training to be incorporated into the organization's protection. We conclude with suggestions for SAT vendors and regulators, notably toward an SAT ecosystem that directly links SAT solutions to usable security technologies within the organization environment.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690196",
    "comment": ""
  },
  {
    "title": "\"Modern problems require modern solutions\": Community-Developed Techniques for Online Exam Proctoring Evasion",
    "author": "Simko, Lucy and Hutchinson, Adryana and Isaac, Alvin and Fries, Evan and Sherr, Micah and Aviv, Adam J.",
    "abstract": "COVID-19 caused an abrupt shift towards remote learning, and along with it, an increased adoption of remote, online proctoring technology to both dissuade and identify academic dishonesty (i.e., cheating). This shift also came with significant discontent from students who took to online platforms to both express their displeasure with remote proctoring and the methods they used for evading monitoring methods, essentially discussing _hacks_ to subvert the software and cheat on exams. In this paper, we seek to understand both the methods this online community shares for evading online proctoring and why they do so. Through qualitative analysis of social media videos (n=137) and comments (n=4,297) on YouTube and TikTok, we find both non-technical (e.g., sticky-notes) and deeply technical (e.g., custom virtual machines) methods of evading proctoring. The online videos, as well as the active comment sections, provide an important window into both an (unethical) desire to cheat but also the development of a security mindset. Many see proctoring software as invasive surveillance technology, and the discussion and sharing of methods to subvert it have similar tones to that of the hacker/tinkerer communities who also seek to share their experiences of subverting technology, for fun and profit. We conclude with lessons for the security and privacy community about evading online exam proctoring, as well as a conversation about fairness and equity in proctoring design.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691638",
    "comment": ""
  },
  {
    "title": "\"Better Be Computer or I'm Dumb\": A Large-Scale Evaluation of Humans as Audio Deepfake Detectors",
    "author": "Warren, Kevin and Tucker, Tyler and Crowder, Anna and Olszewski, Daniel and Lu, Allison and Fedele, Caroline and Pasternak, Magdalena and Layton, Seth and Butler, Kevin and Gates, Carrie and Traynor, Patrick",
    "abstract": "Audio deepfakes represent a rising threat to trust in our daily communications. In response to this, the research community has developed a wide array of detection techniques aimed at preventing such attacks from deceiving users. Unfortunately, the creation of these defenses has generally overlooked the most important element of the system - the user themselves. As such, it is not clear whether current mechanisms augment, hinder, or simply contradict human classification of deepfakes. In this paper, we perform the first large-scale user study on deepfake detection. We recruit over 1,200 users and present them with samples from the three most widely-cited deepfake datasets. We then quantitatively compare performance and qualitatively conduct thematic analysis to motivate and understand the reasoning behind user decisions and differences from machine classifications. Our results show that users correctly classify human audio at significantly higher rates than machine learning models, and rely on linguistic features and intuition when performing classification. However, users are also regularly misled by pre-conceptions about the capabilities of generated audio (e.g., that accents and background sounds are indicative of humans). Finally, machine learning models suffer from significantly higher false positive rates, and experience false negatives that humans correctly classify when issues of quality or robotic characteristics are reported. By analyzing user behavior across multiple deepfake datasets, our study demonstrates the need to more tightly compare user and machine learning performance, and to target the latter towards areas where humans are less likely to successfully identify threats.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670325",
    "comment": ""
  },
  {
    "title": "Understanding Legal Professionals' Practices and Expectations in Data Breach Incident Reporting",
    "author": "Gumusel, Ece and Xiao, Yue and Qin, Yue and Qin, Jiaxin and Liao, Xiaojing",
    "abstract": "Legal professionals are essential in analyzing data breach incident reports and guiding the response to comply with data privacy laws and regulations. Their expertise helps mitigate privacy and security risks and prevents failures in privacy compliance. However, little research has been done to understand how legal professionals perceive, react to, and face challenges within the data breach incident reporting procedure. In this study, we conducted a simulated incident report assessment experiment and semi-structured interviews with 33 legal professionals who varied in age, gender, and legal background. We reported the criteria used by legal professionals to identify privacy-related items and also uncovered that the agreement among legal professionals on the concepts of privacy-related items is low. Furthermore, we presented findings regarding the perceptions and strategies of legal professionals concerning legal and regulatory compliance, as well as the key features of incident responses that facilitate efficient analysis of data privacy and security law compliance. After taking into account the challenges and suggestions provided by legal professionals, we concluded this study with recommendations for enhancing the effectiveness of legal compliance analysis for incident responses.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690357",
    "comment": ""
  },
  {
    "title": "Using AI Assistants in Software Development: A Qualitative Study on Security Practices and Concerns",
    "author": "Klemmer, Jan H. and Horstmann, Stefan Albert and Patnaik, Nikhil and Ludden, Cordelia and Burton, Cordell and Powers, Carson and Massacci, Fabio and Rahman, Akond and Votipka, Daniel and Lipford, Heather Richter and Rashid, Awais and Naiakshina, Alena and Fahl, Sascha",
    "abstract": "Following the recent release of AI assistants, such as OpenAI's ChatGPT and GitHub Copilot, the software industry quickly utilized these tools for software development tasks, e.g., generating code or consulting AI for advice. While recent research has demonstrated that AI-generated code can contain security issues, how software professionals balance AI assistant usage and security remains unclear. This paper investigates how software professionals use AI assistants in secure software development, what security implications and considerations arise, and what impact they foresee on security in software development. We conducted 27 semi-structured interviews with software professionals, including software engineers, team leads, and security testers. We also reviewed 190 relevant Reddit posts and comments to gain insights into the current discourse surrounding AI assistants for software development. Our analysis of the interviews and Reddit posts finds that, despite many security and quality concerns, participants widely use AI assistants for security-critical tasks, e.g., code generation, threat modeling, and vulnerability detection. Participants' overall mistrust leads to checking AI suggestions in similar ways to human code. However, they expect improvements and, therefore, a heavier use of AI for security tasks in the future. We conclude with recommendations for software professionals to critically check AI suggestions, for AI creators to improve suggestion security and capabilities for ethical security tasks, and for academic researchers to consider general-purpose AI in software development.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690283",
    "comment": ""
  },
  {
    "title": "SpecMon: Modular Black-Box Runtime Monitoring of Security Protocols",
    "author": "Morio, Kevin and K\\\"{u}nnemann, Robert",
    "abstract": "This work addresses the verification gap between formal protocol specifications and their real-world implementations by monitoring compliance with formal specifications.We achieve this by instrumenting the networking and cryptographic libraries used by applications to generate event streams, even without access to the source code. An efficient algorithm is then employed to match these event streams against valid traces defined in the formal specification. Unlike previous approaches, our algorithm is capable of handling non-determinism, allowing it to support multiple concurrent sessions. Furthermore, our method introduces minimal overhead, as demonstrated through experiments on the WireGuard userspace implementation and a case study based on prior work. Notably, we find that the reference Tamarin model for WireGuard requires only minor adjustments, such as defining wire formats and correcting small inaccuracies uncovered during our case study. Finally, we provide formal proofs of soundness and completeness for our algorithm, ensuring that it accepts only valid event streams according to the specification and guarantees that all such valid streams are recognized.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690197",
    "comment": ""
  },
  {
    "title": "SemPat: From Hyperproperties to Attack Patterns for Scalable Analysis of Microarchitectural Security",
    "author": "Godbole, Adwait and Manerkar, Yatin A. and Seshia, Sanjit A.",
    "abstract": "Microarchitectural security verification of software has seen the emergence of two broad classes of approaches. The first uses non-interference-based semantic security properties which are verified for a given program and a given model of the hardware microarchitecture. The second is based on attack patterns, which, if found in a program execution, indicates the presence of an exploit. We observe that while the former uses a formal specification that can capture several gadget variants targeting the same vulnerability, it is limited by the scalability of verification. While more scalable, patterns must be currently constructed manually, as they are narrower in scope and sensitive to gadget-specific structure.This work develops a technique that, given a non-interference-based semantic security hyperproperty, automatically generates attack patterns up to a certain complexity parameter (called the skeleton size). Thus, we combine the advantages of both approaches: security can be specified by a hyperproperty that uniformly captures several gadget variants, while automatically generated patterns can be used for scalable verification. We implement our approach in a tool and demonstrate the ability to generate new patterns, (e.g., for SpectreV1, SpectreV4) and improved scalability using the generated patterns over hyperproperty-based verification.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690214",
    "comment": ""
  },
  {
    "title": "Block Ciphers in Idealized Models: Automated Proofs and New Security Results",
    "author": "Ambrona, Miguel and Farshim, Pooya and Harasser, Patrick",
    "abstract": "We develop and implement AlgoROM, a tool to systematically analyze the security of a wide class of symmetric primitives in idealized models of computation. The schemes that we consider are those that can be expressed over an alphabet consisting of XOR and function symbols for hash functions, permutations, or block ciphers.We implement our framework in OCaml and apply it to a number of prominent constructions, which include the Luby-Rackoff (LR), key-alternating Feistel (KAF), and iterated Even-Mansour (EM) ciphers, as well as substitution-permutation networks (SPN). The security models we consider are (S)PRP, and strengthenings thereof under related-key (RK), key-dependent message (KD), and more generally key-correlated (KC) attacks.Using AlgoROM, we are able to reconfirm a number of classical and previously established security theorems, and in one case we identify a gap in a proof from the literature (Connolly et al., ToSC'19). However, most results that we prove with AlgoROM are new. In particular, we obtain new positive results for LR, KAF, EM, and SPN in the above models. Our results better reflect the configurations actually implemented in practice, as they use a single idealized primitive. In contrast to many existing tools, our automated proofs do not operate in symbolic models, but rather in the standard probabilistic model for cryptography.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690222",
    "comment": ""
  },
  {
    "title": "Verifiably Correct Lifting of Position-Independent x86-64 Binaries to Symbolized Assembly",
    "author": "Verbeek, Freek and Naus, Nico and Ravindran, Binoy",
    "abstract": "We present an approach to lift position-independent x86-64 binaries to symbolized NASM. Symbolization is a decompilation step that enables binary patching: functions can be modified, and instructions can be interspersed. Moreover, it is the first abstraction step in a larger decompilation chain. The produced NASM is recompilable, and we extensively test the recompiled binaries to see if they exhibit the same behavior as the original ones. In addition to testing, the produced NASM is accompanied with a certificate, constructed in such a way that if all theorems in the certificate hold, symbolization has occurred correctly. The original and recompiled binary are lifted again with a third-party decompiler (Ghidra). These representations, as well as the certificate, are loaded into the Isabelle/HOL theorem prover, where proof scripts ensure that correctness can be proven automatically. We have applied symbolization to various stripped binaries from various sources, from various compilers, and ranging over various optimization levels. We show how symbolization enables binary-level patching, by tackling challenges originating from industry.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690244",
    "comment": ""
  },
  {
    "title": "Gaussian Elimination of Side-Channels: Linear Algebra for Memory Coloring",
    "author": "Hofmann, Jana and Fournet, C\\'{e}dric and K\\\"{o}pf, Boris and Volos, Stavros",
    "abstract": "Memory coloring is a software-based technique to ensure microarchitectural isolation between trust domains sharing a CPU. Prior coloring schemes target individual microarchitectural components and thus provide only partial solutions. In this paper, we provide theoretical foundations and practical algorithms to infer comprehensive coloring schemes for modern cloud CPUs.To this end, we first formulate the requirements for effective memory coloring schemes in a set-theoretic model, including definitions for simultaneous isolation of shared components and uniform utilization of private components. We then algebraically characterize these requirements for microarchitectural components that are indexed by linear functions, which is the prevalent case in today's CPUs. Based on this, we develop efficient algorithms for computing multi-resource coloring schemes from linear indexing functions, and for reverse-engineering unknown linear indexing functions under minimal assumptions.In a case study, we use our algorithms to compute coloring schemes for recent Intel CPUs, and we show how to design indexing functions that maximize the number of supported trust domains.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690263",
    "comment": ""
  },
  {
    "title": "Foundations for Cryptographic Reductions in CCSA Logics",
    "author": "Baelde, David and Koutsos, Adrien and Sauvage, Justine",
    "abstract": "The Computationally Complete Symbolic Attacker (CCSA) approach to security protocol verification relies on probabilistic logics to reason about the interaction traces between a protocol and an arbitrary adversary. The proof assistant Squirrel implements one such logic. CCSA logics come with cryptographic axioms whose soundness derives from the security of standard cryptographic games, e.g. PRF, EUF, IND-CCA. Unfortunately, these axioms are complex to design and implement; so far, these tasks are manual, ad-hoc and error-prone. We solve these issues by providing a formal and systematic method for deriving axioms from cryptographic games. Our method relies on synthesizing an adversary against some cryptographic game, through the notion of bi-deduction. Concretely, we define a rich notion of bi-deduction, justify how to use it to derive cryptographic axioms, provide a proof system for bi-deduction, and an automatic proof-search method which we implemented in Squirrel.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690193",
    "comment": ""
  },
  {
    "title": "Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses",
    "author": "Yang, Yuxin and Li, Qiang and Jia, Jinyuan and Hong, Yuan and Wang, Binghui",
    "abstract": "Federated graph learning (FedGL) is an emerging federated learning (FL) framework that extends FL to learn graph data from diverse sources without accessing the data. FL for non-graph data has shown to be vulnerable to backdoor attacks, which inject a shared backdoor trigger into the training data such that the trained backdoored FL model can predict the testing data containing the trigger as the attacker desires. However, FedGL against backdoor attacks is largely unexplored, and no effective defense exists.In this paper, we aim to address such significant deficiency. First, we propose an effective, stealthy, and persistent backdoor attack on FedGL. Our attack uses a subgraph as the trigger and designs an adaptive trigger generator that can derive the effective trigger location and shape for each graph. Our attack shows that empirical defenses are hard to detect/remove our generated triggers. To mitigate it, we further develop a certified defense for any backdoored FedGL model against the trigger with any shape at any location. Our defense involves carefully dividing a testing graph into multiple subgraphs and designing a majority vote-based ensemble classifier on these subgraphs. We then derive the deterministic certified robustness based on the ensemble classifier and prove its tightness. We extensively evaluate our attack and defense on six graph datasets. Our attack results show our attack can obtain >90\\% backdoor accuracy in almost all datasets. Our defense results show, in certain cases, the certified accuracy for clean testing graphs against an arbitrary trigger with size 20 can be close to the normal accuracy under no attack, while there is a moderate gap in other cases. Source code is available at: https://github.com/Yuxin104/Opt-GDBA. The full report is at: urlhttps://arxiv.org/abs/2407.08935.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690187",
    "comment": ""
  },
  {
    "title": "Two-Tier Data Packing in RLWE-based Homomorphic Encryption for Secure Federated Learning",
    "author": "Zhou, Yufei and Zheng, Peijia and Cao, Xiaochun and Huang, Jiwu",
    "abstract": "Homomorphic Encryption (HE) facilitates the preservation of privacy in federated learning (FL) aggregation. However, HE imposes significant computational and communication overhead. To address this problem, data encoding methods have been introduced that enable batch processing to improving the efficiency of ciphertext usage. The existing methods simply concatenate integer or coefficients assignment in polynomials, which do not fully make use of HE based on ring learning with errors (RLWE). We present a novel two-tier data encoding approach tailored for RLWE-based HE, effectively utilizing RLWE's polynomial structure. Our method involves a dual-level data packing strategy for batch processing at both integer and polynomial levels. At the first tier (integer level), we amalgamate those quantized model data into larger integers. Beyond existing concatenation-based encoding, we introduce a new encoding method derived from the Chinese Remainder Theorem (CRT). This CRT-based method effectively mitigates overflow and error propagation concerns. At the second tier (polynomial level), we transmute the large integers into a polynomial form. Additionally, we propose a new subring decomposition method, i.e., employing ring isomorphism mappings to project multiple large integers into varied sub-polynomial rings. Our dual-tier encoding strategy offers a more flexible and effective batch HE solution. We rigorously analyze the correctness, efficiency, and security of our approach. Our extensive experimental evaluations reveal that secure FL, empowered by our dual-tier encoding technique, markedly enhances computational and communication efficiencies over prevailing batch HE methods.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690191",
    "comment": ""
  },
  {
    "title": "Samplable Anonymous Aggregation for Private Federated Data Analysis",
    "author": "Talwar, Kunal and Wang, Shan and McMillan, Audra and Feldman, Vitaly and Bansal, Pansy and Basile, Bailey and Cahill, Aine and Chan, Yi Sheng and Chatzidakis, Mike and Chen, Junye and Chick, Oliver R. A. and Chitnis, Mona and Ganta, Suman and Goren, Yusuf and Granqvist, Filip and Guo, Kristine and Jacobs, Frederic and Javidbakht, Omid and Liu, Albert and Low, Richard and Mascenik, Dan and Myers, Steve and Park, David and Park, Wonhee and Parsa, Gianni and Pauly, Tommy and Priebe, Christian and Rishi, Rehan and Rothblum, Guy N. and Song, Congzheng and Song, Linmao and Tarbe, Karl and Vogt, Sebastian and Zhou, Shundong and Jina, Vojta and Scaria, Michael and Winstrom, Luke",
    "abstract": "We revisit the problem of designing scalable protocols for private statistics and private federated learning when each device holds its private data. Locally differentially private algorithms require little trust but are (provably) limited in their utility. Centrally differentially private algorithms can allow significantly better utility but require a trusted curator. This gap has led to significant interest in the design and implementation of simple cryptographic primitives, that can allow central-like utility guarantees without having to trust a central server.Our first contribution is to propose a new primitive that allows for efficient implementation of several commonly used algorithms, and allows for privacy accounting that is close to that in the central setting without requiring the strong trust assumptions it entails. Shuffling and aggregation primitives that have been proposed in earlier works enable this for some algorithms, but have significant limitations as primitives. We propose a Samplable Anonymous Aggregation primitive, which computes an aggregate over a random subset of the inputs and show that it leads to better privacy-utility trade-offs for various fundamental tasks. Secondly, we propose a system architecture that implements this primitive and perform a security analysis of the proposed system. Our design combines additive secret-sharing with anonymization and authentication infrastructures.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690224",
    "comment": ""
  },
  {
    "title": "Byzantine-Robust Decentralized Federated Learning",
    "author": "Fang, Minghong and Zhang, Zifan and Hairi and Khanduri, Prashant and Liu, Jia and Lu, Songtao and Liu, Yuchen and Gong, Neil",
    "abstract": "Federated learning (FL) enables multiple clients to collaboratively train machine learning models without revealing their private training data. In conventional FL, the system follows the server-assisted architecture (server-assisted FL), where the training process is coordinated by a central server. However, the server-assisted FL framework suffers from poor scalability due to a communication bottleneck at the server, and trust dependency issues. To address challenges, decentralized federated learning (DFL) architecture has been proposed to allow clients to train models collaboratively in a serverless and peer-to-peer manner. However, due to its fully decentralized nature, DFL is highly vulnerable to poisoning attacks, where malicious clients could manipulate the system by sending carefully-crafted local models to their neighboring clients. To date, only a limited number of Byzantine-robust DFL methods have been proposed, most of which are either communication-inefficient or remain vulnerable to advanced poisoning attacks. In this paper, we propose a new algorithm called BALANCE (<u>B</u>yzantine-robust <u>a</u>veraging through <u>l</u>ocal simil<u>a</u>rity i<u>n</u> de<u>ce</u>ntralization) to defend against poisoning attacks in DFL. In BALANCE, each client leverages its own local model as a similarity reference to determine if the received model is malicious or benign. We establish the theoretical convergence guarantee for BALANCE under poisoning attacks in both strongly convex and non-convex settings. Furthermore, the convergence rate of BALANCE under poisoning attacks matches those of the state-of-the-art counterparts in Byzantine-free settings. Extensive experiments also demonstrate that BALANCE outperforms existing DFL methods and effectively defends against poisoning attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670307",
    "comment": ""
  },
  {
    "title": "Not One Less: Exploring Interplay between User Profiles and Items in Untargeted Attacks against Federated Recommendation",
    "author": "Hao, Yurong and Chen, Xihui and Lyu, Xiaoting and Liu, Jiqiang and Zhu, Yongsheng and Wan, Zhiguo and Mauw, Sjouke and Wang, Wei",
    "abstract": "Federated recommendation (FR) is a decentralised approach to training personalised recommender systems, protecting users' privacy by avoiding data collection. Despite its privacy advantages, FR remains vulnerable to poisoning attacks. We focus on untargeted poisoning attacks against FR which degrade the overall performance of recommender services, leading to a detrimental impact on user experience and service quality. In this paper, we propose a general framework to formalise untargeted attacks and identify the vital role played by the interplay between items and user profiles in determining FR's performance. We present an untargeted attack FRecAttack2 which exploits this interplay. Specifically, we develop various methods for sampling user profiles, which approximate user distributions with and without collusion among malicious users. Then we leverage a new measurement to identify items that can disrupt the original interplay with user profiles, based on the change velocity of items' recommendation scores during optimisation. Extensive experiments demonstrate the superiority of our attack, outperforming existing methods by up to 27.56\\%, and its stealthiness in evading mainstream defences. To counteract untargeted attacks, we present a defence GuardCQ to detect malicious users by quantifying their contribution to boost the right interplay between items and user profiles. Empirical results show that GuardCQ effectively mitigates the attack's impact on FR and enhances the robustness of FR against poisoning attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670365",
    "comment": ""
  },
  {
    "title": "Unveiling the Vulnerability of Private Fine-Tuning in Split-Based Frameworks for Large Language Models: A Bidirectionally Enhanced Attack",
    "author": "Chen, Guanzhong and Qin, Zhenghan and Yang, Mingxin and Zhou, Yajie and Fan, Tao and Du, Tianyu and Xu, Zenglin",
    "abstract": "Recent advancements in pre-trained large language models (LLMs) have significantly influenced various domains. Adapting these models for specific tasks often involves fine-tuning (FT) with private, domain-specific data. However, privacy concerns keep this data undisclosed, and the computational demands for deploying LLMs pose challenges for resource-limited data holders. This has sparked interest in split learning (SL), a Model-as-a-Service (MaaS) paradigm that divides LLMs into smaller segments for distributed training and deployment, transmitting only intermediate activations instead of raw data. SL has garnered substantial interest in both industry and academia as it aims to balance user data privacy, model ownership, and resource challenges in the private fine-tuning of LLMs. Despite its privacy claims, this paper reveals significant vulnerabilities arising from the combination of SL and LLM-FT: the Not-too-far property of fine-tuning and the auto-regressive nature of LLMs. Exploiting these vulnerabilities, we propose Bidirectional Semi-white-box Reconstruction (BiSR), the first data reconstruction attack (DRA) designed to target both the forward and backward propagation processes of SL. BiSR utilizes pre-trained weights as prior knowledge, combining a learning-based attack with a bidirectional optimization-based approach for highly effective data reconstruction. Additionally, it incorporates a Noise-adaptive Mixture of Experts (NaMoE) model to enhance reconstruction performance under perturbation. We conducted systematic experiments on various mainstream LLMs and different setups, empirically demonstrating BiSR's state-of-the-art performance. Furthermore, we thoroughly examined three representative defense mechanisms, showcasing our method's capability to reconstruct private data even in the presence of these defenses.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690295",
    "comment": ""
  },
  {
    "title": "PeTAL: Ensuring Access Control Integrity against Data-only Attacks on Linux",
    "author": "Kim, Juhee and Park, Jinbum and Lee, Yoochan and Song, Chengyu and Kim, Taesoo and Lee, Byoungyoung",
    "abstract": "Data-only attacks are emerging as a new threat to the security of modern operating systems. As a typical data-only attack, memory corruption attacks can compromise the integrity of kernel data, which effectively breaks the premises of access control systems. Unfortunately, the prevalence of memory corruption vulnerabilities allows attackers to exploit them and bypass access control mechanisms. Given the arbitrary memory access capability, attackers can overwrite access control policies or illegally access the kernel resources protected by the access control systems.This paper presents PeTAL, a practical access control integrity solution against data-only attacks on the ARM-based Linux kernel. PeTAL is designed to ensure access control integrity by providing policy integrity and complete enforcement of access control systems. PeTAL first identifies kernel data used as access control policies and kernel data protected by access control policies, based on the user interfaces of the Linux kernel. Then, PeTAL leverages the ARM Pointer Authentication Code (PAC) and Memory Tagging Extension (MTE) to comprehensively protect the integrity of the identified kernel data and pointers. We implemented the prototype of PeTAL and evaluated the performance and the security impact of PeTAL on real AArch64 hardware with PAC and MTE support. Our evaluation results show that PeTAL can effectively thwart memory-corruption-based attacks on access control systems with reasonable performance overheads at most 4\\% on average in user applications, demonstrating its efficient prospects for kernel security",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690184",
    "comment": ""
  },
  {
    "title": "Detecting Broken Object-Level Authorization Vulnerabilities in Database-Backed Applications",
    "author": "Huang, Yongheng and Shi, Chenghang and Lu, Jie and Li, Haofeng and Meng, Haining and Li, Lian",
    "abstract": "Broken object-level authorization (BOLA) vulnerabilities are among the most critical security risks facing database-backed applications. However, there is still a significant gap in our systematic understanding of these vulnerabilities. To bridge this gap, we conducted an in-depth study of 101 real-world BOLA vulnerabilities from opensource applications. Our study revealed the four most common object-level authorization models in database-backed application.The insights gained from our study inspired the development of a new tool called BolaRay. This tool employs a combination of SQL and static analysis to automatically infer the distinct types of object-level authorization models, and subsequently verify whether existing implementations enforce appropriate checks for these models. We evaluated BolaRay using 25 popular database-backed applications, which led to the identification of 193 true vulnerabilities, including 178 vulnerabilities that have never been reported before, at a false positive rate of 21.86\\%. We reported all newly identified vulnerabilities to the corresponding maintainers. To date, 155 vulnerabilities have been confirmed, with 52 CVE IDs granted.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690227",
    "comment": ""
  },
  {
    "title": "AuthSaber: Automated Safety Verification of OpenID Connect Programs",
    "author": "Al Rahat, Tamjid and Feng, Yu and Tian, Yuan",
    "abstract": "Single Sign-On (SSO)-based authentication protocols, like OpenID Connect (OIDC), play a crucial role in enhancing security and privacy in today's interconnected digital world, gaining widespread adoption among the majority of prominent authentication service providers. These protocols establish a structured framework for verifying and authenticating the identities of individuals, organizations, and devices, while avoiding the necessity of sharing sensitive credentials (e.g., passwords) with external entities. However, the security guarantees of these protocols rely on their proper implementation, and real-world implementations can, and indeed often do, contain logical programming errors leading to severe attacks, including authentication bypass and user account takeover. In response to this challenge, we present AuthSaber, an automated verifier designed to assess the real-world OIDC protocol implementations against their standard safety specifications in a scalable manner. AuthSaber addresses the challenges of expressiveness for OIDC properties, modeling multi-party interactions, and automation by first designing a novel specification language based on linear temporal logic, leveraging an automaton-based approach to constrain the space of possible interactions between OIDC entities, and incorporating several domain-specific transformations to obtain programs and properties that can be directly reasoned about by software model checkers. We evaluate AuthSaber on the 15 most popular and widely used OIDC libraries and discover 16 previously unknown vulnerabilities, all of which are responsively disclosed to the developers. Five categories of these vulnerabilities also led to new CVEs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670318",
    "comment": ""
  },
  {
    "title": "Unveiling Collusion-Based Ad Attribution Laundering Fraud: Detection, Analysis, and Security Implications",
    "author": "Zhu, Tong and Shou, Chaofan and Huang, Zhen and Chen, Guoxing and Zhang, Xiaokuan and Meng, Yan and Hao, Shuang and Zhu, Haojin",
    "abstract": "In recent years, the growth of mobile advertising has been driven by in-app programmatic advertising and technologies like Real-Time Bidding (RTB). However, this growth has also led to an increase in ad fraud, such as click injection, background ad activity, etc. While existing studies have primarily concentrated on ad fraud within individual apps or devices, this paper introduces a new form of collusion-based ad fraud, named ad attribution laundering fraud (ALF). ALF involves multiple apps collaborating to deceive advertisers by misrepresenting the app where ads are displayed. The collusion-based approach allows lower-quality apps to exploit the reputable identities of seemingly legitimate apps. This deceives advertisers or ad networks into believing that the advertisements they place are reaching potentially valid end-users on the legitimate app. The seemingly legitimate ad events and ad attribution procedures employed by individual apps in such attacks can evade detection by existing tools.To detect ALF, we design and implement the first detection framework, AlfScan. It overcomes two challenges to extract apps' identities from diverse and obfuscated apps using both static and dynamic analysis techniques, then cross-check the identities to identify ALF. We evaluate AlfScan on a 200-app ground truth dataset, and it achieves 92\\% precision and 92\\% recall. We use AlfScan to conduct a large-scale analysis on 91, 006 apps and identify 4, 515 unique fraudulent apps and 1, 483 fraudulent clusters, exposing patterns among fraudulent developers and revealing reliability issues in third-party app development frameworks. We also find that through ALF, fraudulent apps can generate invalid ad traffic that is 2.43 times to 33.33 greater than the ad traffic they would normally generate. After reporting our findings to 15 ad network companies, 4 companies expressed interest in testing AlfScan. In particular, we have submitted 344 apps to the Unity ad team, and they have confirmed that the apps were involved in fraudulent activities.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670314",
    "comment": ""
  },
  {
    "title": "Gopher: High-Precision and Deep-Dive Detection of Cryptographic API Misuse in the Go Ecosystem",
    "author": "Zhang, Yuexi and Li, Bingyu and Lin, Jingqiang and Li, Linghui and Bai, Jiaju and Jia, Shijie and Wu, Qianhong",
    "abstract": "The complexity of cryptographic APIs and developers' expertise gaps often leads to their improper use, seriously threatening information security. Existing cryptographic API misuse detection tools that rely on black/white-list methods require experts to manually establish detection rules. They struggle to dynamically update rules and scale to cover numerous unofficial cryptographic libraries. Furthermore, as these tools are primarily aimed at non-Go languages, they have limited applicability and accuracy in the Go ecosystem, which is extensively used for security-centric applications. To mitigate these challenges, we present Gopher, a novel cryptographic misuse detection framework, that excels in encapsulated API and cross-library detection. In this framework, we have designed CryDict to convert rules into unified and standardized constraints, capable of deriving new usage rules and elucidating implicit knowledge during scanning. Gopher leverages CryDict to create a logical separation between rule formulation and Detector detection, enabling dynamic updating of constraints and enhancing detection capabilities. This significantly improves the Gopher 's compatibility and scalability. Utilizing Gopher, we have conducted an extensive analysis of the Go ecosystem, examining 19,313 Go projects. In our rigorous testing, Gopher demonstrated a remarkable 98.9\\% accuracy rate and identified 64.1\\% of previously undetected misuses. This scrutiny has surfaced numerous hidden security vulnerabilities, and highlighted misuse tendencies across diverse project categories.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690276",
    "comment": ""
  },
  {
    "title": "uMMU: Securing Data Confidentiality with Unobservable Memory Subsystem",
    "author": "Lim, Hajeong and Kim, Jaeyoon and Lee, Hojoon",
    "abstract": "Ensuring data confidentiality in a computing system's memory hierarchy proved to be a formidable challenge with the large attack surface. Diverse and powerful attacks threaten data confidentiality. Memory safety is notoriously hard to achieve with unsafe languages, thereby empowering adversaries with unauthorized memory accesses, as represented by the HeartBleed incident. More recently, microarchitectural side channel attacks reign as a prevalent threat against data confidentiality that affects program execution including the safeguarded ones inside TEEs.In this paper, we introduce an in-process memory subsystem called uMMU. uMMU coherently consolidates the notion of employing processor registers as unobservable storage with data confidentiality protection techniques such as memory encryption and Oblivious RAM. uMMU creates a new address space called uVirtual address space that is unobservable to adversaries. Under the abstraction created by uMMU, the processor's spacious extended registers, such as Intel x86's AVX512, are transformed into unobservable and addressable physical memory backing. Completing the principles of virtual memory abstraction is the memory management that maintains a secure swap space applied with memory confidentiality policies such as encryption or ORAM. uMMU is a versatile and powerful framework that can host data confidentiality policies on sensitive data. Our real-world evaluation indicates that uMMU significantly improves the performance of programs with encryption and ORAM schemes for sensitive data protection: an average of 69.93\\% improvement in encryption-based protection of sensitive data in MbedTLS, and 497.84\\% for ORAM-based elimination of access patterns on Memcached's hashtable.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690340",
    "comment": ""
  },
  {
    "title": "Secure Parallel Computation with Oblivious State Transitions",
    "author": "Attrapadung, Nuttapong and Isayama, Kota and Sadakane, Kunihiko and Tozawa, Kazunari",
    "abstract": "We introduce Oblivious Parallel Stateful Computation (OPSC), a form of secure multi-party computation (MPC) tailored for stateful machine computation models emphasizing parallel execution across multiple data. OPSC enables parties to compute multiple results simultaneously in a parallel fashion, leveraging all data from current states and auxiliary inputs dynamically entered at that point. With its parallel and dynamic nature, OPSC holds promise for privacy-preserving applications in intricate decision-making scenarios involving multiple agents, such as traffic analyses, individual consumer behavior economics, and epidemiological simulations.We focus on OPSC for binary branch, akin to deterministic finite automata (DFA) with binary alphabet albeit with multiple pebbles moving. A straightforward approach to obtain OPSC with N data and |S| states is to run N instances of MPC for individual DFA, incurring a ~O(N |S|) overhead. Distributed Oblivious RAM (DORAM) is a related primitive that allows efficient oblivious read and write of distributed data and can facilitate OPSC. However, no existing method achieves both constant round and cost less than ~O(N |S|) for all metrics. In this paper, we formalize OPSC and propose a protocol achieving constant round and ~O(N + |S|) costs for all metrics, including communication and storage costs.Our protocols drastically improve storage efficiency, requiring just 408 MB for scenarios with 16 million data and 26,000 states, compared to 24 TB with the DORAM-based approach instantiated with the state-of-the-art DUORAM (Vadapalli et al., USENIX Sec'23), representing a four-order-of-magnitude improvement. Additionally, our online processing time is comparable, with the DUORAM-based approach being about 1.3 times faster.We demonstrate the practical utility of OPSC through a proof of concept for agent-based simulations and apply OPSC to obliviously solve the All Nearest Smaller Values (ANSV) problem, a crucial primitive in parallel computation. Additionally, we explore its application in multiple pattern matching scenarios.At the core of our OPSC design is a new primitive of independent interest: Oblivious Group-Wise Stable Sorting, which enables sorting data within privately partitioned groups. We introduce Oblivious Parallel Stateful Computation (OPSC), a form of secure multi-party computation (MPC) tailored for stateful machine computation models emphasizing parallel execution across multiple data. OPSC enables parties to compute multiple results simultaneously in a parallel fashion, leveraging all data from current states and auxiliary inputs dynamically entered at that point. With its parallel and dynamic nature, OPSC holds promise for privacy-preserving applications in intricate decision-making scenarios involving multiple agents, such as traffic analyses, individual consumer behavior economics, and epidemiological simulations.We focus on OPSC for binary branch, akin to deterministic finite automata (DFA) with binary alphabet albeit with multiple pebbles moving. A straightforward approach to obtain OPSC with N data and |S| states is to run N instances of MPC for individual DFA, incurring a ~O (N |S|) overhead. Distributed Oblivious RAM (DORAM) is a related primitive that allows efficient oblivious read and write of distributed data and can facilitate OPSC. However, no existing method achieves both constant round and cost less than ~O(N |S|) for all metrics. In this paper, we formalize OPSC and propose a protocol achieving constant round and ~O (N + |S|) costs for all metrics, including communication and storage costs.Our protocols drastically improve storage efficiency, requiring just 408 MB for scenarios with 16 million data and 26,000 states, compared to 24 TB with the DORAM-based approach instantiated with the state-of-the-art DUORAM (Vadapalli et al., USENIX Sec'23), representing a four-order-of-magnitude improvement. Additionally, our online processing time is comparable, with the DUORAM-based approach being about 1.3 times faster.We demonstrate the practical utility of OPSC through a proof of concept for agent-based simulations and apply OPSC to obliviously solve the All Nearest Smaller Values (ANSV) problem, a crucial primitive in parallel computation. Additionally, we explore its application in multiple pattern matching scenarios.At the core of our OPSC design is a new primitive of independent interest: Oblivious Group-Wise Stable Sorting, which enables sorting data within privately partitioned groups.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690315",
    "comment": ""
  },
  {
    "title": "Secure Sorting and Selection via Function Secret Sharing",
    "author": "Agarwal, Amit and Boyle, Elette and Chandran, Nishanth and Gilboa, Niv and Gupta, Divya and Ishai, Yuval and Kelkar, Mahimna and Ma, Yiping",
    "abstract": "We revisit the problem of concretely efficient secure computation of sorting and selection (e.g., maximum, median, or top-k) on secret-shared data, focusing on the case of security against a single semi-honest party. Previous solutions either have a high communication overhead or many rounds of interaction, even when allowing input-independent preprocessing.We propose a suite of 2-party and 3-party offline-online protocols that exploit the efficient aggregation feature of function secret sharing to minimize the online communication and rounds. In particular, most of our protocols are optimal in terms of both online communication and online rounds up to small constant factors.We compare the performance of our protocols with prior works for different input parameters (number of items, bit length of items, batch size) and system parameters (CPU cores, network) and obtain up to 14x improvement in online run time for sorting and selection under some settings.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690359",
    "comment": ""
  },
  {
    "title": "Helium: Scalable MPC among Lightweight Participants and under Churn",
    "author": "Mouchet, Christian and Chatel, Sylvain and Pyrgelis, Apostolos and Troncoso, Carmela",
    "abstract": "We introduce Helium, a novel framework that supports scalable secure multiparty computation (MPC) for lightweight participants and tolerates churn. Helium relies on multiparty homomorphic encryption (MHE) as its core building block. While MHE schemes have been well studied in theory, prior works fall short of addressing critical considerations paramount for adoption such as supporting resource-constrained and unstably connected participants. In this work, we systematize the requirements of MHE-based MPC protocols from a practical lens, and we propose a novel execution mechanism that addresses those considerations. We implement this execution mechanism in Helium, which makes it the first implemented framework to support MPC under network churn based solely on cryptographic assumptions. We show that a Helium network of 30 parties connected with 100Mbits/s links and experiencing a system-wide churn rate of 40 failures per minute can compute the product between a fixed 512x512 secret matrix (e.g., a collectively-trained private model) and a fresh secret vector (e.g., a feature vector) 8.3 times per second. This is ~1500 times faster than a state-of-the-art MPC framework operating under no churn.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670346",
    "comment": ""
  },
  {
    "title": "Practical Key-Extraction Attacks in Leading MPC Wallets",
    "author": "Makriyannis, Nikolaos and Yomtov, Oren and Galansky, Arik",
    "abstract": "Multi-Party Computation (MPC) has become a major tool for protecting hundreds of billions of dollars in cryptocurrency wallets. MPC protocols are currently powering the wallets of Coinbase, Binance, Zengo, BitGo, Fireblocks and many other fintech companies servicing thousands of financial institutions and hundreds of millions of end-user consumers.We present four novel key-extraction attacks on popular MPC signing protocols showing how a single corrupted party may extract the secret in full during the MPC signing process. Our attacks are highly practical (the practicality of the attack depends on the number of signature-generation ceremonies the attacker participates in before extracting the key). Namely, we show key-extraction attacks against different threshold-ECDSA protocols/implementations requiring 106, 256, 16, and one signature, respectively. In addition, we provide proof-of-concept code that implements our attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670359",
    "comment": ""
  },
  {
    "title": "Efficient Secret Sharing for Large-Scale Applications",
    "author": "Patel, Sarvar and Persiano, Giuseppe and Seo, Joon Young and Yeo, Kevin",
    "abstract": "Threshold secret sharing enables distributing a message to n parties such that no subset of fewer than t parties can learn the message, whereas any subset of at least t parties can recover the message. Despite being a fundamental primitive, secret sharing still suffers from one significant drawback, where its message reconstruction algorithm is computationally expensive for large privacy thresholds t. In this paper, we aim to address this significant drawback.We study general (t,c)-ramp secret sharing schemes where the number of parties c needed to reconstruct the secret may be larger than t. We present a ramp secret sharing scheme whose reconstruction time is 2-7.8x faster than prior constructions suitable against adversaries that adaptively corrupt parties. For t = 220, our new protocol has reconstruction time of 5 seconds whereas prior work requires nearly half a minute. We see improvements starting from as small as t = 256. Furthermore, we obtain correctness threshold as small as c ≥ 1.05t. To obtain our construction, we first improve the secret sharing frameworks by Cramer et al. (EUROCRYPT'15) and Applebaum et al. (CRYPTO'23) from erasure codes. Our new framework obtains secret sharing schemes that may be used against adversaries with adaptive corruptions while requiring only weaker correctness guarantees from the underlying erasure code with a distributed generation property. Furthermore, our new framework also maintains the linear homomorphism of the prior works. Afterwards, we present a concretely efficient erasure code from random band matrices that satisfies the distributed generation property.We show that our secret sharing scheme can improve many real-world applications. In secure aggregation protocols for federated learning, we obtain up to 22\\% reductions in computational cost by replacing Shamir's scheme with our construction. We extend our protocol to obtain a verifiable ramp secret sharing scheme where each party can verify the consistency of the shares. Our new verifiable ramp secret sharing has 8.2-25.2x faster sharing and 2.7-23.2x faster reconstruction time compared to prior works. Finally, we present an improved distributed verifiable random function that may be used for decentralized randomness beacons.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670379",
    "comment": ""
  },
  {
    "title": "Oblivious Single Access Machines - A New Model for Oblivious Computation",
    "author": "Appan, Ananya and Heath, David and Ren, Ling",
    "abstract": "Oblivious RAM (ORAM) allows a client to securely outsource memory storage to an untrusted server. It has been shown that no ORAM can simultaneously achieve small bandwidth blow-up, small client storage, and a single roundtrip of latency.We consider a weakening of the RAM model, which we call the Single Access Machine (SAM) model. In the SAM model, each memory slot can be written to at most once and read from at most once. We adapt existing tree-based ORAM to obtain an oblivious SAM (OSAM) that has O(log n) bandwidth blow-up (which we show is optimal), small client storage, and a single roundtrip.OSAM unlocks improvements to oblivious data structures/algorithms. For instance, we achieve oblivious unbalanced binary trees (e.g. tries, splay trees). By leveraging splay trees, we obtain a notion of caching ORAM, where an access in the worst case incurs amortized O(log2 n) bandwidth blow-up and O(log n) roundtrips, but in many common cases (e.g. sequential scans) incurs only amortized O(log n) bandwidth blow-up and O(1) roundtrips. We also give new oblivious graph algorithms, including computing minimum spanning trees and single source shortest paths, in which the OSAM client reads/writes O(|E| ⋅ log |E|) words using O(|E|) roundtrips, where |E| is the number of edges. This improves over prior custom solutions by a log factor.At a higher level, OSAM provides a general model for oblivious computation. We construct a programming interface around OSAM that supports arbitrary pointer-manipulating programs such that dereferencing a pointer to an object incurs O(log d log n) bandwidth blowup and O(log d) roundtrips, where d is the number of pointers to that object. This new interface captures a wide variety of data structures and algorithms (e.g., trees, tries, doubly-linked lists) while matching or exceeding prior best asymptotic results. It both unifies much of our understanding of oblivious computation and allows the programmer to write oblivious algorithms combining various common data structures/algorithms and beyond.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690352",
    "comment": ""
  },
  {
    "title": "Tight ZK CPU: Batched ZK Branching with Cost Proportional to Evaluated Instruction",
    "author": "Yang, Yibin and Heath, David and Hazay, Carmit and Kolesnikov, Vladimir and Venkitasubramaniam, Muthuramakrishnan",
    "abstract": "We explore Zero-Knowledge Proofs (ZKPs) of statements expressed as programs written in high-level languages, e.g., C or assembly. At the core of executing such programs in ZK is the repeated evaluation of a CPU step, achieved by branching over the CPU's instruction set. This approach is general and covers traversal-execution of a program's control flow graph (CFG): here CPU instructions are straight-line program fragments (of various sizes) associated with the CFG nodes. This highlights the usefulness of ZK CPUs with a large number of instructions of varying sizes.We formalize and design an efficient tight ZK CPU, where the cost (both computation and communication, for each party) of each step depends only on the instruction taken. This qualitatively improves over state of the art, where cost scales with the size of the largest CPU instruction (largest CFG node).Our technique is formalized in the standard commit-and-prove paradigm, so our results are compatible with a variety of (interactive and non-interactive) general-purpose ZK.We implemented an interactive tight arithmetic (over F261-1) ZK CPU based on Vector Oblivious Linear Evaluation (VOLE) and compared it to the state-of-the-art non-tight VOLE-based ZK CPU Batchman (Yang et al. CCS'23). In our experiments, under the same hardware configuration, we achieve comparable performance when instructions are of the same size and a 5-18\\texttimes{} improvement when instructions are of varied size. Our VOLE-based tight ZK CPU (over F261-1) can execute 100K (resp. 450K) multiplication gates per second in a WAN-like (resp. LAN-like) setting. It requires ≤ 102 Bytes per multiplication gate. Our basic building block, ZK Unbalanced Read-Only Memory, may be of independent interest.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690289",
    "comment": ""
  },
  {
    "title": "Sparrow: Space-Efficient zkSNARK for Data-Parallel Circuits and Applications to Zero-Knowledge Decision Trees",
    "author": "Pappas, Christodoulos and Papadopoulos, Dimitrios",
    "abstract": "Space-efficient SNARKs aim to reduce the prover's space overhead which is one the main obstacles for deploying SNARKs in practice, as it can be prohibitively large (e.g., orders of magnitude larger than natively performing the computation). In this work, we propose Sparrow, a novel space-efficient zero-knowledge SNARK for data-parallel arithmetic circuits with two attractive features: (i) it is the first space-efficient scheme where, for a given field, the prover overhead increases with a multiplicative sublogarithmic factor as the circuit size increases, and (ii) compared to prior space-efficient SNARKs that work for arbitrary arithmetic circuits, it achieves prover space asymptotically smaller than the circuit size itself. Our key building block is a novel space-efficient sumcheck argument with improved prover time which may be of independent interest. Our experimental results for three use cases (arbitrary data parallel circuits, multiplication trees, batch SHA256 hashing) indicate Sparrow outperforms the prior state-of-the-art space-efficient SNARK for arithmetic circuits Gemini (Bootle et al., EUROCRYPT'22) by 3.2-28.7x in total prover space and 3.1-11.3x in prover time. We then use Sparrow to build zero-knowledge proofs of tree training and prediction, relying on its space efficiency to scale to large datasets and forests of multiple trees. Compared to a (non-space-efficient) optimal-time SNARK based on the GKR protocol, we observe prover space reduction of 16-240x for tree training while maintaining essentially the same prover and verifier times and proof size. Even more interestingly, our prover requires comparable space to natively perform the underlying computation. E.g., for a 400MB dataset, our prover only needs 1.4x more space than the native computation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690318",
    "comment": ""
  },
  {
    "title": "The LaZer Library: Lattice-Based Zero Knowledge and Succinct Proofs for Quantum-Safe Privacy",
    "author": "Lyubashevsky, Vadim and Seiler, Gregor and Steuer, Patrick",
    "abstract": "The hardness of lattice problems offers one of the most promising security foundations for quantum-safe cryptography. Basic schemes for public key encryption and digital signatures are already close to standardization at NIST and several other standardization bodies, and the research frontier has moved on to building primitives with more advanced privacy features. At the core of many such primitives are zero-knowledge proofs. In recent years, zero-knowledge proofs for (and using) lattice relations have seen a dramatic jump in efficiency and they currently provide arguably the shortest, and most computationally efficient, quantum-safe proofs for many scenarios. The main difficulty in using these proofs by non-experts (and experts!) is that they have a lot of moving parts and a lot of internal parameters depend on the particular instance that one is trying to prove.Our main contribution is a library for zero-knowledge and succinct proofs which consists of efficient and flexible C code underneath a simple-to-use Python interface. Users without any background in lattice-based proofs should be able to specify the lattice relations and the norm bounds that they would like to prove and the library will automatically create a proof system, complete with the intrinsic parameters, using either the succinct proofs of LaBRADOR (Beullens and Seiler, Crypto 2023) or the linear-size, though smaller for certain application, proofs of Lyubashevsky et al. (Crypto 2022). The Python interface also allows for common operations used in lattice-based cryptography which will enable users to write and prototype their full protocols within the syntactically simple Python environment.We showcase some of the library's usefulness by giving protocol implementations for blind signatures, anonymous credentials, the zero-knowledge proof needed in the recent Swoosh protocol (Gajland et al., Usenix 2024), proving knowledge of Kyber keys, and an aggregate signature scheme. Most of these are the most efficient, from a size, speed, and memory perspective, known quantum-safe instantiations.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690330",
    "comment": ""
  },
  {
    "title": "Real-World Universal zkSNARKs are Non-Malleable",
    "author": "Faonio, Antonio and Fiore, Dario and Russo, Luigi",
    "abstract": "Simulation extractability is a strong security notion of zkSNARKs that guarantees that an attacker who produces a valid proof must know the corresponding witness, even if the attacker had prior access to proofs generated by other users. Notably, simulation extractability implies that proofs are non-malleable and is of fundamental importance for applications of zkSNARKs in distributed systems. In this work, we study sufficient and necessary conditions for constructing simulation-extractable universal zkSNARKs via the popular design approach based on compiling polynomial interactive oracle proofs (PIOP). Our main result is the first security proof that popular universal zkSNARKs, such as PLONK and Marlin, as deployed in the real world, are simulation-extractable. Our result fills a gap left from previous work (Faonio et al. TCC'23, and Kohlweiss et al. TCC'23) which could only prove the simulation extractability of the \"textbook\" versions of these schemes and does not capture their optimized variants, with all the popular optimization tricks in place, that are eventually implemented and deployed in software libraries.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690351",
    "comment": ""
  },
  {
    "title": "A Succinct Range Proof for Polynomial-based Vector Commitment",
    "author": "Gao, Rui and Wan, Zhiguo and Hu, Yuncong and Wang, Huaqun",
    "abstract": "A range proof serves as a protocol for the prover to prove to the verifier that a committed number lies in a specified range, such as [0,2n), without disclosing the actual value. Range proofs find extensive application in various domains. However, the efficiency of many existing schemes diminishes significantly when confronted with batch proofs encompassing multiple elements.To improve the scalability and efficiency, we propose MissileProof, a vector range proof scheme, proving that every element in the committed vector is within [0,2n). We first reduce this argument to a bi-to-univariate SumCheck problem and a bivariate polynomial ZeroTest problem. Then generalizing the idea of univariate SumCheck PIOP, we design a bi-to-univariate SumCheck PIOP. By introducing a random polynomial, we construct the bivariate polynomial ZeroTest using a univariate polynomial ZeroTest and a univariate polynomial SumCheck PIOP. Finally, combining the PIOP for vector range proof, a KZG-based polynomial commitment scheme and the Fiat-Shamir transformation, we get a zero-knowledge succinct non-interactive vector range proof.Compared with existing schemes, our scheme has the optimal proof size (O(1)), the optimal commitment length (O(1)), and the optimal verification time (O(1)), at the expense of slightly sacrificing proof time (O(log l ⋅ n log n) operations on the prime field for FFT and O(ln) group exponentiations in G). Moreover, we implemented an anti-money-laundering stateless blockchain based on the MissileProof. The gas consumption of the verification smart contract is reduced by 85\\%.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670324",
    "comment": ""
  },
  {
    "title": "LUNA: Quasi-Optimally Succinct Designated-Verifier Zero-Knowledge Arguments from Lattices",
    "author": "Steinfeld, Ron and Sakzad, Amin and Esgin, Muhammed F. and Kuchta, Veronika and Yassi, Mert and Zhao, Raymond K.",
    "abstract": "We introduce the first candidate Lattice-based designated verifier (DV) zero knowledge sUccinct Non-interactive Argument (ZK-SNARG) protocol, named LUNA, with quasi-optimal proof length (quasi-linear in the security/privacy parameter). By simply relying on mildly stronger security assumptions, LUNA is also a candidate ZK-SNARK (i.e. argument of knowledge). LUNA achieves significant improvements in concrete proof sizes, reaching below 6 KB (compared to >32 KB in prior work) for 128-bit security/privacy level. To achieve our quasi-optimal succinct LUNA, we give a new regularity result for 'private' re-randomization of Module LWE (MLWE) samples using discrete Gaussian randomization vectors, also known as a lattice-based leftover hash lemma with leakage, which applies with a discrete Gaussian re-randomization parameter that is polynomial in the statistical privacy parameter (avoiding exponential smudging), and hides the coset of the re-randomization vector support set. Along the way, we derive bounds on the smoothing parameter of the intersection of short integer solution (SIS), gadget, and Gaussian perp module lattices over the power of 2 cyclotomic rings. We then introduce a new candidate linear-only homomorphic encryption scheme called Module Half-GSW (HGSW), and apply our regularity theorem to provide smudging-free circuit-private homomorphic linear operations for Module HGSW. Our implementation and experimental performance evaluation show that, for typical instance sizes, Module HGSW provides favourable performance for ZK-SNARG applications involving lightweight verifiers. It enables significantly (around 5x) shorter proof lengths while speeding up CRS generation and encryption time by 4-16x and speeding up decryption time by 4.3x, while incurring just 1.2-2x time overhead in linear homomorphic proof generation operations, compared to a Regev encryption used in prior work in the ZK-SNARG context. We believe our techniques are of independent interest and will find application in other privacy-preserving lattice-based protocols.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670345",
    "comment": ""
  },
  {
    "title": "zkLogin: Privacy-Preserving Blockchain Authentication with Existing Credentials",
    "author": "Baldimtsi, Foteini and Chalkias, Konstantinos Kryptos and Ji, Yan and Lindstr\\o{}m, Jonas and Maram, Deepak and Riva, Ben and Roy, Arnab and Sedaghat, Mahdi and Wang, Joy",
    "abstract": "For many users, a private key based wallet serves as the primary entry point to blockchains. Commonly recommended wallet authentication methods, such as mnemonics or hardware wallets, can be cumbersome. This difficulty in user onboarding has significantly hindered the adoption of blockchain-based applications.We develop zkLogin, a novel technique that leverages identity tokens issued by popular platforms (any OpenID Connect enabled platform e.g., Google, Facebook, etc.) to authenticate transactions. At the heart of zkLogin lies a signature scheme allowing the signer to sign using their existing OpenID accounts and nothing else. This improves the user experience significantly as users do not need to remember a new secret and can reuse their existing accounts.zkLogin provides strong security and privacy guarantees. Unlike prior works, zkLogin's security relies solely on the underlying platform's authentication mechanism without the need for any additional trusted parties (e.g., trusted hardware or oracles). As the name suggests, zkLogin leverages zero-knowledge proofs (ZKP) to ensure that the sensitive link between a user's off-chain and on-chain identities is hidden, even from the platform itself.zkLogin enables a number of important applications outside blockchains. It allows billions of users to produce verifiable digital content leveraging their existing digital identities, e.g., email address. For example, a journalist can use zkLogin to sign a news article with their email address, allowing verification of the article's authorship by any party.We have implemented and deployed zkLogin on the Sui blockchain as an additional alternative to traditional digital signature-based addresses. Due to the ease of web3 on-boarding just with social login, many hundreds of thousands of zkLogin accounts have already been generated in various industries such as gaming, DeFi, direct payments, NFT collections, sports racing, cultural heritage, and many more.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690356",
    "comment": ""
  },
  {
    "title": "Derecho: Privacy Pools with Proof-Carrying Disclosures",
    "author": "Beal, Josh and Fisch, Ben",
    "abstract": "A privacy pool enables clients to deposit units of a cryptocurrency into a shared pool where ownership of deposited currency is tracked via a system of cryptographically hidden records. Clients may later withdraw from the pool without linkage to previous deposits. Some privacy pools also support hidden transfer of currency ownership within the pool. In August 2022, the U.S. Department of Treasury sanctioned Tornado Cash, the largest Ethereum privacy pool, on the premise that it enables illicit actors to hide the origin of funds, citing its usage by the DPRK-sponsored Lazarus Group to launder over $455 million dollars worth of stolen cryptocurrency. This ruling effectively made it illegal for U.S. persons/institutions to use or accept funds that went through Tornado Cash, sparking a global debate among privacy rights activists and lawmakers. Against this backdrop, we present Derecho, a system that institutions could use to request cryptographic attestations of fund origins rather than naively rejecting all funds coming from privacy pools. Derecho is a novel application of proof-carrying data, which allows users to propagate allowlist membership proofs through a privacy pool's transaction graph. Derecho is backwards-compatible with existing Ethereum privacy pool designs, adds no overhead in gas costs, and costs users only a few seconds to produce attestations.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670270",
    "comment": ""
  },
  {
    "title": "Arke: Scalable and Byzantine Fault Tolerant Privacy-Preserving Contact Discovery",
    "author": "Mohnblatt, Nicolas and Sonnino, Alberto and Gurkan, Kobi and Jovanovic, Philipp",
    "abstract": "Contact discovery is a crucial component of social applications, facilitating interactions between registered contacts. This work introduces Arke, a novel contact discovery scheme that addresses the limitations of existing solutions in terms of privacy, scalability, and reliance on trusted third parties. Arke ensures the unlinkability of user interactions, mitigates enumeration attacks, and operates without single points of failure or trust. Notably, Arke is the first contact discovery system whose performance is independent of the total number of users and the first that can operate in a Byzantine setting. It achieves its privacy goals through an unlinkable handshake mechanism built on top of an identity-based non-interactive key exchange. By leveraging a custom distributed architecture, Arke forgoes the expense of consensus to achieve scalability while maintaining consistency in an adversarial environment. Performance evaluations demonstrate that Arke provides a throughput of over 1,500 user requests per second at a latency of less than 0.5 seconds in a large geo-distributed setting which would allow privacy-preserving contact discovery for all of the popular messaging applications in one system.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670289",
    "comment": ""
  },
  {
    "title": "Atomic and Fair Data Exchange via Blockchain",
    "author": "Tas, Ertem Nusret and Seres, Istv\\'{a}n Andr\\'{a}s and Zhang, Yinuo and Melczer, M\\'{a}rk and Kelkar, Mahimna and Bonneau, Joseph and Nikolaenko, Valeria",
    "abstract": "We introduce a blockchain Fair Data Exchange (FDE) protocol, enabling a storage server to transfer a data file to a client atomically: the client receives the file if and only if the server receives an agreed-upon payment. We put forth a new definition for a cryptographic scheme that we name verifiable encryption under committed key (VECK), and we propose two instantiations for this scheme. Our protocol relies on a blockchain to enforce the atomicity of the exchange and uses VECK to ensure that the client receives the correct data (matching an agreed-upon commitment) before releasing the payment for the decrypting key. Our protocol is trust-minimized and requires only constant-sized on-chain communication, concretely 3 signatures, 1 verification key, and 1 secret key, with most of the data stored and communicated off-chain. It also supports exchanging only a subset of the data, can amortize the server's work across multiple clients, and offers a general framework to design alternative FDE protocols using different commitment schemes. A prominent application of our protocol is the Danksharding data availability scheme on Ethereum, which commits to data via KZG polynomial commitments. We also provide an open-source implementation for our protocol with both instantiations for VECK, demonstrating our protocol's efficiency and practicality on Ethereum.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690248",
    "comment": ""
  },
  {
    "title": "Asynchronous Consensus without Trusted Setup or Public-Key Cryptography",
    "author": "Das, Sourav and Duan, Sisi and Liu, Shengqi and Momose, Atsuki and Ren, Ling and Shoup, Victor",
    "abstract": "Byzantine consensus is a fundamental building block in distributed cryptographic problems. Despite decades of research, most existing asynchronous consensus protocols require a strong trusted setup and expensive public-key cryptography. In this paper, we study asynchronous Byzantine consensus protocols that do not rely on a trusted setup and do not use public-key cryptography such as digital signatures. We give an Asynchronous Common Subset (ACS) protocol whose security is only based on cryptographic hash functions modeled as a random oracle. Our protocol has O(κn3) total communication and runs in expected O(1) rounds. The fact that we use only cryptographic hash functions also means that our protocol is post-quantum secure. The minimal use of cryptography and the small number of rounds make our protocol practical. We implement our protocol and evaluate it in a geo-distributed setting with up to 128 machines. Our experimental evaluation shows that our protocol is more efficient than the only other setup-free consensus protocol that has been implemented to date. En route to our asynchronous consensus protocols, we also introduce new primitives called asynchronous secret key sharing and cover gather, which may be of independent interest.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670327",
    "comment": ""
  },
  {
    "title": "Asynchronous Authentication",
    "author": "Mouallem, Marwa and Eyal, Ittay",
    "abstract": "A myriad of authentication mechanisms embody a continuous evolution from verbal passwords in ancient times to contemporary multi-factor authentication: Cryptocurrency wallets advanced from a single signing key to using a handful of well-kept credentials, and for online services, the infamous \"security questions'' were all but abandoned. Nevertheless, digital asset heists and numerous identity theft cases illustrate the urgent need to revisit the fundamentals of user authentication.We abstract away credential details and formalize the general, common case of asynchronous authentication, with unbounded message propagation time. Given credentials' fault probabilities (e.g., loss or leak), we seek mechanisms with maximal success probability. Such analysis was not possible before due to the large number of possible mechanisms. We show that every mechanism is dominated by some Boolean mechanism ---defined by a monotonic Boolean function on presented credentials. We present an algorithm for finding approximately optimal mechanisms by leveraging the problem structure to reduce complexity by orders of magnitude.The algorithm immediately revealed two surprising results: Accurately incorporating easily-lost credentials improves cryptocurrency wallet security by orders of magnitude. And novel usage of (easily-leaked) security questions improves authentication security for online services.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670328",
    "comment": ""
  },
  {
    "title": "PG: Byzantine Fault-Tolerant and Privacy-Preserving Sensor Fusion with Guaranteed Output Delivery",
    "author": "Jin, Chenglu and Yin, Chao and van Dijk, Marten and Duan, Sisi and Massacci, Fabio and Reiter, Michael K. and Zhang, Haibin",
    "abstract": "We design and implement PG, a Byzantine fault-tolerant and privacy-preserving multi-sensor fusion system. PG is flexible and extensible, supporting a variety of fusion algorithms and application scenarios. On the theoretical side, PG develops and unifies techniques from dependable distributed systems and modern cryptography. PG can provably protect the privacy of individual sensor inputs and fusion results. In contrast to prior works, PG can provably defend against pollution attacks and guarantee output delivery, even in the presence of malicious sensors that may lie about their inputs, contribute ill-formed inputs, and provide no inputs at all to sway the final result, and in the presence of malicious servers serving as aggregators.On the practical side, we implement PG in the client-server-sensor setting. Moreover, we deploy PG in a cloud-based system with 261 sensors and a cyber-physical system with 19 resource-constrained sensors. In both settings, we show that PG is efficient and scalable in both failure-free and failure scenarios.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670343",
    "comment": ""
  },
  {
    "title": "A Comprehensive Analysis of Security Vulnerabilities and Attacks in Satellite Modems",
    "author": "Yu, Lingjing and Hao, Jingli and Ma, Jun and Sun, Yong and Zhao, Yijun and Luo, Bo",
    "abstract": "Satellite modems are critical components in satellite communication networks. Especially, they determine the entire communication regime in traditional systems where the satellites only act as transparent relays. However, unlike satellites that are usually more isolated and better protected, satellite modems are accessible and susceptible to lower-cost attacks, potentially serving as a weak link in the chain of satellite communication security. We make the first attempt to shed light on satellite modem security. We first physically disassemble commodity satellite modems and systematically examine hardware and software modules. We perform a measurement study on the satellite modems that are exposed to the Internet. We identify 16 security vulnerabilities across three attack surfaces: satellite communication interface, ground network interface, and hardware. We further introduce AirSecAnalyzer, an automated security analyzer/fuzzer for the modems' satellite communication interface. Through comprehensive analysis and extensive experiments on 9 real-world satellite modems, we report 18 novel attacks that exploit the identified vulnerabilities. Our findings are expected to contribute as a valuable foundation for future research on the security of satellite modems and satellite communication networks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670390",
    "comment": ""
  },
  {
    "title": "GPSBuster: Busting out Hidden GPS Trackers via MSoC Electromagnetic Radiations",
    "author": "Li, Yue and Yan, Zhenxiong and Jin, Wenqiang and Ning, Zhenyu and Liu, Daibo and Qin, Zheng and Liu, Yu and Zhu, Huadi and Li, Ming",
    "abstract": "The escalating threat of hidden GPS tracking devices poses significant risks to personal privacy and security. Featured by their miniaturization and misleading appearances, GPS devices can be easily disguised in their surroundings making their detection extremely challenging. In this paper, we propose a novel side-channel-driven detection system, GPSBuster, leveraging electromagnetic radiation (EMR) emitted by GPS trackers. Our feasibility studies and hardware analysis reveal that unique EMR patterns associated with the tracker's operation, stemming from the quartz oscillator, local oscillator, and mixer in the Mixed-Signal on Chip (MSoC) system. Nevertheless, as a side-channel leakage, EMRs can be extremely weak and suffer from the ambient noise interference, rendering the detection impractical. To address these challenges, we develop the signal processing techniques with noise removals and a dual-dimensional folding mechanism to accumulate the spectrum energy and protrude the EMR patterns with high Signal-to-Noise Ratios (SNR). Our detection prototype, built with a portable HackRF One device, allows users to perform a scan-to-detect manner and achieves an overall success rate of 98.4\\% on top-10 selling GPS trackers under various testing cases. The maximum detection range is 0.61m.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690362",
    "comment": ""
  },
  {
    "title": "Accurate and Efficient Recurring Vulnerability Detection for IoT Firmware",
    "author": "Xiao, Haoyu and Zhang, Yuan and Shen, Minghang and Lin, Chaoyang and Zhang, Can and Liu, Shengli and Yang, Min",
    "abstract": "IoT firmware faces severe threats to security vulnerabilities. As an important method to detect vulnerabilities, recurring vulnerability detection has not been systematically studied in IoT firmware. In fact, existing methods would meet significant challenges from two aspects. First, firmware vulnerabilities are usually reported in texts without too much code-level information, e.g., security patches. Second, firmware images are released as binaries, making the analysis of known vulnerabilities and the detection of unknown vulnerabilities quite difficult. This paper presents FirmRec, the first recurring vulnerability detection approach for IoT firmware. FirmRec features several new techniques to enable accurate and efficient vulnerability detection.First, it proposes a new exploitation-based vulnerability signature representation for firmware, which does not use syntactic code features but the semantic features along the dynamic vulnerability exploitation procedure (thus is more resilient to binary code changes and fits the context of binary-only firmware). Second, given a vulnerability report, it designs concolic execution-based vulnerability signature extraction to understand the vulnerability exploitation procedure and generate an exploitation-based vulnerability signature. Third, based on known vulnerability signatures, it employs a two-stage pipeline to accurately and efficiently detect recurring vulnerabilities. With a dataset of 320 firmware images, FirmRec efficiently detects 642 vulnerabilities. Till now, 53 CVEs have been assigned. Compared with SaTC, jTrans, and Greenhouse, FirmRec detects more vulnerabilities and is more accurate. Our study shows that recurring vulnerabilities are quite prevalent in IoT firmware but require new techniques to detect.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670275",
    "comment": ""
  },
  {
    "title": "RISiren: Wireless Sensing System Attacks via Metasurface",
    "author": "Jiang, Chenghan and Yang, Jinjiang and Li, Xinyi and Li, Qi and Zhang, Xinyu and Ren, Ju",
    "abstract": "After over a decade of intensive research, wireless sensing technology is nearing commercialization. However, the inherent openness of the wireless medium exposes this technology to security flaws and vulnerabilities. In this paper, we introduce RISiren to reveal the risk. RISiren is a pioneering end-to-end black-box attack system leveraging programmable metasurface with a high level of stealthiness. The key insight of RISiren lies in its ability to generate malicious multipath using metasurface, thereby disrupting wireless channel metrics influenced by genuine human activities and facilitating malicious attacks. To ensure the effectiveness of RISiren, we propose a novel metasurface configuration strategy aiming at creating human-like activities that stem from a comprehensive analysis of how human activities impact wireless signal propagation. We have implemented and validated RISiren using commercial Wi-Fi devices. Our evaluation involved testing our attack strategies against five state-of-the-art systems (including five different types of recognition frameworks) representative of the current landscape. The experimental results show that the adversarial wireless signals generated by RISiren achieve over 90\\% attack success rate on average, and remain robust and effective across different environments and deployment setups, including through wall attack scenarios.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690186",
    "comment": ""
  },
  {
    "title": "The Invisible Polyjuice Potion: an Effective Physical Adversarial Attack against Face Recognition",
    "author": "Wang, Ye and Liu, Zeyan and Luo, Bo and Hui, Rongqing and Li, Fengjun",
    "abstract": "Face recognition systems have been targeted by recent physical adversarial machine learning attacks, which attach or project visible patterns on adversaries' faces to trick backend FR models. While these attacks have demonstrated effectiveness in the literature, they often rely on visibly suspicious patterns, are susceptible to environmental noise, or exhibit limited success rates in practice. In this paper, we propose a novel physical adversarial attack against deep face recognition systems, namely Agile (Adversarial Glasses with Infrared LasEr). It generates adjustable, invisible laser perturbations and emits them into the camera CMOS to launch dodging and impersonation attacks against facial biometrics systems. To do so, we first theoretically model physical adversarial perturbations and convert them to the digital domain. The generated synthesized attack signals are utilized to guide real-world laser settings. Our experiments with real-world attackers and a benchmark face database show that Agile is highly effective in DoS, dodging, and impersonation attacks. More importantly, the candidate impersonation target and optimal attack settings identified by Agile's attack synthesis approach are highly consistent with real-world physical attack results. The grey-box and black-box evaluation against commercial FR models also confirms the effectiveness of the Agile attack.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670382",
    "comment": ""
  },
  {
    "title": "RefleXnoop: Passwords Snooping on NLoS Laptops Leveraging Screen-Induced Sound Reflection",
    "author": "Wang, Penghao and Hu, Jingzhi and Liu, Chao and Luo, Jun",
    "abstract": "Password inference attacks by covert wireless side-channels jeopardize information safety, even for people with high security awareness and vigilance against snoopers. Yet, with limited spatial resolution, existing attacks cannot accurately infer password input on QWERTY keyboards in distance, creating psychological safety in using laptops publicly. To refute this false belief, we propose RefleXnoop, enabling an attacker to snoop a victim's typing details on a non-line-of-sight  (NLoS) laptop. Apart from passively overhearing keystroke acoustic emanations, RefleXnoop actively probes with ultrasound, whose larger bandwidth and lower noise floor offers a finer resolution. To further maximize its performance, RefleXnoop exploits the laptop's screen reflection to enhance diversity in sound acquisition, and it innovates in neural models to effectively fuse the diversified sound acquisitions and to achieve robust feature-to-key translation. We implement RefleXnoop with commodity hardware and conduct extensive evaluation on it; the results demonstrate that RefleXnoop achieves 85\\% top-100 accuracy for inferring 8-character passwords on laptop QWERTY-keyboard and in multiple noisy environments.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670341",
    "comment": ""
  },
  {
    "title": "UWBAD: Towards Effective and Imperceptible Jamming Attacks Against UWB Ranging Systems with COTS Chips",
    "author": "Yang, Yuqiao and Wu, Zhongjie and Zhang, Yongzhao and Chen, Ting and Li, Jun and Yang, Jie and Liu, Wenhao and Zhang, Xiaosong and Shi, Ruicong and Li, Jingwei and Jiang, Yu and Su, Zhuo",
    "abstract": "UWB ranging systems have been adopted in many critical and security sensitive applications due to its precise positioning and secure ranging capabilities. We present a practical jamming attack, namely UWBAD, against commercial UWB ranging systems, which exploits the vulnerability of the adoption of the normalized cross-correlation process in UWB ranging and can selectively and quickly block ranging sessions without prior knowledge of the configurations of the victim devices, potentially leading to severe consequences such as property loss, unauthorized access, or vehicle theft. UWBAD achieves more effective and less imperceptible jamming due to: (i) it efficiently blocks every ranging session by leveraging the field-level jamming, thereby exerting a tangible impact on commercial UWB ranging systems, and (ii) the compact, reactive, and selective system design based on COTS UWB chips, making it affordable and less imperceptible. We successfully conducted real attacks against commercial UWB ranging systems from the three largest UWB chip vendors on the market, e.g., Apple, NXP, and Qorvo. We reported our findings to Apple, related Original Equipment Manufacturers (OEM), and the Automotive Security Research Group. As of the writing of this paper, the related OEM has acknowledged this vulnerability in their automotive systems and has offered a 5, 000 reward as a bounty.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670349",
    "comment": ""
  },
  {
    "title": "Stealing Maggie's Secrets-On the Challenges of IP Theft Through FPGA Reverse Engineering",
    "author": "Klix, Simon and Albartus, Nils and Speith, Julian and Staat, Paul and Verstege, Alice and Wilde, Annika and Lammers, Daniel and Langheinrich, J\\\"{o}rn and Kison, Christian and Sester-Wehle, Sebastian and Holcomb, Daniel and Paar, Christof",
    "abstract": "Intellectual Property (IP) theft is a cause of major financial and reputational damage, reportedly in the range of hundreds of billions of dollars annually in the U.S. alone. Field Programmable Gate Arrays (FPGAs) are particularly exposed to IP theft, because their configuration file contains the IP in a proprietary format that can be mapped to a gate-level netlist with moderate effort. Despite this threat, the scientific understanding of this issue lacks behind reality, thereby preventing an in-depth assessment of IP theft from FPGAs in academia. We address this discrepancy through a real-world case study on a Lattice iCE40 FPGA found inside iPhone 7. Apple refers to this FPGA as Maggie. By reverse engineering the proprietary signal-processing algorithm implemented on Maggie, we generate novel insights into the actual efforts required to commit FPGA IP theft and the challenges an attacker faces on the way. Informed by our case study, we then introduce generalized netlist reverse engineering techniques that drastically reduce the required manual effort and are applicable across a diverse spectrum of FPGA implementations and architectures. We evaluate these techniques on six benchmarks that are representative of different FPGA applications and have been synthesized for Xilinx and Lattice FPGAs, as well as in an end-to-end white-box case study. Finally, we provide a comprehensive open-source tool suite of netlist reverse engineering techniques to foster future research, enable the community to perform realistic threat assessments, and facilitate the evaluation of novel countermeasures.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690235",
    "comment": ""
  },
  {
    "title": "Glitch-Stopping Circuits: Hardware Secure Masking without Registers",
    "author": "Zhang, Zhenda and Petkova-Nikova, Svetla and Nikov, Ventzislav",
    "abstract": "Masking is one of the most popular countermeasures to protect implementations against power and electromagnetic side-channel attacks because it offers provable security. Masking has been shown secure against d-threshold probing adversaries by Ishai et al. at CRYPTO'03, but this adversary's model doesn't consider any physical hardware defaults and thus such masking schemes were shown to be still vulnerable when implemented as hardware circuits. To address these limitations glitch-extended probing adversaries and correspondingly glitch-immune masking schemes have been introduced. This paper introduces glitch-stopping circuits, which coincide with circuits protected via glitch-immune masking when instantiated with registers. Then we show that one can instantiate glitch-stopping circuits without registers by using clocked logic gates or latches. This is illustrated for both ASIC and FPGA, offering a promising alternative to conventional register-based masked implementations. Compared to the traditional register-based approach, these register-free solutions can reduce the latency to a single cycle and achieve a lower area cost. We prove and experimentally confirm that the proposed solution is as secure as the register-based one. In summary, this paper proposes a novel method to address the latency of register-based hardware masking without jeopardizing their security. This method not only reduces the latency down to one clock cycle but also improves the area costs of the implementations.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670335",
    "comment": ""
  },
  {
    "title": "Whipping the Multivariate-based MAYO Signature Scheme using Hardware Platforms",
    "author": "Hirner, Florian and Streibl, Michael and Krieger, Florian and Mert, Ahmet Can and Roy, Sujoy Sinha",
    "abstract": "NIST issued a new call in 2023 to diversify the portfolio of quantum-resistant digital signature schemes since the current portfolio relies on lattice problems. The MAYO scheme, which builds on the Unbalanced Oil and Vinegar (UOV) problem, is a promising candidate for this new call. MAYO introduces emulsifier maps and a novel 'whipping' technique to significantly reduce the key sizes compared to previous UOV schemes. This paper provides a comprehensive analysis of the implementation aspects of MAYO and proposes several optimization techniques that we use to implement a high-speed hardware accelerator. The first optimization technique is the partial unrolling of the emulsification process to increase parallelization. The second proposed optimization is a novel memory structure enabling the parallelization of significant bottlenecks in the MAYO scheme. In addition to this, we present a flexible transposing technique for the data format used in MAYO that can be expanded to other UOV-based schemes. We use these techniques to design the first high-speed ASIC and FPGA accelerator that supports all operations of the MAYO scheme for different NIST security levels. Compared with state-of-the-art, like HaMAYO [24] and UOV [7], our FPGA design shows a performance benefit of up to three orders of magnitude in both latency and area-time-product. Furthermore, we lower the BRAM consumption by up to 2.8 \\texttimes{} compared to these FPGA implementations. Compared to high-end CPU implementations, our ASIC design allows between 2.81\\texttimes{} and 60.14\\texttimes{} higher throughputs. This increases the number of signing operations per second from 483 to 13424, thereby fostering performant deployment of the MAYO scheme in time-critical applications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690258",
    "comment": ""
  },
  {
    "title": "CiMSAT: Exploiting SAT Analysis to Attack Compute-in-Memory Architecture Defenses",
    "author": "Wang, Jianfeng and Yang, Huazhong and Deng, Shuwen and Li, Xueqing",
    "abstract": "Compute-in-memory (CiM) architecture is an emerging energy-efficient processing paradigm that has attracted widespread attention in AI and Internet of Things (IoT) applications. To protect statically stored sensitive data in CiM, designers have implemented various hardware obfuscation techniques in CiM architectures. However, we observe that existing CiM obfuscation defense strategies are based on straightforward static-key deployment strategies, which pose vulnerabilities from the perspective of key-pruning algorithms for de-obfuscation.This work proposes CiMSAT, a CiM de-obfuscation methodology based on Boolean satisfiability (SAT) theory. We conduct the first security analysis specifically tailored to the storage and mixed-signal computing features of CiM architecture, which are two key challenges to de-obfuscate existing state-of-the-art CiM defenses. To model storage units, we innovatively fit and utilize the \"no-inference-value\" obfuscated data for function approximation. To reconstruct mixed-signal circuits, we design bias-tolerant SAT to address the biases introduced by the approximation. With the proposed workflow, we investigate and evaluate all the existing 14 CiM obfuscation architectures using our de-obfuscation framework. We model a total of 176 defense vectors derived from different defense techniques and parameters, among which 158 (90\\%) can be de-obfuscated and returned the keys within 1,000 seconds and 172 (98\\%) defenses can be recovered within 105 seconds (approximately one day). We further reload the keys into CiM simulators with obfuscation, achieving an average of 97\\% and 95\\% accuracy recovery in widely adopted MNIST and CIFAR-10 classification applications in CiM obfuscation, respectively.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690251",
    "comment": ""
  },
  {
    "title": "QueryCheetah: Fast Automated Discovery of Attribute Inference Attacks Against Query-Based Systems",
    "author": "Stevanoski, Bozhidar and Cretu, Ana-Maria and de Montjoye, Yves-Alexandre",
    "abstract": "Query-based systems (QBSs) are one of the key approaches for sharing data. QBSs allow analysts to request aggregate information from a private protected dataset. Attacks are a crucial part of ensuring QBSs are truly privacy-preserving. The development and testing of attacks is however very labor-intensive and unable to cope with the increasing complexity of systems. Automated approaches have been shown to be promising but are currently extremely computationally intensive, limiting their applicability in practice. We here propose QueryCheetah, a fast and effective method for automated discovery of privacy attacks against QBSs. We instantiate QueryCheetah on attribute inference attacks and show it to discover stronger attacks than previous methods while being 18 times faster than the state-of-the-art automated approach. We then show how QueryCheetah allows system developers to thoroughly evaluate the privacy risk, including for various attacker strengths and target individuals. We finally show how QueryCheetah can be used out-of-the-box to find attacks in larger syntaxes and workarounds around ad-hoc defenses.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690272",
    "comment": ""
  },
  {
    "title": "Analyzing Inference Privacy Risks Through Gradients In Machine Learning",
    "author": "Li, Zhuohang and Lowy, Andrew and Liu, Jing and Koike-Akino, Toshiaki and Parsons, Kieran and Malin, Bradley and Wang, Ye",
    "abstract": "In distributed learning settings, models are iteratively updated with shared gradients computed from potentially sensitive user data. While previous work has studied various privacy risks of sharing gradients, our paper aims to provide a systematic approach to analyze private information leakage from gradients. We present a unified game-based framework that encompasses a broad range of attacks including attribute, property, distributional, and user disclosures. We investigate how different uncertainties of the adversary affect their inferential power via extensive experiments on five datasets across various data modalities. Our results demonstrate the inefficacy of solely relying on data aggregation to achieve privacy against inference attacks in distributed learning. We further evaluate five types of defenses, namely, gradient pruning, signed gradient descent, adversarial perturbations, variational information bottleneck, and differential privacy, under both static and adaptive adversary settings. We provide an information-theoretic view for analyzing the effectiveness of these defenses against inference from gradients. Finally, we introduce a method for auditing attribute inference privacy, improving the empirical estimation of worst-case privacy through crafting adversarial canary records.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690304",
    "comment": ""
  },
  {
    "title": "Membership Inference Attacks Against In-Context Learning",
    "author": "Wen, Rui and Li, Zheng and Backes, Michael and Zhang, Yang",
    "abstract": "Adapting Large Language Models (LLMs) to specific tasks introduces concerns about computational efficiency, prompting an exploration of efficient methods such as In-Context Learning (ICL). However, the vulnerability of ICL to privacy attacks under realistic assumptions remains largely unexplored. In this work, we present the first membership inference attack tailored for ICL, relying solely on generated texts without their associated probabilities. We propose four attack strategies tailored to various constrained scenarios and conduct extensive experiments on four popular large language models. Empirical results show that our attacks can accurately determine membership status in most cases, e.g., 95\\% accuracy advantage against LLaMA, indicating that the associated risks are much higher than those shown by existing probability-based attacks. Additionally, we propose a hybrid attack that synthesizes the strengths of the aforementioned strategies, achieving an accuracy advantage of over 95\\% in most cases. Furthermore, we investigate three potential defenses targeting data, instruction, and output. Results demonstrate combining defenses from orthogonal dimensions significantly reduces privacy leakage and offers enhanced privacy assurances.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690306",
    "comment": ""
  },
  {
    "title": "SeqMIA: Sequential-Metric Based Membership Inference Attack",
    "author": "Li, Hao and Li, Zheng and Wu, Siyuan and Hu, Chengrui and Ye, Yutong and Zhang, Min and Feng, Dengguo and Zhang, Yang",
    "abstract": "Most existing membership inference attacks (MIAs) utilize metrics (e.g., loss) calculated on the model's final state, while recent advanced attacks leverage metrics computed at various stages, including both intermediate and final stages, throughout the model training. Nevertheless, these attacks often process multiple intermediate states of the metric independently, ignoring their time-dependent patterns. Consequently, they struggle to effectively distinguish between members and non-members who exhibit similar metric values, particularly resulting in a high false-positive rate.In this study, we delve deeper into the new membership signals in the black-box scenario. We identify a new, more integrated membership signal: the Pattern of Metric Sequence, derived from the various stages of model training. We contend that current signals provide only partial perspectives of this new signal: the new one encompasses both the model's multiple intermediate and final states, with a greater emphasis on temporal patterns among them. Building upon this signal, we introduce a novel attack method called Sequential-metric based Membership Inference Attack (SeqMIA). Specifically, we utilize knowledge distillation to obtain a set of distilled models representing various stages of the target model's training. We then assess multiple metrics on these distilled models in chronological order, creating distilled metric sequence. We finally integrate distilled multi-metric sequences as a sequential multiformat and employ an attention-based RNN attack model for inference. Empirical results show SeqMIA outperforms all baselines, especially can achieve an order of magnitude improvement in terms of TPR @ 0.1\\% FPR. Furthermore, we delve into the reasons why this signal contributes to SeqMIA's high attack performance, and assess various defense mechanisms against SeqMIA.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690335",
    "comment": ""
  },
  {
    "title": "PreCurious: How Innocent Pre-Trained Language Models Turn into Privacy Traps",
    "author": "Liu, Ruixuan and Wang, Tianhao and Cao, Yang and Xiong, Li",
    "abstract": "The pre-training and fine-tuning paradigm has demonstrated its effectiveness and has become the standard approach for tailoring language models to various tasks. Currently, community-based platforms offer easy access to various pre-trained models, as anyone can publish without strict validation processes. However, a released pre-trained model can be a privacy trap for fine-tuning datasets if it is carefully designed. In this work, we propose PreCurious framework to reveal the new attack surface where the attacker releases the pre-trained model and gets a black-box access to the final fine-tuned model. PreCurious aims to escalate the general privacy risk of both membership inference and data extraction on the fine-tuning dataset. The key intuition behind PreCurious is to manipulate the memorization stage of the pre-trained model and guide fine-tuning with a seemingly legitimate configuration. While empirical and theoretical evidence suggests that parameter-efficient and differentially private fine-tuning techniques can defend against privacy attacks on a fine-tuned model, PreCurious demonstrates the possibility of breaking up this invulnerability in a stealthy manner compared to fine-tuning on a benign pre-trained model. While DP provides some mitigation for membership inference attack, by further leveraging a sanitized dataset, PreCurious demonstrates potential vulnerabilities for targeted data extraction even under differentially private tuning with a strict privacy budget e.g. ε=0.05. Thus, PreCurious raises warnings for users on the potential risks of downloading pre-trained models from unknown sources, relying solely on tutorials or common-sense defenses, and releasing sanitized datasets even after perfect scrubbing.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690279",
    "comment": ""
  },
  {
    "title": "Uncovering Gradient Inversion Risks in Practical Language Model Training",
    "author": "Feng, Xinguo and Ma, Zhongkui and Wang, Zihan and Chegne, Eu Joe and Ma, Mengyao and Abuadbba, Alsharif and Bai, Guangdong",
    "abstract": "The gradient inversion attack has been demonstrated as a significant privacy threat to federated learning (FL), particularly in continuous domains such as vision models. In contrast, it is often considered less effective or highly dependent on impractical training settings when applied to language models, due to the challenges posed by the discrete nature of tokens in text data. As a result, its potential privacy threats remain largely underestimated, despite FL being an emerging training method for language models. In this work, we propose a domain-specific gradient inversion attack named GRAB (<u>gra</u>dient inversion with hy<u>b</u>rid optimization). GRAB features two alternating optimization processes to address the challenges caused by practical training settings, including a simultaneous optimization on dropout masks between layers for improved token recovery and a discrete optimization for effective token sequencing. GRAB can recover a significant portion (up to 92.9\\% recovery rate) of the private training data, outperforming the attack strategy of utilizing discrete optimization with an auxiliary model by notable improvements of up to 28.9\\% recovery rate in benchmark settings and 48.5\\% recovery rate in practical settings. GRAB provides a valuable step forward in understanding this privacy threat in the emerging FL training mode of language models.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690292",
    "comment": ""
  },
  {
    "title": "Curator Attack: When Blackbox Differential Privacy Auditing Loses Its Power",
    "author": "Wang, Shiming and Xiang, Liyao and Cheng, Bowei and Ji, Zhe and Sun, Tianran and Wang, Xinbing",
    "abstract": "A surge in data-driven applications enhances everyday life but also raises serious concerns about private information leakage. Hence many privacy auditing tools are emerging for checking if the data sanitization performed meets the privacy standard of the data owner. Blackbox auditing for differential privacy is particularly gaining popularity for its effectiveness and applicability to a wide range of scenarios. Yet, we identified that blackbox auditing is essentially flawed with its setting --- small probabilities/densities are ignored due to inaccurate observation. Our argument is based on a solid false positive analysis from a hypothesis testing perspective, which is missed out by prior blackbox auditing tools. This oversight greatly reduces the reliability of these tools, as it allows malicious or incapable data curators to pass the auditing with an overstated privacy guarantee, posing significant risks to data owners. We demonstrate the practical existence of such threats in classical differential privacy mechanisms against four representative blackbox auditors with experimental validations. Our findings aim to reveal the limitations of blackbox auditing tools, empower the data owner with the awareness of risks in using these tools, and encourage the development of more reliable differential privacy auditing methods.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690367",
    "comment": ""
  },
  {
    "title": "Data Poisoning Attacks to Locally Differentially Private Frequent Itemset Mining Protocols",
    "author": "Tong, Wei and Chen, Haoyu and Niu, Jiacheng and Zhong, Sheng",
    "abstract": "Local differential privacy (LDP) provides a way for an untrusted data collector to aggregate users' data without violating their privacy. Various privacy-preserving data analysis tasks have been studied under the protection of LDP, such as frequency estimation, frequent itemset mining, and machine learning. Despite its privacy-preserving properties, recent research has demonstrated the vulnerability of certain LDP protocols to data poisoning attacks. However, existing data poisoning attacks are focused on basic statistics under LDP, such as frequency estimation and mean/variance estimation. As an important data analysis task, the security of LDP frequent itemset mining has yet to be thoroughly examined. In this paper, we aim to address this issue by presenting novel and practical data poisoning attacks against LDP frequent itemset mining protocols. By introducing a unified attack framework with composable attack operations, our data poisoning attack can successfully manipulate the state-of-the-art LDP frequent itemset mining protocols and has the potential to be adapted to other protocols with similar structures. We conduct extensive experiments on three datasets to compare the proposed attack with four baseline attacks. The results demonstrate the severity of the threat and the effectiveness of the proposed attack.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670298",
    "comment": ""
  },
  {
    "title": "TabularMark: Watermarking Tabular Datasets for Machine Learning",
    "author": "Zheng, Yihao and Xia, Haocheng and Pang, Junyuan and Liu, Jinfei and Ren, Kui and Chu, Lingyang and Cao, Yang and Xiong, Li",
    "abstract": "Watermarking is broadly utilized to protect ownership of shared data while preserving data utility. However, existing watermarking methods for tabular datasets fall short on the desired properties (detectability, non-intrusiveness, and robustness) and only preserve data utility from the perspective of data statistics, ignoring the performance of downstream ML models trained on the datasets. Can we watermark tabular datasets without significantly compromising their utility for training ML models while preventing attackers from training usable ML models on attacked datasets?In this paper, we propose a hypothesis testing-based watermarking scheme, TabularMark. Data noise partitioning is utilized for data perturbation during embedding, which is adaptable for numerical and categorical attributes while preserving the data utility. For detection, a custom-threshold one proportion z-test is employed, which can reliably determine the presence of the watermark. Experiments on real-world and synthetic datasets demonstrate the superiority of TabularMark in detectability, non-intrusiveness, and robustness.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690373",
    "comment": ""
  },
  {
    "title": "SafeEar: Content Privacy-Preserving Audio Deepfake Detection",
    "author": "Li, Xinfeng and Li, Kai and Zheng, Yifan and Yan, Chen and Ji, Xiaoyu and Xu, Wenyuan",
    "abstract": "Text-to-Speech (TTS) and Voice Conversion (VC) models have exhibited remarkable performance in generating realistic and natural audio. However, their dark side, audio deepfake poses a significant threat to both society and individuals. Existing countermeasures largely focus on determining the genuineness of speech based on complete original audio recordings, which however often contain private content. This oversight may refrain deepfake detection from many applications, particularly in scenarios involving sensitive information like business secrets. In this paper, we propose SafeEar, a novel framework that aims to detect deepfake audios without relying on accessing the speech content within. Our key idea is to devise a neural audio codec into a novel decoupling model that well separates the semantic and acoustic information from audio samples, and only use the acoustic information (e.g., prosody and timbre) for deepfake detection. In this way, no semantic content will be exposed to the detector. To overcome the challenge of identifying diverse deepfake audio without semantic clues, we enhance our deepfake detector with real-world codec augmentation. Extensive experiments conducted on four benchmark datasets demonstrate SafeEar's effectiveness in detecting various deepfake techniques with an equal error rate (EER) down to 2.02\\%. Simultaneously, it shields five-language speech content from being deciphered by both machine and human auditory analysis, demonstrated by word error rates (WERs) all above 93.93\\% and our user study. Furthermore, our benchmark constructed for anti-deepfake and anti-content recovery evaluation helps provide a basis for future research in the realms of audio privacy preservation and deepfake detection.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670285",
    "comment": ""
  },
  {
    "title": "PLeak: Prompt Leaking Attacks against Large Language Model Applications",
    "author": "Hui, Bo and Yuan, Haolin and Gong, Neil and Burlina, Philippe and Cao, Yinzhi",
    "abstract": "Large Language Models (LLMs) enable a new ecosystem with many downstream applications, called LLM applications, with different natural language processing tasks. The functionality and performance of an LLM application highly depend on its system prompt, which instructs the backend LLM on what task to perform. Therefore, an LLM application developer often keeps a system prompt confidential to protect its intellectual property. As a result, a natural attack, called prompt leaking, is to steal the system prompt from an LLM application, which compromises the developer's intellectual property. Existing prompt leaking attacks primarily rely on manually crafted queries, and thus achieve limited effectiveness.In this paper, we design a novel, closed-box prompt leaking attack framework, called PLeak, to optimize an adversarial query such that when the attacker sends it to a target LLM application, its response reveals its own system prompt. We formulate finding such an adversarial query as an optimization problem and solve it with a gradient-based method approximately. Our key idea is to break down the optimization goal by optimizing adversary queries for system prompts incrementally, i.e., starting from the first few tokens of each system prompt step by step until the entire length of the system prompt.We evaluate PLeak in both offline settings and for real-world LLM applications, e.g., those on Poe, a popular platform hosting such applications. Our results show that PLeak can effectively leak system prompts and significantly outperforms not only baselines that manually curate queries but also baselines with optimized queries that are modified and adapted from existing jailbreaking attacks. We responsibly reported the issues to Poe and are still waiting for their response. Our implementation is available at this repository: https://github.com/BHui97/PLeak.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670370",
    "comment": ""
  },
  {
    "title": "A Framework for Differential Privacy Against Timing Attacks",
    "author": "Ratliff, Zachary and Vadhan, Salil",
    "abstract": "The standard definition of differential privacy (DP) ensures that a mechanism's output distribution on adjacent datasets is indistinguishable. However, real-world implementations of DP can, and often do, reveal information through their runtime distributions, making them susceptible to timing attacks.In this work, we establish a general framework for ensuring differential privacy in the presence of timing side channels. We define a new notion of timing privacy, which captures programs that remain differentially private to an adversary that observes the program's runtime in addition to the output. Our framework enables chaining together component programs that are timing-stable followed by a random delay to obtain DP programs that achieve timing privacy. Importantly, our definitions allow for measuring timing privacy and output privacy using different privacy measures.We illustrate how to instantiate our framework by giving programs for standard DP computations in the RAM and Word RAM models of computation. Furthermore, we show how our framework can be realized in code through a natural extension of the OpenDP Programming Framework.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690206",
    "comment": ""
  },
  {
    "title": "Exploiting Temporal Vulnerabilities for Unauthorized Access in Intent-based Networking",
    "author": "Weintraub, Ben and Kim, Jiwon and Tao, Ran and Nita-Rotaru, Cristina and Okhravi, Hamed and Tian, Dave (Jing) and Ujcich, Benjamin E.",
    "abstract": "Intent-based networking (IBN) enables network administrators to express high-level goals and network policies without needing to specify low-level forwarding configurations, topologies, or protocols. Administrators can define intents that capture the overall behavior they want from the network, and an IBN controller compiles such intents into low-level configurations that get installed in the network and implement the desired behavior.We discovered that current IBN specifications and implementations do not specify that flow rule installation orderings should be enforced, which leads to temporal vulnerabilities where, for a limited time, attackers can exploit indeterminate connectivity behavior to gain unauthorized network access.In this paper, we analyze the causes of such temporal vulnerabilities and their security impacts with a representative case study via the ONOS IBN implementation. We devise the Phantom Link attack and demonstrate a working exploit to highlight the security impacts. To defend against such attacks, we propose Spotlight, a detection method that can alert a system administrator of risky intent updates prone to exploitable temporal vulnerabilities. Spotlight is effective in identifying risky updates using realistic network topologies and policies. We show that Spotlight can detect risky updates in a mean time of 0.65 seconds for topologies of over 1,300 nodes.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670301",
    "comment": ""
  },
  {
    "title": "PIC-BI: Practical and Intelligent Combinatorial Batch Identification for UAV assisted IoT Networks",
    "author": "Ren, Zhe and Li, Xinghua and Miao, Yinbin and Zhu, Mengyao and Yuan, Shunjie and Deng, Robert H.",
    "abstract": "Unmanned Aerial Vehicle (UAV)-assisted IoT networks are receiving a lot of attention in academia and industry. For instance, a UAV can fly and hover over sensors, during which time the sensors simultaneously initiate batch access requests to the UAV. Typically, UAV employs batch authentication to efficiently handle these batch accesses. However, an attacker can initiate illegal requests, causing batch authentication to fail. There are various batch identification algorithms to find illegal requests, enabling legitimate sensors to establish service connections quickly. Existing work wants to choose a suitable one based on the specific attack scenario. However, existing work assumes that the percentage r\\% of illegal requests is known in advance, which is impractical in real-world scenarios. Besides, existing work only selects a suitable batch identification algorithm based on r\\%, limiting the performance of batch identification to the capabilities of the alternative algorithms. Drawing inspiration from the Kalman filter, we first propose an adaptive estimation algorithm for the number of illegal requests to address the above problems. Based on the estimated value e\\%, we design a combinatorial batch identification using reinforcement learning. This approach allows the combination of different algorithms to achieve superior performance. Extensive experiments demonstrate that, for the estimation algorithm, the relative error is less than 20\\% in 27 out of 40 experiments. Regarding the combinatorial algorithms, the delay can be reduced by approximately 7.15\\% to 30.86\\% compared to existing methods.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670303",
    "comment": ""
  },
  {
    "title": "Detecting Tunneled Flooding Traffic via Deep Semantic Analysis of Packet Length Patterns",
    "author": "Fu, Chuanpu and Li, Qi and Shen, Meng and Xu, Ke",
    "abstract": "Distributed denial-of-service (DDoS) protection services capture various flooding attacks by analyzing traffic features. However, existing services are unable to accurately detect tunneled attack traffic because the tunneling protocols encrypt both packet headers and payloads, which hide the traffic features used for detection, and can thus evade these detection services. In this paper, we develop Exosphere, which detects tunneled attack traffic by analyzing packet length patterns, without investigating any information in packets. Specifically, it utilizes a deep learning based method to analyze the semantics of packet patterns, i.e., the features represent the strong correlations between flooding packets with similar length patterns, and classify attack traffic according to these semantic features. We prove that the strong correlations of packet length patterns ensure the theoretical guarantee of applying semantic analysis to recognize correlated attack packets. We prototype Exosphere with FPGAs and deploy it in a real-world institutional network. The experimental results demonstrate that Exosphere achieves 0.967 F1 accuracy, while detecting flooding traffic generated by unseen attacks and misconfigurations. Moreover, it achieves 0.996 AUC accuracy on existing datasets including various stealthy attacks, and thus significantly outperforms the existing deep learning models. It achieves accuracy comparable to the best performances achieved by 12 state-of-the-art methods that cannot detect tunneled flooding traffic, while improving their efficiency by 6.19 times.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670353",
    "comment": ""
  },
  {
    "title": "Release the Hounds! Automated Inference and Empirical Security Evaluation of Field-Deployed PLCs Using Active Network Data",
    "author": "Pickren, Ryan and Chhotaray, Animesh and Li, Frank and Zonouz, Saman and Beyah, Raheem",
    "abstract": "Surveying field-deployed Industrial Control System (ICS) equipment has numerous security applications, including attack-surface management and measuring the adoption of vulnerability patches. However, discovering real-world devices using massive Internet-scale scan datasets is tedious and error-prone. We introduce PLCHound, a novel ICS asset discovery solution designed to automatically reveal elusive ICS devices hiding in network data collected by Internet-scale scanners such as Censys or Shodan. Our solution systematically uncovers indirect evidence of controllers using subtle network-based indicators and temporally-resistant signatures that are often overlooked in prior work. We present PLCHound's architecture, experimentally verify its accuracy, and explore the security advantages of enhanced device discovery. We also use PLCHound to perform the largest comprehensive examination of the publicly-reachable population of ICS devices by popular vendors. Our results reveal that the industry-accepted estimations and latest published papers undercount the true number of public devices by up to 37x. We also find that 95.88\\% of devices expose protocols that cause them to be remotely vulnerable to recent critical CVEs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690195",
    "comment": ""
  },
  {
    "title": "BinPRE: Enhancing Field Inference in Binary Analysis Based Protocol Reverse Engineering",
    "author": "Jiang, Jiayi and Zhang, Xiyuan and Wan, Chengcheng and Chen, Haoyi and Sun, Haiying and Su, Ting",
    "abstract": "Protocol reverse engineering (PRE) aims to infer the specification of network protocols when the source code is not available. Specifically, field inference is one crucial step in PRE to infer the field formats and semantics. To perform field inference, binary analysis based PRE techniques are one major approach category. However, such techniques face two key challenges --- (1) the format inference is fragile when the logics of processing input messages may vary among different protocol implementations, and (2) the semantic inference is limited by inadequate and inaccurate inference rules.To tackle these challenges, we present BinPRE, a binary analysis based PRE tool. BinPRE incorporates (1) an instruction-based semantic similarity analysis strategy for format extraction; (2) a novel library composed of atomic semantic detectors for improving semantic inference adequacy; and (3) a cluster-and-refine paradigm to further improve semantic inference accuracy. We have evaluated BinPRE against five existing PRE tools, including Polyglot, AutoFormat, Tupni, BinaryInferno and DynPRE. The evaluation results on eight widely-used protocols show that BinPRE outperforms the prior PRE tools in both format and semantic inference. BinPRE achieves the perfection of 0.73 on format extraction and the F1-score of 0.74 (0.81) on semantic inference of types (functions), respectively. The field inference results of BinPRE have helped improve the effectiveness of protocol fuzzing by achieving 5~29\\% higher branch coverage, compared to those of the best prior PRE tool. BinPRE has also helped discover one new zero-day vulnerability, which otherwise cannot be found.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690299",
    "comment": ""
  },
  {
    "title": "Manipulating OpenFlow Link Discovery Packet Forwarding for Topology Poisoning",
    "author": "Chen, Mingming and La Porta, Thomas and Taylor, Teryl and Araujo, Frederico and Jaeger, Trent",
    "abstract": "Software-defined networking (SDN) is a centralized, dynamic, and programmable network management technology that enables flexible traffic control and scalability. SDN facilitates network administration through a centralized view of the underlying physical topology; tampering with this topology view can result in catastrophic damage to network management and security. To underscore this issue, we introduce Marionette, a new topology poisoning technique that manipulates OpenFlow link discovery packet forwarding to alter topology information. Our approach exposes an overlooked yet widespread attack vector, distinguishing itself from traditional link fabrication attacks that tamper, spoof, or relay discovery packets at the data plane. Unlike localized attacks observed in existing methods, our technique introduces a globalized topology poisoning attack that leverages control privileges. Marionette implements a reinforcement learning algorithm to compute a poisoned topology target, and injects flow entries to achieve a long-lived stealthy attack. Our evaluation shows that Marionette successfully attacks five open-source controllers and nine OpenFlow-based discovery protocols. Marionette overcomes the state-of-the-art topology poisoning defenses, showcasing a new class of topology poisoning that initiates on the control plane. This security vulnerability was ethically disclosed to OpenDaylight, and CVE-2024-37018 has been assigned.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690345",
    "comment": ""
  },
  {
    "title": "Fuzz to the Future: Uncovering Occluded Future Vulnerabilities via Robust Fuzzing",
    "author": "Raj, Arvind S and Gibbs, Wil and Dong, Fangzhou and Vadayath, Jayakrishna Menon and Tompkins, Michael and Wirsz, Steven and Liu, Yibo and Hu, Zhenghao and Zhu, Chang and Menon, Gokulkrishna Praveen and Dolan-Gavitt, Brendan and Doup\\'{e}, Adam and Wang, Ruoyu and Shoshitaishvili, Yan and Bao, Tiffany",
    "abstract": "The security landscape of software systems has witnessed considerable advancements through dynamic testing methodologies, especially fuzzing. Traditionally, fuzzing involves a sequential, cyclic process where software is tested to identify crashes. These crashes are then triaged and patched, leading to subsequent cycles that uncover further vulnerabilities. While effective, this method is not efficient as each cycle potentially reveals new issues previously obscured by earlier crashes, thus resulting in vulnerabilities being discovered sequentially.In this paper, we present a solution to identify occluded future vulnerabilities - vulnerabilities that are hard or impossible to trigger due to current vulnerabilities occluding the triggering path. We introduce robust fuzzing, a novel technique that enables fuzzers probe beyond the immediate crash location and uncover new vulnerabilities or variants of known ones. We implemented robust fuzzing in FlakJack, a pioneering fuzzing add-on that leverages binary patching to proactively identify occluded future vulnerabilities hidden behind current crashes. By enabling fuzzers to bypass immediate crash points and delve deeper into the software, FlakJack not only accelerates the vulnerability discovery process but also significantly enhances the efficacy of software testing. With the help of FlakJack, we found 28 new vulnerabilities in projects that have been extensively tested through the OSS-Fuzz project. This approach promises a transformative shift in how vulnerabilities are identified and managed, aiming to shorten the time span of vulnerability discovery over the long term.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690278",
    "comment": ""
  },
  {
    "title": "Fuzzing JavaScript Engines with a Graph-based IR",
    "author": "Xu, Haoran and Jiang, Zhiyuan and Wang, Yongjun and Fan, Shuhui and Xu, Shenglin and Xie, Peidai and Fu, Shaojing and Payer, Mathias",
    "abstract": "Mutation-based fuzzing effectively discovers defects in JS engines. High-quality mutations are key for the performance of mutation-based fuzzers. The choice of the underlying representation (e.g., a sequence of tokens, an abstract syntax tree, or an intermediate representation) defines the possible mutation space and subsequently influences the design of mutation operators. Current program representations in JS engine fuzzers center around abstract syntax trees and customized bytecode-level intermediate languages. However, existing efforts struggle to generate semantically valid and meaningful mutations, limiting the discovery of defects in JS engines.Our proposed graph-based intermediate representation, FlowIR, directly represents the JS control flow and data flow as the mutation target. FlowIR is essential for the implementation of powerful semantic mutation. It supports mutation operators at the data flow and control flow level, thereby expanding the granularity of mutation operators. Experimental results show that our method is more effective in discovering new bugs. Our prototype, FuzzFlow, outperforms state-of-the-art fuzzers in generating valid test cases and exploring code coverage. In our evaluation, we detected 37 new defects in thoroughly tested mainstream JS engines.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690336",
    "comment": ""
  },
  {
    "title": "CrossFire: Fuzzing macOS Cross-XPU Memory on Apple Silicon",
    "author": "Zhu, Jiaxun and Lin, Minghao and Yin, Tingting and Cai, Zechao and Wang, Yu and Chang, Rui and Shen, Wenbo",
    "abstract": "Modern computing systems increasingly utilize XPUs, such as GPUs and NPUs, for specialized computation tasks. While these XPUs provide critical functionalities, their security protections are generally weaker than those of CPUs, making them attractive attack targets. In particular, Apple silicon optimizes memory usage by adopting a unified memory architecture (UMA), which employs shared memory regions (termed cross-XPU memory) to facilitate communication between CPUs and XPUs. Although the cross-XPU memory enhances performance, it also introduces a new attack surface. Unfortunately, the difficulty in identifying effective shared memory regions and generating valid payloads makes fuzzing cross-XPU memory a challenging problem that cannot be resolved effectively by existing fuzzing techniques.Therefore, we propose CrossFire, the first fuzzer targeting Apple silicon XPU by fuzzing cross-XPU memory, to evaluate this new attack surface. Initially, we conduct an in-depth cross-XPU memory analysis to investigate the challenges of fuzzing XPU. To address these challenges, CrossFire introduces two novel techniques to pinpoint effective fuzzing regions in cross-XPU memory and trace kernel execution information to extract data constraints. Leveraging these techniques, we develop CrossFire based on the m1n1 hypervisor to monitor cross-XPU memory accesses and perform grey-box hooking-based fuzzing. We further evaluate CrossFire on macOS Ventura, where it has identified 15 new zero-day bugs, 8 of which have been confirmed by Apple.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690376",
    "comment": ""
  },
  {
    "title": "Leveraging Binary Coverage for Effective Generation Guidance in Kernel Fuzzing",
    "author": "Liu, Jianzhong and Shen, Yuheng and Xu, Yiru and Jiang, Yu",
    "abstract": "State-of-the-art kernel fuzzers use edge-based code coverage metrics for novel behavior detection. However, code coverage is not sufficient for operating system kernels, for they contain many untracked but interesting features, such as comparison operands, kernel state identifiers, flags, and executable code, within its data segments, that reflects different execution patterns, and can profoundly increase the granularity and scope of the coverage metrics.This paper proposes the use of Kernel Binary Coverage Feedback, a comprehensive and effective execution feedback method that provides metrics reflecting the execution coverage status of the entire binary coverage to kernel fuzzers. Our approach abstracts program behavior as its memory access pattern during execution, and considers all such relevant behavior, including standard memory reads and writes, predicate comparisons, etc., to obtain a coverage metric on the whole kernel binary for input generation guidance.We implemented a prototype tool KBinCov and integrated it into a popular kernel fuzzer Syzkaller. We evaluated its effectiveness against vanilla Syzkaller, as well as certain other approaches, including StateFuzz and IJON. Our results show that KBinCov achieves code and binary coverage increases of 7\\%, 7\\%, 9\\%, and 87\\%, 34\\%, 61\\%, compared to Syzkaller (using kcov), StateFuzz, and IJON, on recent versions of the Linux kernels, respectively, while only incurring a 1.74\\texttimes{} overhead increase, less than StateFuzz and IJON's 2.5x and 2.2x figures. In addition, we found 21 previously unknown bugs using KBinCov with Syzkaller, more than Syzkaller (with kcov), StateFuzz, and IJON, which found 4, 4, and 2 bugs, respectively.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690232",
    "comment": ""
  },
  {
    "title": "LiftFuzz: Validating Binary Lifters through Context-aware Fuzzing with GPT",
    "author": "Zhou, Yutong and Yang, Fan and Song, Zirui and Zhang, Ke and Chen, Jiongyi and Zhang, Kehuan",
    "abstract": "Analyzing binary code is vital for software engineering and security research, particularly when the source code is unavailable. However, understanding, modifying, and retargeting binary code can be complex tasks. To counter these difficulties, binary lifters have been introduced. These tools translate binary code into Intermediate Representations (IRs), providing several advantages, such as enabling modifications to executables without source code and facilitating code retargetability. So far, accurately developing binary lifters for modern ISAs is universally acknowledged as challenging and error-prone. Existing validation methods mainly concentrate on isolated instructions, overlooking interactions among instructions. In this paper, we introduce LiftFuzz, a novel framework that leverages instruction context-aware fuzzing to validate binary lifters. LiftFuzz harnesses an assembly language model to learn interactions among instructions and generates test cases with the knowledge. LiftFuzz greatly outperforms the baseline, requiring only 1/1000 of the test cases used by the baseline to identify 26 inconsistencies, including a previously uncovered category. LiftFuzz significantly contributes to enhancing the performance of binary lifters, which are frequently employed in binary security applications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670276",
    "comment": ""
  },
  {
    "title": "Prompt Fuzzing for Fuzz Driver Generation",
    "author": "Lyu, Yunlong and Xie, Yuxuan and Chen, Peng and Chen, Hao",
    "abstract": "Crafting high-quality fuzz drivers not only is time-consuming but also requires a deep understanding of the library. However, the state-of-the-art automatic fuzz driver generation techniques fall short of expectations. While fuzz drivers derived from consumer code can reach deep states, they have limited coverage. Conversely, interpretative fuzzing can explore most API calls but requires numerous attempts within a large search space. We propose PromptFuzz, a coverage-guided fuzzer for prompt fuzzing that iteratively generates fuzz drivers to explore undiscovered library code. To explore API usage in fuzz drivers during prompt fuzzing, we propose several key techniques: instructive program generation, erroneous program validation, coverage-guided prompt mutation, and constrained fuzzer scheduling. We implemented PromptFuzz and evaluated it on 14 real-world libraries. Compared with OSS-Fuzz and Hopper (the state-of-the-art fuzz driver generation tool), fuzz drivers generated by PromptFuzz achieved 1.61 and 1.63 times higher branch coverage than those by OSS-Fuzz and Hopper, respectively. Moreover, the fuzz drivers generated by PromptFuzz detected 33 genuine, new bugs out of a total of 49 crashes, out of which 30 bugs have been confirmed by their respective communities.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670396",
    "comment": ""
  },
  {
    "title": "Alchemy: Data-Free Adversarial Training",
    "author": "Bai, Yijie and Ma, Zhongming and Chen, Yanjiao and Deng, Jiangyi and Pang, Shengyuan and Liu, Yan and Xu, Wenyuan",
    "abstract": "Machine learning models have become integral to various aspects of daily life, prompting increased vulnerability to adversarial attacks. Adversarial training is one of the most promising and practical methods to enhance model robustness. Existing adversarial training methods, however, assume access to the original training data. But nowadays, more and more users directly download models from the open-source model platforms or tech companies, but the original training datasets are usually unreleased because of commercial interests or privacy. In such scenarios, the user cannot utilize the former adversarial training methods to improve model robustness because of the lack of original training datasets. Thus, we present the first exploration of a data-free adversarial training framework, Alchemy, which seeks to enhance model robustness without requiring access to the original training data. By addressing the notable challenges of reconstructing high-quality training data with robust features and improving the adversarial robustness to the inaccessible original dataset, our approach achieves the goals of both high accuracy maintenance and robustness improvement. Comprehensive experiments on four datasets compared with five baselines, demonstrate Alchemy's high effectiveness. With no access to any training dataset, the average robustness improvement with Alchemy is effective in most attack scenarios. Additional evaluations underscore the framework's stability under different settings and discuss future research directions.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670395",
    "comment": ""
  },
  {
    "title": "I Don't Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors",
    "author": "Lin, Zijin and Zhao, Yue and Chen, Kai and He, Jinwen",
    "abstract": "Deep neural networks (DNNs) have revolutionized the field of computer vision like object detection with their unparalleled performance. However, existing research has shown that DNNs are vulnerable to adversarial attacks. In the physical world, an adversary could exploit adversarial patches to implement a Hiding Attack (HA) which patches the target object to make it disappear from the detector, and an Appearing Attack (AA) which fools the detector into misclassifying the patch as a specific object. Recently, many defense methods for detectors have been proposed to mitigate the potential threats of adversarial patches. However, such methods still have limitations in generalization, robustness and efficiency. Most defenses are only effective against the HA, leaving the detector vulnerable to the AA.In this paper, we propose NutNet, an innovative model for detecting adversarial patches, with high generalization, robustness and efficiency. With experiments for six detectors including YOLOv2-v4, SSD, Faster RCNN and DETR on both digital and physical domains, the results show that our proposed method can effectively defend against both the HA and AA, with only 0.4\\% sacrifice of the clean performance. We compare NutNet with four baseline defense methods for detectors, and our method exhibits an average defense performance that is over 2.4 times and 4.7 times higher than existing approaches for HA and AA, respectively. In addition, NutNet only increases the inference time by 8\\%, which can meet the real-time requirements of the detection systems. Demos and the full paper of NutNet are available at: https://sites.google.com/view/nutnet.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670317",
    "comment": ""
  },
  {
    "title": "Beowulf: Mitigating Model Extraction Attacks Via Reshaping Decision Regions",
    "author": "Gong, Xueluan and Wei, Rubin and Wang, Ziyao and Sun, Yuchen and Peng, Jiawen and Chen, Yanjiao and Wang, Qian",
    "abstract": "Machine Learning as a Service (MLaaS) enables resource-constrained users to access well-trained models through a publicly accessible Application Programming Interface (API) on a pay-per-query basis. Nevertheless, model owners may face the potential threats of model extraction attacks where malicious users replicate valuable commercial models based on query results. Existing defenses against model extraction attacks, however, either sacrifice prediction accuracy or fail to thwart more advanced attacks. In this paper, we propose a novel model extraction defense, dubbed Beowulf 1 , which draws inspiration from theoretical findings that models with complex and narrow decision regions are difficult to be reproduced. Rather than arbitrarily altering decision regions, which may jeopardize the predictive capacity of the victim model, we introduce a dummy class, carefully synthesized using both random and adversarial noises. The random noise broadens the coverage of the dummy class, and the adversarial noise impacts decision regions near decision boundaries with normal classes. To further improve the model utility, we propose to employ data augmentation methods to seamlessly integrate the dummy class and the normal classes. Extensive evaluations on CIFAR-10, GTSRB, CIFAR-100, and ImageNette datasets demonstrate that Beowulf can significantly reduce the extraction accuracy of 6 state-of-the-art model extraction attacks by as much as 80\\%. Moreover, we show that Beowulf is also robust to adaptive model extraction attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670267",
    "comment": ""
  },
  {
    "title": "PhySense: Defending Physically Realizable Attacks for Autonomous Systems via Consistency Reasoning",
    "author": "Yu, Zhiyuan and Li, Ao and Wen, Ruoyao and Chen, Yijia and Zhang, Ning",
    "abstract": "Autonomous vehicles (AVs) empowered by deep neural networks (DNNs) are bringing transformative changes to our society. However, they are generally susceptible to adversarial attacks, especially physically realizable perturbations that can mislead perception and cause catastrophic outcomes. While existing defenses have shown success, there remains a pressing need for improved robustness while maintaining efficiency to meet real-time system operations.To tackle these challenges, we introduce PhySense, a complementary solution that leverages multi-faceted reasoning for misclassification detection and correction. This defense is built on physical characteristics, including static and dynamic object attributes and their interrelations. To effectively integrate these diverse sources, we develop a system based on the conditional random field that models objects and relationships as a spatial-temporal graph for holistic reasoning on the perceived scene. To ensure the defense does not violate the timing requirement of the real-time cyber-physical control loop, we profile the run-time characteristics of the workloads to parallelize and pipeline the execution of the defense implementation. The efficacy of PhySense is experimentally validated through simulations of datasets and real-world driving tests. It also demonstrates resiliency against adaptive attacks, and the potential of applying underlying principles to other modalities beyond vision.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690236",
    "comment": ""
  },
  {
    "title": "AirGapAgent: Protecting Privacy-Conscious Conversational Agents",
    "author": "Bagdasarian, Eugene and Yi, Ren and Ghalebikesabi, Sahra and Kairouz, Peter and Gruteser, Marco and Oh, Sewoong and Balle, Borja and Ramage, Daniel",
    "abstract": "The growing use of large language model (LLM)-based conversational agents to manage sensitive user data raises significant privacy concerns. While these agents excel at understanding and acting on context, this capability can be exploited by malicious actors. We introduce a novel threat model where adversarial third-party apps manipulate the context of interaction to trick LLM-based agents into revealing private information not relevant to the task at hand.Grounded in the framework of contextual integrity, we introduce AirGapAgent, a privacy-conscious agent designed to prevent unintended data leakage by restricting the agent's access to only the data necessary for a specific task. Extensive experiments using Gemini, GPT, and Mistral models as agents validate our approach's effectiveness in mitigating this form of context hijacking while maintaining core agent functionality. For example, we show that a single-query context hijacking attack on a Gemini Ultra agent reduces its ability to protect user data from 94\\% to 45\\%, while an AirGapAgent achieves 97\\% protection, rendering the same attack ineffective.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690350",
    "comment": ""
  },
  {
    "title": "ERASER: Machine Unlearning in MLaaS via an Inference Serving-Aware Approach",
    "author": "Hu, Yuke and Lou, Jian and Liu, Jiaqi and Ni, Wangze and Lin, Feng and Qin, Zhan and Ren, Kui",
    "abstract": "Over the past years, Machine Learning-as-a-Service (MLaaS) has received a surging demand for supporting Machine Learning-driven services to offer revolutionized user experience across diverse application areas. MLaaS provides inference service with low inference latency based on an ML model trained using a dataset collected from numerous individual data owners. Recently, for the sake of data owners' privacy and to comply with the \"right to be forgotten (RTBF)\" as enacted by data protection legislation, many machine unlearning methods have been proposed to remove data owners' data from trained models upon their unlearning requests. However, despite their promising efficiency, almost all existing machine unlearning methods handle unlearning requests independently from inference requests, which unfortunately introduces a new security issue of inference service obsolescence and a privacy vulnerability of undesirable exposure for machine unlearning in MLaaS.In this paper, we propose the ERASER framework for machin<u>E</u> unlea<u>R</u>ning in MLa<u>AS</u> via an inferenc<u>E</u> se<u>R</u>ving-aware approach. ERASER strategically choose appropriate unlearning execution timing to address the inference service obsolescence issue. A novel inference consistency certification mechanism is proposed to avoid the violation of RTBF principle caused by postponed unlearning executions, thereby mitigating the undesirable exposure vulnerability. ERASER offers three groups of design choices to allow for tailor-made variants that best suit the specific environments and preferences of various MLaaS systems. Extensive empirical evaluations across various settings confirm ERASER's effectiveness, e.g., it can effectively save up to 99\\% of inference latency and 31\\% of computation overhead over the inference-oblivion baseline.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670398",
    "comment": ""
  },
  {
    "title": "The HitchHiker's Guide to High-Assurance System Observability Protection with Efficient Permission Switches",
    "author": "Zhang, Chuqi and Zeng, Jun and Zhang, Yiming and Ahmad, Adil and Zhang, Fengwei and Jin, Hai and Liang, Zhenkai",
    "abstract": "Protecting system observability records (logs) from compromised OSs has gained significant traction in recent times, with several note-worthy approaches proposed. Unfortunately, none of the proposed approaches achieve high performance with tiny log protection delays. They also leverage risky environments for protection (e.g., many use general-purpose hypervisors or TrustZone, which have large TCB and attack surfaces). HitchHiker is an attempt to rectify this problem. The system is designed to ensure (a) in-memory protection of batched logs within a short and configurable real-time deadline by efficient hardware permission switching, and (b) an end-to-end high-assurance environment built upon hardware protection primitives with debloating strategies for secure log protection, persistence, and management. Security evaluations and validations show that HitchHiker reduces log protection delay by 93.3--99.3\\% compared to the state-of-the-art, while reducing TCB by 9.4--26.9X. Performance evaluations show HitchHiker incurs a geometric mean of less than 6\\% overhead on diverse real-world programs, improving on the state-of-the-art approach by 61.9--77.5\\%.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690188",
    "comment": ""
  },
  {
    "title": "Eclipse: Preventing Speculative Memory-error Abuse with Artificial Data Dependencies",
    "author": "Christou, Neophytos and Gaidis, Alexander J. and Atlidakis, Vaggelis and Kemerlis, Vasileios P.",
    "abstract": "Historically, researchers have treated memory safety-based and speculative execution attacks as two separate domains. Recent work has introduced Speculative Memory-error Abuse (SMA) attacks, which combine memory corruption vulnerabilities with Spectre-like primitives. Using SMA, an attacker can leak sensitive program information and defeat a wide variety of memory-corruption mitigations, including (K)ASLR, software-based XOM, and even ARM PA, eventually carrying out an end-to-end (architecturally-visible) exploit. We present Eclipse: a novel protection scheme against SMA attacks. Eclipse works by propagating artificial data dependencies onto sensitive data, preventing the CPU from using attacker-controlled data during speculative execution. We demonstrate that Eclipse provides comprehensive protection against speculative-probing and Pacman-style attacks, two prominent examples of Speculative Memory-error Abuse attacks that target both the x86(-64) and ARM architectures. We evaluate the performance of Eclipse on x86-64 and demonstrate that it introduces minimal overhead, compared to alternative hardening approaches, incurring ≈0\\%--9.5\\% slowdown on SPEC CPU 2017, up to 8.6\\% slowdown in real-world applications, and negligible overhead in the Linux kernel.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690201",
    "comment": ""
  },
  {
    "title": "Toss a Fault to BpfChecker: Revealing Implementation Flaws for eBPF runtimes with Differential Fuzzing",
    "author": "Peng, Chaoyuan and Jiang, Muhui and Wu, Lei and Zhou, Yajin",
    "abstract": "eBPF is a revolutionary technology that can run sandboxed programs in a privileged context and has an extensive range of applications, such as network monitoring on Linux kernel, denial-of-service protection on Windows, and the execution mechanism of smart contracts on blockchain. However, implementation flaws in eBPF have broad-reaching impact and serious consequences. Prior studies primarily focus on the memory safety of the eBPF runtimes, but few can detect implementation flaws (i.e., whether the implementation is correct). Meanwhile, existing implementation flaws detecting methods predominantly address bugs in the verifier, neglecting bugs in other components (i.e., the interpreter and the JIT compiler). In this paper, we present BpfChecker, a differential fuzzing framework to detect implementation flaws in the eBPF runtimes. It utilizes eBPF programs as input, performing differential testing for the critical states across various eBPF runtimes to uncover implementation flaws. To enhance the semantics of generated programs, we devise a lightweight intermediate representation and perform constrained mutations under the guidance of error messages. We have implemented a prototype of BpfChecker and extensively evaluated it on the three eBPF runtimes (i.e., Solana rBPF, vanilla rBPF, Windows eBPF). As a result, we have uncovered 28 new implementation flaws, received 2 CVEs and 800,000 bounty with developers' acknowledgment. More importantly, 2 of the newly found bugs can be used to create divergences in the execution layer of the Solana network.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690237",
    "comment": ""
  },
  {
    "title": "Program Ingredients Abstraction and Instantiation for Synthesis-based JVM Testing",
    "author": "Zhao, Yingquan and Wang, Zan and Chen, Junjie and Fu, Ruifeng and Lu, Yanzhou and Gao, Tianchang and Ye, Haojie",
    "abstract": "Java Virtual Machine (JVM) holds a crucial position in executing various Java programs, thereby necessitating rigorous testing to ensure software reliability and security. Regarding existing JVM testing techniques, synthesis-based techniques have proven to be state-of-the-art, which construct a test program by synthesizing various program ingredients extracted from historical bug-revealing test programs into a seed program. However, existing synthesis-based techniques directly use the program ingredients specific to historical bugs, which limits the test scope without the ability of covering more JVM features and negatively affects the diversity of synthesized test programs.This paper introduces a paradigm of ''ingredient abstraction and instantiation'' for synthesis-based JVM testing and develops a new technique called Jetris. Instead of merely inserting the specific program ingredients into different seed programs, Jetris leverages the knowledge derived from historical bug-revealing program ingredients to generalize bug-revealing patterns (i.e., control- and data-flow patterns), and then utilizes these patterns as guidance to generate more program ingredients. To achieve a more comprehensive exploration, we enrich the generated ingredients by incorporating various program elements (e.g., new data type). We extensively evaluated Jetris on four Long-Term Support OpenJDK versions of two mainstream JVMs (i.e., HotSpot and OpenJ9). The experimental results demonstrate that Jetris can detect more unique bugs than existing techniques, and the test programs generated by Jetris can achieve higher JVM code coverage. Additionally, Jetris successfully detects 21 previously unknown bugs in these mainstream JVMs, and 13 of them have been confirmed/fixed by developers. Moreover, Jetris has been successfully applied to a new JVM implementation in a global IT company and detected 9 bugs during the practical evaluation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690366",
    "comment": ""
  },
  {
    "title": "VMud: Detecting Recurring Vulnerabilities with Multiple Fixing Functions via Function Selection and Semantic Equivalent Statement Matching",
    "author": "Huang, Kaifeng and Lu, Chenhao and Cao, Yiheng and Chen, Bihuan and Peng, Xin",
    "abstract": "The widespread use of open-source software (OSS) has led to extensive code reuse, making vulnerabilities in OSS significantly pervasive. The vulnerabilities due to code reuse in OSS are commonly known as vulnerable code clones (VCCs) or recurring vulnerabilities. Existing approaches primarily employ clone-based techniques to detect recurring vulnerabilities by matching vulnerable functions in software projects. These techniques do not incorporate specially designed mechanisms for vulnerabilities with multiple fixing functions (VM). Typically, they generate a signature for each fixing function and report VM using a matching-one-in-all approach. However, the variation in vulnerability context across diverse fixing functions results in varying accuracy levels in detecting VM, potentially limiting the effectiveness of existing methods.In this paper, we introduce VMud, a novel approach for detecting Vulnerabilities with Multiple Fixing Functions. VMud identifies vulnerable function clones (VCCs) through function matching similar to existing methods. However, VMud takes a different approach by only selecting the critical functions from VM for signature generation, which are a subset of the fixing functions. This step ensures that VMud focuses on fixing functions that offer sufficient knowledge about the VM. To cope with the potential decrease in recall due to excluding the remaining fixing functions, VMud employs semantic equivalent statement matching using these critical functions. It aims to uncover more VM by creating two signatures of each critical function and matching precisely by contextual semantic equivalent statement mapping on the two signatures. Our evaluation has demonstrated that VMud surpasses state-of-the-art vulnerability detection approaches by 30.30\\% in terms of F1-Score. Furthermore, VMud has successfully detected 275 new VM from 84 projects, with 42 confirmed cases and 5 assigned CVE identifiers.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690372",
    "comment": ""
  },
  {
    "title": "On Understanding and Forecasting Fuzzers Performance with Static Analysis",
    "author": "Zhang, Dongjia and Fioraldi, Andrea and Balzarotti, Davide",
    "abstract": "Fuzz testing, a technique for detecting critical software vulnerabilities, combines various methodologies from previous research to improve its effectiveness. For fuzzing practitioners, it is imperative to comprehend the effects of distinct techniques and select the ideal configuration customized to the program they need to test.However, evaluating the individual contributions of these techniques is often very difficult. Prior research compared assembled fuzzers and studied their affinity with different programs. Nevertheless, assembled fuzzers cannot be easily broken down into independent components, and therefore, the evaluation does not clarify which technique explains the performance of the fuzzer. Without understanding the potential impact of integrating different fuzzing techniques, it becomes even more challenging to adjust the fuzzer configuration for different programs under test.Our research tackles this challenge by introducing a novel approach that correlates static analysis features extracted at compile time with the performance results of various fuzzing techniques. Our method uses diverse metrics to uncover the relationship between the static attributes of a program and the dynamic runtime performance of fuzzers. The correlation analysis performed on 23 target applications reveals interesting relationships, such as power schedulers performing better with larger programs and context-sensitive feedback, struggling with a large number of inputs.This approach not only enhances our analytical understanding of fuzzing techniques, but also enables predictive capabilities. We show how a simple machine learning model can propose a fuzzer configuration customized for a particular program using information collected through static analysis. In 11 of our benchmark programs, fuzzers using the suggested configuration achieved the best improvement over the baseline compared to AFLplusplus, LibFuzzer and Honggfuzz.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670348",
    "comment": ""
  },
  {
    "title": "End-to-End Encrypted Cloud Storage in the Wild: A Broken Ecosystem",
    "author": "Hofmann, Jonas and Truong, Kien Tuong",
    "abstract": "End-to-end encrypted cloud storage offers a way for individuals and organisations to delegate their storage needs to a third-party, while keeping control of their data using cryptographic techniques. We conduct a cryptographic analysis of various products in the ecosystem, showing that many providers fail to provide an adequate level of security. In particular, we provide an in-depth analysis of five end-to-end encrypted cloud storage systems, namely Sync, pCloud, Icedrive, Seafile, and Tresorit, in the setting of a malicious server. These companies cumulatively have over 22 million users and are major providers in the field. We unveil severe cryptographic vulnerabilities in four of them. Our attacks invalidate the marketing claims made by the providers of these systems, showing that a malicious server can, in some cases, inject files in the encrypted storage of users, tamper with file data, and even gain direct access to the content of the files. Many of our attacks affect multiple providers in the same way, revealing common failure patterns in independent cryptographic designs. We conclude by discussing the significance of these patterns beyond the security of the specific providers.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690309",
    "comment": ""
  },
  {
    "title": "Scalable Equi-Join Queries over Encrypted Database",
    "author": "Du, Kai and Wang, Jianfeng and Wu, Jiaojiao and Wang, Yunling",
    "abstract": "Secure join queries over encrypted databases, the most expressive class of SQL queries, have attracted extensive attention recently. The state-of-the-art JXT (Jutla et al. ASIACRYPT 2022) enables join queries on encrypted relational databases without pre-computing all possible joins. However, JXT can merely support join queries over two tables (in encrypted databases) with some high-entropy join attributes. In this paper, we propose an equi-join query protocol over two tables dubbed JXT+, that allows the join attributes with arbitrary names instead of JXT requiring the identical name for join attributes. JXT+ reduces the query complexity from O(ell_1 cdot ell_2) to O(ell_1) as compared to JXT, where ell_1 and ell_2 denote the numbers of matching records in two tables respectively. Furthermore, we present JXT++, the first equi-join queries across three or more tables over encrypted databases without pre-computation. Specifically, JXT++ supports joins of arbitrary attributes, i.e., all attributes (even low-entropy) can be candidates for join, while JXT requires high-entropy join attributes. In addition, JXT++ can alleviate sub-query leakage on three or more tables, which hides the leakage from the matching records of two-table join. Finally, we implement and compare our proposed schemes with the state-of-the-art JXT. The experimental results demonstrate that both of our schemes are superior to JXT in search and storage costs. In particular, JXT+ (resp., JXT++) brings a saving of 49\\% (resp., 68\\%) in server storage cost and achieves a speedup of 51.7\\texttimes{} (resp., 54.3\\texttimes{}) in search latency.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690377",
    "comment": ""
  },
  {
    "title": "Graphiti: Secure Graph Computation Made More Scalable",
    "author": "Koti, Nishat and Kukkala, Varsha Bhat and Patra, Arpita and Raj Gopal, Bhavish",
    "abstract": "Privacy-preserving graph analysis allows performing computations on graphs that store sensitive information while ensuring all the information about the topology of the graph, as well as data associated with the nodes and edges, remains hidden. The current work addresses this problem by designing a highly scalable framework, Graphiti, that allows securely realising any graph algorithm. Graphiti relies on the technique of secure multiparty computation (MPC) to design a generic framework that improves over the state-of-the-art framework of GraphSC by Araki et al. (CCS'21). The key technical contribution is that Graphiti has round complexity independent of the graph size, which in turn allows attaining the desired scalability. Specifically, this is achieved by (i) decoupling the Scatter primitive of GraphSC into separate operations of Propagate and ApplyE, (ii) designing a novel constant-round approach to realise Propagate, as well as (iii) designing a novel constant-round approach to realise the Gather primitive of GraphSC by leveraging the linearity of the aggregation operation. We benchmark the performance of Graphiti for the application of contact tracing via BFS for 10 hops and observe that it takes less than 2 minutes when computing over a graph of size 10^7. Concretely it improves over the state-of-the-art up to a factor of 1034\\texttimes{} in online run time. Similar to GraphSC by Araki et al., since Graphiti relies on a secure protocol for shuffle, we additionally design a shuffle protocol secure against a semi-honest adversary in the 2-party with a helper setting. Given the versatility of shuffle protocol, the designed solution is of independent interest. Hence, we also benchmark the performance of the designed shuffle where we observe improvements of up to 1.83\\texttimes{} in online run time when considering an input vector of size 10^7, in comparison to the state-of-the-art in the considered setting.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670393",
    "comment": ""
  },
  {
    "title": "CoGNN: Towards Secure and Efficient Collaborative Graph Learning",
    "author": "Zou, Zhenhua and Liu, Zhuotao and Shan, Jinyong and Li, Qi and Xu, Ke and Xu, Mingwei",
    "abstract": "Collaborative graph learning represents a learning paradigm where multiple parties jointly train a graph neural network (GNN) using their own proprietary graph data. To honor the data privacy of all parties, existing solutions for collaborative graph learning are either based on federated learning (FL) or secure machine learning (SML). Although promising in terms of efficiency and scalability due to their distributed training scheme, FL-based approaches fall short in providing provable security guarantees and achieving good model performance. Conversely, SML-based solutions, while offering provable privacy guarantees, are hindered by their high computational and communication overhead, as well as poor scalability as more parties participate.To address the above problem, we propose CoGNN, a novel framework that simultaneously reaps the benefits of both FL-based and SML-based approaches. At a high level, CoGNN is enabled by (i) a novel message passing mechanism that can obliviously and efficiently express the vertex data propagation/aggregation required in GNN training and inference and (ii) a two-stage Dispatch-Collect execution scheme to securely decompose and distribute the GNN computation workload for concurrent and scalable executions. We further instantiate the CoGNN framework, together with customized optimizations, to train Graph Convolutional Network (GCN) models. Extensive evaluations on three graph datasets demonstrate that compared with the state-of-the-art (SOTA) SML-based approach, CoGNN reduces up to 123x running time and up to 522x communication cost per party. Meanwhile, the GCN models trained using CoGNN have nearly identical accuracies as the plaintext global-graph training, yielding up to 11.06\\% accuracy improvement over the GCN models trained via federated learning.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670300",
    "comment": ""
  },
  {
    "title": "PathGES: An Efficient and Secure Graph Encryption Scheme for Shortest Path Queries",
    "author": "Falzon, Francesca and Ghosh, Esha and Paterson, Kenneth G. and Tamassia, Roberto",
    "abstract": "The increasing importance of graph databases and cloud storage services prompts the study of private queries on graphs. We propose PathGES, a graph encryption scheme (GES) for single-pair shortest path queries. PathGES is efficient and mitigates the state-of-the-art attack by Falzon and Paterson (2022) on the GES by Ghosh, Kamara, and Tamassia (2021), while only incurring an additional logarithmic factor in storage overhead. PathGES leverages a novel data structure that minimizes leakage and server computation.We generalize what it means for one leakage function to leak less than another by defining a relation with respect to a family of query sequences and show that our scheme provably leaks less than the GKT scheme when all queries have been issued. We complement our security proof with a cryptanalysis that demonstrates an information-theoretic gap in the size of the query reconstruction space of our scheme as compared to the GKT scheme and provide concrete examples of the gap for several graph families. Our prototype implementation of PathGES is efficient in practice for real-world social network and geographic data sets. In comparison with the GKT scheme, PathGES has the same response size on average and up to 1.5x faster round-trip query time.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670305",
    "comment": ""
  },
  {
    "title": "Secure Vickrey Auctions with Rational Parties",
    "author": "Ganesh, Chaya and Gupta, Shreyas and Kanukurthi, Bhavana and Shankar, Girisha",
    "abstract": "In this work, we construct a second price (Vickrey) auction protocol (SPA), which does not require any auctioneers and ensures total privacy in the presence of rational parties participating in the auction. In particular, the confidentiality of the highest bid and the identity of the second highest bidder are protected. We model the bidders participating in the second price auction as rational, computationally bounded and privacy-sensitive parties. These are self-interested agents who care about winning the auction more than learning about the private bids of other parties. A rational party does not deviate from the protocol arbitrarily but does so only for its own individual 'advantage' -- without any consideration for others. Such an advantage is modelled using suitable utility functions.We show that for rational and computationally bounded parties participating in our second-price auctions protocol, there exists a privacy-preserving dominant strategy equilibrium in which every party prefers to follow the protocol rather than to deviate.Our protocol is implemented using open-source cryptographic constructs. Running our SPA protocol on commodity hardware with 15 bidders, with bids of length 10 bits, completes in 1.26sec and has total communication of 0.77MB whereas, under similar conditions, Atlas (semi-honest) protocol takes 40\\% more time (2.11 sec) and 87\\% more communication (6.09MB).",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670311",
    "comment": ""
  },
  {
    "title": "Batching-Efficient RAM using Updatable Lookup Arguments",
    "author": "Dutta, Moumita and Ganesh, Chaya and Patranabis, Sikhar and Prakash, Shubh and Singh, Nitin",
    "abstract": "RAM (random access memory) is an important primitive in verifiable computation. In this paper, we focus on realizing RAM with efficient batching property, i.e, proving a batch of m updates on a RAM of size N while incurring a cost that is sublinear in N. Classical approaches based on Merkle-trees or address ordered transcripts to model RAM correctness are either concretely inefficient, or incur linear overhead in the size of the RAM. Recent works explore cryptographic accumulators based on unknown-order groups (RSA, class-groups) to model the RAM state. While recent RSA accumulator based approaches offer significant improvement over classical methods, they incur linear overhead in the size of the accumulated set to compute witnesses, as well as prohibitive constant overheads.We realize a batching-efficient RAM with superior asymptotic and concrete costs as compared to existing approaches. Towards this: (i) we build on recent constructions of lookup arguments to allow efficient lookups even in presence of table updates, and (ii) we realize a variant of sub-vector relation addressed in prior works, which we call committed index lookup. We combine the two building blocks to realize batching-efficient RAM with sublinear dependence on size of the RAM. Our construction incurs an amortized proving cost of ~O(m log m + √(mN)) for a batch of m updates on a RAM of size N. Our results also benefit the recent arguments for sub-vector relation, by enabling them to be efficient in presence of updates to the table. We believe that this is a contribution of independent interest.We implement our solution to evaluate its concrete efficiency. Our experiments show that it offers significant improvement over existing works on batching-efficient accumulators/RAMs, with a substantially reduced resource barrier.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670356",
    "comment": ""
  },
  {
    "title": "Multi-Verifier Zero-Knowledge Proofs for Any Constant Fraction of Corrupted Verifiers",
    "author": "Escudero, Daniel and Polychroniadou, Antigoni and Song, Yifan and Weng, Chenkai",
    "abstract": "In this work we study the efficiency of Zero-Knowledge (ZK) arguments of knowledge, particularly exploring Multi-Verifier ZK (MVZK) protocols as a midway point between Non-Interactive ZK and Designated-Verifier ZK, offering versatile applications across various domains. We introduce a new MVZK protocol designed for the preprocessing model, allowing any constant fraction of verifiers to be corrupted, potentially colluding with the prover. Our contributions include the first MVZK over rings. Unlike recent prior works on fields in the dishonest majority case, our protocol demonstrates communication complexity independent of the number of verifiers, contrasting the linear complexity of previous approaches. This key advancement ensures improved scalability and efficiency. We provide an end-to-end implementation of our protocol. The benchmark shows that it achieves a throughput of 1.47 million gates per second for 64 verifiers with 50\\% corruption, and 0.88 million gates per second with 75\\% corruption.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670357",
    "comment": ""
  },
  {
    "title": "Call Me By My Name: Simple, Practical Private Information Retrieval for Keyword Queries",
    "author": "Celi, Sofia and Davidson, Alex",
    "abstract": "We introduce ChalametPIR: a single-server Private Information Retrieval (PIR) scheme supporting fast, low-bandwidth keyword queries, with a conceptually very simple design. In particular, we develop a generic framework for converting PIR schemes for index queries over flat arrays (based on the Learning With Errors problem) into keyword PIR. This involves representing a key-value map using any probabilistic filter that permits reconstruction of elements from inclusion queries (e.g. Cuckoo filters). In particular, we make use of recently developed Binary Fuse filters to construct ChalametPIR, with minimal efficiency blow-up compared with state-of-the-art index-based schemes (all costs bounded by a factor of (≤ 1.08)). Furthermore, we show that ChalametPIR achieves runtimes and financial costs that are factors of between (6x)-(11x) and (3.75x)-(11.4x) more efficient, respectively, than state-of-the-art keyword PIR approaches, for varying database configurations. Bandwidth costs are additionally reduced or remain competitive, depending on the configuration. Finally, we believe that our application of Binary Fuse filters can have independent value towards developing efficient variants of related cryptographic primitives (e.g. private set intersection), that already benefit from using less efficient filter constructions.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670271",
    "comment": ""
  },
  {
    "title": "Computationally Secure Aggregation and Private Information Retrieval in the Shuffle Model",
    "author": "Gasc\\'{o}n, Adri\\`{a} and Ishai, Yuval and Kelkar, Mahimna and Li, Baiyu and Ma, Yiping and Raykova, Mariana",
    "abstract": "The shuffle model has recently emerged as a popular setting for differential privacy, where clients can communicate with a central server using anonymous channels or an intermediate message shuffler. This model was also explored in the context of cryptographic tasks such as secure aggregation and private information retrieval (PIR). However, this study was almost entirely restricted to the stringent notion of information-theoretic security.In this work, we study computationally secure aggregation protocols and PIR in the shuffle model. Our starting point is the insight that the previous technique of shuffling additive shares can be improved in the computational setting. We show that this indeed holds under the standard learning parity with noise (LPN) assumption, but even better efficiency follows from plausible conjectures about the multi-disjoint syndrome decoding (MDSD) problem that we introduce and study in this work.We leverage the above towards improving the efficiency of secure aggregation and PIR in the shuffle model. For secure aggregation of long vectors, our protocols require 9x--25x less communication than the previous information-theoretic solutions. Our PIR protocols enjoy the simplicity and concrete efficiency benefits of multi-server PIR while only requiring a single server to store the database. Under the MDSD assumption, they improve over recent single-server PIR constructions by up to two orders of magnitude.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670391",
    "comment": ""
  },
  {
    "title": "Efficient Scalable Multi-Party Private Set Intersection(-Variants) from Bicentric Zero-Sharing",
    "author": "Gao, Ying and Luo, Yuanchao and Wang, Longxin and Liu, Xiang and Qi, Lin and Wang, Wei and Zhou, Mengmeng",
    "abstract": "Multi-party private set intersection (MPSI) allows n (ngeq3) participants, each holding a dataset of size m, to compute the intersection of their sets without revealing any additional information. We extract a primitive called bicentric zero-sharing, which can reduce MPSI to two-party PSI between two central participants named Pivot and Leader. We introduce an efficient instantiation of bicentric zero-sharing, which involves a round of sharing and reconstruction of an oblivious key-value store (OKVS) object. We then combine this construction with two-party PSI to propose a new efficient scalable MPSI protocol. We also propose protocols for computing MPSI variants based on bicentric zero-sharing, such as multi-party private set intersection cardinality (MPSI-CA) and multi-party threshold private set intersection (MTPSI). Our protocols are mainly based on symmetric-key operations, and the communication complexity of each participant is at most O(n+m). The security of our protocols relies on the assumption that Leader and Pivot do not collude, which can be applicable in many scenarios. In this case, our protocols are secure against arbitrary collusion (except Leader and Pivot) in the semi-honest model. Moreover, our protocols are secure against up to n-2 malicious Clients (participants except Leader and Pivot) in the random oracle model. All these protocols realize the scalability with the number of participants.We demonstrate the scalability of our protocols with an implementation and a comparison with the state-of-the-art MPSI. Experiments show that when computing MPSI for 15 participants with datasets of 220 elements each, our protocol is 46.4x faster in the LAN setting, 18.3x faster in WAN setting, and requires 24.7x less communication cost compared to the state-of-the-art in CCS'21 (by Nevo et al.), and the improvement becomes more significant as the number of participants and set size increases. To the best of our knowledge, ours are the first protocols that report on more than 100 participants. For 140 participants with datasets of 220 elements each, our MPSI and MPSI-CA protocol requires only 4.557s and 16.02s in the LAN setting, respectively.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690245",
    "comment": ""
  },
  {
    "title": "High-Throughput Three-Party DPFs with Applications to ORAM and Digital Currencies",
    "author": "Zyskind, Guy and Yanai, Avishay and Pentland, Alex 'Sandy'",
    "abstract": "Distributed point functions (DPF) are increasingly becoming a foundational tool with applications for application-specific and general secure computation. While two-party DPF constructions are readily available for those applications with satisfiable performance, the three-party ones are left behind in both security and efficiency. In this paper we close this gap and propose the first three-party DPF construction that matches the state-of-the-art two-party DPF on all metrics. Namely, it is secure against a malicious adversary corrupting both the dealer and one out of the three evaluators, its function's shares are of the same size and evaluation takes the same time as in the best two-party DPF. Compared to the state-of-the-art three-party DPF, our construction enjoys 40-120\\texttimes{} smaller function's share size and shorter evaluation time, for function domains of 216 -240, respectively.Apart from DPFs as a stand-alone tool, our construction finds immediate applications to private information retrieval (PIR), writing (PIW) and oblivious RAM (ORAM). To further showcase its applicability, we design and implement an ORAM with access policy, an extension to ORAMs where a policy is being checked before accessing the underlying database. The policy we plug-in is the one suitable for account-based digital currencies, and in particular to central bank digital currencies (CBDCs). Our protocol offers the first design and implementation of a large scale privacy-preserving account-based digital currency. While previous works supported anonymity sets of 64-256 clients and less than 10 transactions per second (tps), our protocol supports anonymity sets in the millions, performing {500,200,58} tps for anonymity sets of {216, 218, 220}, respectively.Toward that application, we introduce a new primitive called updatable DPF, which enables a direct computation of a dot product between a DPF and a vector; we believe that updatable DPF and the new dot-product protocol will find interest in other applications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670292",
    "comment": ""
  },
  {
    "title": "Employees' Attitudes towards Phishing Simulations: \"It's like when a child reaches onto the hot hob\"",
    "author": "Schiller, Katharina and Adamsky, Florian and Eichenm\\\"{u}ller, Christian and Reimert, Matthias and Benenson, Zinaida",
    "abstract": "E-mail phishing attacks remain one of the most significant challenges in IT security and are often used for initial access. Many organizations rely on phishing simulations to educate their staff to recognize suspicious e-mails. Previous studies have analyzed the effectiveness of these phishing simulations with mixed findings. However, the perception of and attitudes towards phishing simulations among staff have received little to no attention. This paper presents findings from a study that we carried out in cooperation with a multinational company that conducted phishing simulations over more than 12 months. We first conducted a quantitative survey involving 757 employees and then qualitative interviews with 22 participants to gain deeper insights into the perception of phishing simulations and the corresponding e-learning. We could not find evidence that employees feel attacked by their organization, as previous studies suspected. On the contrary, we found that a majority 86.9 \\% have a positive or very positive attitude towards phishing simulations. The interviews revealed that some employees developed new routines for e-mail processing, but most describe themselves as having become more vigilant without concrete changes. Furthermore, we found evidence that phishing simulations create a false sense of security, as the employees feel protected by them. Additionally, a lack of communication and feedback can negatively impact employees' attitudes and lead to adverse consequences. Finally, we show that only a small portion of the employees who clicked on the phishing website interacted with the interactive e-learning elements, which raises questions about its objective usefulness, although they are perceived as useful.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690212",
    "comment": ""
  },
  {
    "title": "Content, Nudges and Incentives: A Study on the Effectiveness and Perception of Embedded Phishing Training",
    "author": "Lain, Daniele and Jost, Tarek and Matetic, Sinisa and Kostiainen, Kari and Capkun, Srdjan",
    "abstract": "A common form of phishing training in organizations is the use of simulated phishing emails to test employees' susceptibility to phishing attacks, and the immediate delivery of training material to those who fail the test. This widespread practice is dubbed embedded training; however, its effectiveness in decreasing the likelihood of employees falling for phishing again in the future is questioned by the contradictory findings of several recent field studies.We investigate embedded phishing training in three aspects. First, we observe that the practice incorporates different components---knowledge gains from its content, nudges and reminders from the test itself, and the deterrent effect of potential consequences---our goal is to study which ones are more effective, if any. Second, we explore two potential improvements to training, namely its timing and the use of incentives. Third, we analyze employees' reception and perception of the practice. For this, we conducted a large-scale mixed-methods (quantitative and qualitative) study on the employees of a partner company.Our study contributes several novel findings on the training practice: in particular, its effectiveness comes from its nudging effect, i.e., the periodic reminder of the threat rather than from its content, which is rarely consumed by employees due to lack of time and perceived usefulness. Further, delaying training to ease time pressure is as effective as currently established practices, while rewards do not improve secure behavior. Finally, some of our results support previous findings with increased ecological validity, e.g., that phishing is an attention problem, rather than a knowledge one, even for the most susceptible employees, and thus enforcing training does not help.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690348",
    "comment": ""
  },
  {
    "title": "\"I Had Sort of a Sense that I Was Always Being Watched...Since I Was\": Examining Interpersonal Discomfort From Continuous Location-Sharing Applications",
    "author": "Childs, Kevin and Gibson, Cassidy and Crowder, Anna and Warren, Kevin and Stillman, Carson and Redmiles, Elissa M. and Jain, Eakta and Traynor, Patrick and Butler, Kevin R. B.",
    "abstract": "Continuous location sharing (CLS) applications are widely used for safety and social convenience. However, these applications have privacy concerns that can be used for control and harm. To understand user concerns, we performed the largest user study of CLS application usage performed to date, with 1500 of 3000 users indicating they use CLS applications and 896 of these users completing surveys. From survey responses, we conducted 23 interviews with participants who had uncomfortable experiences. With these interviews, we perform thematic analysis grounded by sociological frameworks of power dynamics and social exchange theory. We observe that CLS application users face discomfort related to three primary categories that build on each other: (1) overstepped boundaries, (2) continued discomfort, and (3) lifestyle-impacting behaviors. With this foundational understanding, we suggest features that aim to reduce relationship imbalances that CLS applications enable. Our resulting study demonstrates that CLS applications contribute to interpersonal discomfort, highlighting the need for design changes.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690342",
    "comment": ""
  },
  {
    "title": "When Compiler Optimizations Meet Symbolic Execution: An Empirical Study",
    "author": "Zhang, Yue and Sirlanci, Melih and Wang, Ruoyu and Lin, Zhiqiang",
    "abstract": "Compiler optimizations intend to transform a program into a semantic-equivalent one with improved performance, but it is unclear how these optimizations may impact the performance of dynamic symbolic execution (DSE) on binary code. To systematically understand the impact of compiler optimizations on two popular DSE techniques (i.e., symbolic exploration and symbolic tracing), this paper presents an empirical study that quantifies 209 GCC compilation flags and 73 Clang compilation flags to reveal both positive and negative optimizations to DSE. Our data set contains 992 unique test cases, which are produced from 3,449 source files in the GCC test suite. After analyzing 2,978,976 binary programs that we compiled with two compilers and various compilation flags, we found that although some optimizations make DSE faster, most optimizations will actually slow down DSE. Our analysis further reveals root causes behind these impacts. The most positive impacts that optimizations have on DSE come from the reduction of the number of instructions and program paths, whereas negative impacts are caused by a series of unexpected behaviors, including increased numbers of instructions or program paths, library function inlining preventing DSE engines from using function summaries, and arithmetic optimizations leading to more sophisticated constraints. Being the first in-depth analysis on why compiler flags influence the performance of DSE, this project sheds light on program transformations that can be applied before performing DSE tasks for better performance.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670372",
    "comment": ""
  },
  {
    "title": "Defying the Odds: Solana's Unexpected Resilience in Spite of the Security Challenges Faced by Developers",
    "author": "Andreina, S\\'{e}bastien and Cloosters, Tobias and Davi, Lucas and Giesen, Jens-Rene and Gutfleisch, Marco and Karame, Ghassan and Naiakshina, Alena and Naji, Houda",
    "abstract": "Solana gained considerable attention as one of the most popular blockchain platforms for deploying decentralized applications. Compared to Ethereum, however, we observe a lack of research on how Solana smart contract developers handle security, what challenges they encounter, and how this affects the overall security of the ecosystem. To address this, we conducted the first comprehensive study on the Solana platform consisting of a 90-minute Solana smart contract code review task with 35 participants followed by interviews with a subset of seven participants. Our study shows, quite alarmingly, that none of the participants could detect all important security vulnerabilities in a code review task and that 83\\% of the participants are likely to release vulnerable smart contracts. Our study also sheds light on the root causes of developers' challenges with Solana smart contract development, suggesting the need for better security guidance and resources. In spite of these challenges, our automated analysis on currently deployed Solana smart contracts surprisingly suggests that the prevalence of vulnerabilities - especially those pointed out as the most challenging in our developer study - is below 0.3\\%. We explore the causes of this counter-intuitive resilience and show that frameworks, such as Anchor, are aiding Solana developers in deploying secure contracts.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670333",
    "comment": ""
  },
  {
    "title": "Unmasking the Security and Usability of Password Masking",
    "author": "Hu, Yuqi and Alroomi, Suood and Sahin, Sena and Li, Frank",
    "abstract": "Password masking, a practice where passwords are obscured during entry, is widely adopted for online authentication. However, its merits have been debated for over a decade, with questions about its security benefits and concerns about its usability impact. Yet to date, masking has received limited prior exploration.In this work, we empirically investigate the security and usability impact of password masking. We first assess the masking practices of popular browsers and websites, demonstrating masking's ubiquity as well as its design diversity. Guided by our real-world observations, we then conduct a mixed-method evaluation of masking for both mobile and PC devices, combining a survey of over 200 participants on their experiences with and perspectives on masking along with user experiments of 600 participants performing password logins under varying masking conditions. Through our study, we uncover misconceptions about masking, masking's usability and security impact, and user preferences on masking's use and its design. Ultimately, our study establishes empirical grounding on how this popular technique manifests in practice, providing recommendations for its use moving forward.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690333",
    "comment": ""
  },
  {
    "title": "Batch Range Proof: How to Make Threshold ECDSA More Efficient",
    "author": "Tang, Guofeng and Han, Shuai and Lin, Li and Wei, Changzheng and Yan, Ying",
    "abstract": "With the demand of cryptocurrencies, threshold ECDSA recently regained popularity. So far, several methods have been proposed to construct threshold ECDSA, including the usage of OT and homomorphic encryptions (HE). Due to the mismatch between the plaintext space and the signature space, HE-based threshold ECDSA always requires zero-knowledge range proofs, such as Paillier and Joye-Libert (JL) encryptions. However, the overhead of range proofs constitutes a major portion of the total cost.In this paper, we propose efficient batch range proofs to improve the efficiency of threshold ECDSA. At the heart of our efficiency improvement is a new technical tool calledMulti-Dimension Forking Lemma, as a generalization of the well-known general forking lemma [Bellare and Neven, CCS 2006]. Based on our new tool, we construct efficient batch range proofs for Paillier and JL encryptions, and use them to give batch multiplication-to-addition (MtA) protocols, which are crucial to most threshold ECDSA. Our constructions improve the prior Paillier-based MtA by a factor of 2 and the prior JL-based MtA by a factor of 3, in both computation and bandwidth in an amortized way. Our batch MtA can be used to improve the efficiency of most Paillier and JL based threshold ECDSA. As three typical examples, our benchmarking results show: 1. We improve the Paillier-based CGGMP20 [Canetti et al., CCS 2020] in bandwidth by a factor of 2.1 to 2.4, in computation by a factor of 1.5 to 1.7. 2. By implementing threshold ECDSA with the batch JL MtA of XAL+23 [Xue et al., CCS 2023] and our batch JL MtA respectively, our batch construction improves theirs in bandwidth by a factor of 2.0 to 2.29, in computation by a factor of 1.88 to 2.09. 3. When replacing OT-based MtA in DKLs24 [Doerner et al., S&P 2024] with our Paillier-based batch MtA, we improve the bandwidth efficiency by 7.8\\texttimes{} at the cost of 5.7\\texttimes{} slower computation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670287",
    "comment": ""
  },
  {
    "title": "RSA-Based Dynamic Accumulator without Hashing into Primes",
    "author": "Kemmoe, Victor Youdom and Lysyanskaya, Anna",
    "abstract": "A cryptographic accumulator is a compact data structure for representing a set of elements coming from some domain. It allows for a compact proof of membership and, in the case of a universal accumulator, non-membership of an element x in the data structure. A dynamic accumulator, furthermore, allows elements to be added to and deleted from the accumulator.Previously known RSA-based dynamic accumulators were too slow in practice because they required that an element in the domain be represented as a prime number. Accumulators based on settings other than RSA had other drawbacks such as requiring a prohibitively large common reference string or a trapdoor, or not permitting deletions.In this paper, we construct an RSA-based dynamic accumulator that does not require that the accumulated elements be represented as primes and show how it can be extended into a universal accumulator. We also show how to aggregate membership and non-membership witnesses and batch additions and deletions. We demonstrate that, for 112-bit, 128-bit, and 192-bit security, the efficiency gains compared to previously known RSA-based accumulators are substantial, and, for the first time, make cryptographic accumulators a viable candidate for a certificate revocation mechanism as part of a WebPKI-type system. To achieve an efficient verification time for aggregated witnesses, we introduce a variant of Wesolowski's proof of exponentiation (Journal of Cryptology 2020) that does not require hashing into primes.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690199",
    "comment": ""
  },
  {
    "title": "Non-interactive VSS using Class Groups and Application to DKG",
    "author": "Kate, Aniket and Mangipudi, Easwar Vivek and Mukherjee, Pratyay and Saleem, Hamza and Thyagarajan, Sri Aravinda Krishnan",
    "abstract": "We put forward a non-interactive verifiable secret sharing (NI-VSS) scheme using class groups - we call it cgVSS. Our construction follows the standard framework of encrypting the shares to a set of recipients and generating a non-interactive proof of correct sharing. However, as opposed to prior works, such as Groth's [Eprint 2021], or Gentry et al.'s [Eurocrypt 2022], we do not require any range proof - this is possible due to the unique structure of class groups, that enables efficient encryption/decryption of large field elements in the exponent of an ElGamal-style encryption scheme. Importantly, this is possible without destroying the additive homomorphic structure, which is required to make the proof-of-correctness highly efficient. This approach not only substantially simplifies the NI-VSS process, but also outperforms the state-of-art schemes significantly. For example, our implementation shows that for a 150 node system cgVSS outperforms (a simplified implementation of) Groth's protocol in overall communication complexity by 5.6x, about 9.3 -- 9.7x in the dealer time and 2.4 - 2.7x in the receiver time per node.Additionally, we formalize the notion of public verifiability, which enables anyone, possibly outside the participants, to verify the correctness of the dealing. In fact, we re-interpret the notion of public verifiability and extend it to the setting when potentially all recipients may be corrupt and yet can not defy public verifiability - to distinguish from state-of-art, we call this strong public verifiability. Our formalization uses the universal composability framework.Finally, through a generic transformation, we obtain a non-interactive distributed key generation (NI-DKG) scheme for threshold systems, where the secret key is the discrete log of the public key. Our security analysis in the VSS-hybrid model uses a formalization that considers a (strong) public verifiability notion for DKG, even when more than threshold parties are corrupt. Instantiating with cgVSS we obtain a NI-DKG scheme from class groups - we call it cgDKG.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670312",
    "comment": ""
  },
  {
    "title": "zkPi: Proving Lean Theorems in Zero-Knowledge",
    "author": "Laufer, Evan and Ozdemir, Alex and Boneh, Dan",
    "abstract": "Interactive theorem provers (ITPs), such as Lean and Coq, can express formal proofs for a large category of theorems, from abstract math to software correctness. Consider Alice who has a Lean proof for some public statement T. Alice wants to convince the world that she has such a proof, without revealing the actual proof. Perhaps the proof shows that a secret program is correct or safe, but the proof itself might leak information about the program's source code. A natural way for Alice to proceed is to construct a succinct, zero-knowledge, non-interactive argument of knowledge (zkSNARK) to prove that she has a Lean proof for the statement T.In this work we build zkPi, the first zkSNARK for proofs expressed in Lean, a state of the art interactive theorem prover. With zkPi, a prover can convince a verifier that a Lean theorem is true, while revealing little else. The core problem is building an efficient zkSNARK for dependent typing. We evaluate zkPi on theorems from two core Lean libraries: stdlib and mathlib. zkPi successfully proves 57.9\\% of the theorems in stdlib, and 14.1\\% of the theorems in mathlib, within 4.5 minutes per theorem. A zkPi proof is sufficiently short that Fermat could have written one in the margin of his proverbial notebook.Interactive theorem provers (ITPs) can express virtually all systems of formal reasoning. Thus, an implemented zkSNARK for ITP theorems generalizes practical zero-knowledge's interface beyond the status quo: circuit satisfiability and program execution.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670322",
    "comment": ""
  },
  {
    "title": "Zero-Knowledge Proofs of Training for Deep Neural Networks",
    "author": "Abbaszadeh, Kasra and Pappas, Christodoulos and Katz, Jonathan and Papadopoulos, Dimitrios",
    "abstract": "A zero-knowledge proof of training (zkPoT) enables a party to prove that they have correctly trained a committed model based on a committed dataset without revealing any additional information about the model or the dataset. An ideal zkPoT should offer provable security and privacy guarantees, succinct proof size and verifier runtime, and practical prover efficiency. In this work, we present Kaizen, a zkPoT targeted for deep neural networks (DNNs) that achieves all these goals at once. Our construction enables a prover to iteratively train their model via (mini-batch) gradient descent, where the number of iterations need not be fixed in advance; at the end of each iteration, the prover generates a commitment to the trained model parameters attached with a succinct zkPoT, attesting to the correctness of the executed iterations. The proof size and verifier time are independent of the number of iterations.Our construction relies on two building blocks. First, we propose an optimized GKR-style (sumcheck-based) proof system for the gradient-descent algorithm with concretely efficient prover cost; this allows the prover to generate a proof for each iteration. We then show how to recursively compose these proofs across multiple iterations to attain succinctness. As of independent interest, we propose a generic framework for efficient recursive composition of GKR-style proofs, along with aggregatable polynomial commitments.Benchmarks indicate that Kaizen can handle the training of complex models such as VGG-11 with 10 million parameters and batch size 16. The prover runtime is 15 minutes per iteration, which is 24\\texttimes{} faster than generic recursive proofs, with prover memory overhead 27\\texttimes{} lower. The proof size is 1.63 megabytes, and the verifier runtime is only 130 milliseconds, where both are independent of the number of iterations and the size of the dataset.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670316",
    "comment": ""
  },
  {
    "title": "Multi-User Security of CCM Authenticated Encryption Mode",
    "author": "Zhang, Xiangyang and Shen, Yaobin and Wang, Lei",
    "abstract": "The CCM authenticated encryption mode has gained widespread usage and standardization. Notably, in conjunction with GCM and ChaCha20-Poly1305, CCM is recommended to be used in TLS 1.3 that underlies in https. Since TLS 1.3 is currently utilized by a large number of users, it is imperative to assess the security of these schemes in the multi-user model. Concrete multi-user security analysis for GCM and ChaCha20-Poly1305 have been scrutinized in literature. However, the formal multi-user security analysis for CCM falls behind that for GCM and ChaCha20-Poly1305. Furthermore, in the associated IETF document, the multi-user security bound for CCM is derived by naive generic reduction and falls considerably short of our expectations. In this paper, we bridge the gap by establishing a concrete multi-user security bound for CCM. Our new bound surpasses that derived from generic reduction and it indicates that CCM maintains birthday-bound security in the multi-user model as in the single-user model.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670385",
    "comment": ""
  },
  {
    "title": "HyperTheft: Thieving Model Weights from TEE-Shielded Neural Networks via Ciphertext Side Channels",
    "author": "Yuan, Yuanyuan and Liu, Zhibo and Deng, Sen and Chen, Yanzuo and Wang, Shuai and Zhang, Yinqian and Su, Zhendong",
    "abstract": "Trusted execution environments (TEEs) are widely employed to protect deep neural networks (DNNs) from untrusted hosts (e.g., hypervisors). By shielding DNNs as fully black-box via encryption, TEEs mitigate model weight leakage and its follow-up white-box attacks. However, this paper uncovers that the confidentiality of TEE-shielded DNNs can be violated due to an emerging threat towards TEEs: ciphertext side channels of TEEs create weight-dependent observations during a DNN's execution. Despite the potential of inferring DNN weights from ciphertext side channels, existing techniques are inapplicable due to their over-strong requirements and the high precision required by DNN weights. A DNN can have millions of weight elements, and even a few incorrectly recovered weight elements may make the DNN non-functional.We propose a novel viewpoint that focuses on the functionality of DNN weights, rather than each weight element's exact value. Accordingly, we design HyperTheft to directly generate weights that are functionality-equivalent to the victim DNN using ciphertext side channels. HyperTheft is established for highly practical settings; it exhibits the weakest requirement compared to prior methods. When only knowing a victim DNN's input type and task type (which are public and denote the minimal information required to use a DNN), HyperTheft can recover its weight using ciphertext side channels logged during the victim DNN's one execution. The whole procedure does not require attackers to 1) query the victim DNN, 2) have valid data that the DNN accepts, or 3) know the victim DNN's structure. Our evaluations generate more than 8K DNN weights which constantly achieve 77\\%~97\\% test accuracy in different DNN runtimes, including various versions of PyTorch and DNN executables. Our recovered weights can subsequently enable training data leakage and severe bit-flip attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690317",
    "comment": ""
  },
  {
    "title": "NeuJeans: Private Neural Network Inference with Joint Optimization of Convolution and FHE Bootstrapping",
    "author": "Ju, Jae Hyung and Park, Jaiyoung and Kim, Jongmin and Kang, Minsik and Kim, Donghwan and Cheon, Jung Hee and Ahn, Jung Ho",
    "abstract": "Fully homomorphic encryption (FHE) is a promising cryptographic primitive for realizing private neural network inference (PI) services by allowing a client to fully offload the inference task to a cloud server while keeping the client data oblivious to the server. This work proposes NeuJeans, an FHE-based solution for the PI of deep convolutional neural networks (CNNs). NeuJeans tackles the critical problem of the enormous computational cost for the FHE evaluation of CNNs. We introduce a novel encoding method called Coefficients-in-Slot (CinS) encoding, which enables multiple convolutions in one HE multiplication without costly slot permutations. We further observe that CinS encoding is obtained by conducting the first several steps of the Discrete Fourier Transform (DFT) on a ciphertext in conventional Slot encoding. This property enables us to save the conversion between CinS and Slot encodings as bootstrapping a ciphertext starts with DFT. Exploiting this, we devise optimized execution flows for various two-dimensional convolution (conv2d) operations and apply them to end-to-end CNN implementations. NeuJeans accelerates the performance of conv2d-activation sequences by up to 5.68\\texttimes{} compared to state-of-the-art FHE-based PI work and performs the PI of a CNN at the scale of ImageNet within a mere few seconds.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690375",
    "comment": ""
  },
  {
    "title": "Ents: An Efficient Three-party Training Framework for Decision Trees by Communication Optimization",
    "author": "Lin, Guopeng and Han, Weili and Ruan, Wenqiang and Zhou, Ruisheng and Song, Lushan and Li, Bingshuai and Shao, Yunfeng",
    "abstract": "Multi-party training frameworks for decision trees based on secure multi-party computation enable multiple parties to train high-performance models on distributed private data with privacy preservation. The training process essentially involves frequent dataset splitting according to the splitting criterion (e.g. Gini impurity). However, existing multi-party training frameworks for decision trees demonstrate communication inefficiency due to the following issues: (1) They suffer from huge communication overhead in securely splitting a dataset with continuous attributes. (2) They suffer from huge communication overhead due to performing almost all the computations on a large ring to accommodate the secure computations for the splitting criterion.In this paper, we are motivated to present an efficient three-party training framework, namely Ents, for decision trees by communication optimization. For the first issue, we present a series of training protocols based on the secure radix sort protocols[17] to efficiently and securely split a dataset with continuous attributes. For the second issue, we propose an efficient share conversion protocol to convert shares between a small ring and a large ring to reduce the communication overhead incurred by performing almost all the computations on a large ring. Experimental results from eight widely used datasets show that Ents outperforms state-of-the-art frameworks by 5.5x ~ 9.3\\texttimes{} in communication sizes and 3.9x ~ 5.3\\texttimes{} in communication rounds. In terms of training time, Ents yields an improvement of 3.5x ~ 6.7\\texttimes{}. To demonstrate its practicality, Ents requires less than three hours to securely train a decision tree on a widely used real-world dataset (Skin Segmentation) with more than 245,000 samples in the WAN setting.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670274",
    "comment": ""
  },
  {
    "title": "Fast and Accurate Homomorphic Softmax Evaluation",
    "author": "Cho, Wonhee and Hanrot, Guillaume and Kim, Taeseong and Park, Minje and Stehl\\'{e}, Damien",
    "abstract": "Homomorphic encryption is one of the main solutions for building secure and privacy-preserving solutions for Machine Learning as a Service, a major challenge in a society where AI becomes more and more pervasive. This motivates the development of homomorphic algorithms for the main building blocks of AI, typically for the components of the various types of neural networks architectures.Among those components, we focus on the Softmax function, defined by Softmax(x ) = (exp(xi) / ∑j=1n exp(xj))1 ≤ i ≤ n. This function is deemed to be one of the most difficult to evaluate homomorphically, because of its multivariate nature and of the very large range of values for exp(xi). The available homomorphic algorithms remain restricted, especially in large dimensions, while important applications such as Large Language Models (LLM) require computing Softmax over large dimensional vectors. Our algorithm has strong scalability properties in terms of range and dimension while maintaining very good numerical accuracy. In terms of multiplicative depth of the computation (a suitable measure of cost for homomorphic algorithms), our algorithm achieves O(log n) complexity for a fixed range of inputs, where n is the Softmax dimension.Our algorithm is especially adapted to the situation where we must compute many Softmax at the same time, for instance, in the LLM situation. In that case, assuming that all Softmax calls are packed into m ciphtertexts, the asymptotic amortized multiplicative depth cost per ciphertext is, again over a fixed range, O(1 + m/N) for N the homomorphic ring degree (typically N=216, so that we have N ≫ m in practice).The main ingredient of our algorithms is a normalize-and-square strategy, which manages to interlace the (numerically unstable) exponential computation over a large range and (very expensive) normalization, decomposing both in stabler and cheaper smaller steps.We have implemented our algorithms using the HEaaN implementation of the CKKS HE system. Comparing ourselves to the state of the art, our experiments show, in practice, a gain of a factor 2.5 to 8 compared to state of the art solutions.These experiments demonstrate good accuracy (around 16-bit precision in the worst case, around 20 on average) and support the linear behavior in the dimension. The many-ciphertexts version allows us to compute 8192 Softmax of dimension 256 in parallel in 486s (single-thread CPU), corresponding to an amortized 0.06s per Softmax call. All Softmax calls of the 32-layers LLaMa large language model (7B version) with context length 128 on an RTX-6000 GPU take around 1.5 minutes, and the final Softmax call in dimension 32768 for token generation takes less than 3 seconds. This suggests that near-practicality may be accessible with dedicated hardware.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670369",
    "comment": ""
  },
  {
    "title": "zkLLM: Zero Knowledge Proofs for Large Language Models",
    "author": "Sun, Haochen and Li, Jason and Zhang, Hongyang",
    "abstract": "The recent surge in artificial intelligence (AI), characterized by the prominence of large language models (LLMs), has ushered in fundamental transformations across the globe. However, alongside these advancements, concerns surrounding the legitimacy of LLMs have grown, posing legal challenges to their extensive applications. Compounding these concerns, the parameters of LLMs are often treated as intellectual property, restricting direct investigations.In this study, we address a fundamental challenge within the realm of AI legislation: the need to establish the authenticity of outputs generated by LLMs. To tackle this issue, we present zkLLM, which stands as the inaugural specialized zero-knowledge proof tailored for LLMs to the best of our knowledge. Addressing the persistent challenge of non-arithmetic operations in deep learning, we introduce tlookup, a parallelized lookup argument designed for non-arithmetic tensor operations in deep learning, offering a solution with no asymptotic overhead. Furthermore, leveraging the foundation of tlookup, we introduce zkAttn, a specialized zero-knowledge proof crafted for the attention mechanism, carefully balancing considerations of running time, memory usage, and accuracy.Empowered by our fully parallelized CUDA implementation, zkLLM emerges as a significant stride towards achieving efficient zero-knowledge verifiable computations over LLMs. Remarkably, for LLMs boasting 13 billion parameters, our approach enables the generation of a correctness proof for the entire inference process in under 15 minutes. The resulting proof, compactly sized at less than 200 kB, is designed to uphold the privacy of the model parameters, ensuring no inadvertent information leakage.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670334",
    "comment": ""
  },
  {
    "title": "AITIA: Efficient Secure Computation of Bivariate Causal Discovery",
    "author": "Nguyen, Truong Son and Wang, Lun and Kornaropoulos, Evgenios M. and Trieu, Ni",
    "abstract": "Researchers across various fields seek to understand causal relationships but often find controlled experiments impractical. To address this, statistical tools for causal discovery from naturally observed data have become crucial. Non-linear regression models, such as Gaussian process regression, are commonly used in causal inference but have limitations due to high costs when adapted for secure computation. Support vector regression (SVR) offers an alternative but remains costly in an Multi-party computation context due to conditional branches and support vector updates.In this paper, we propose Aitia, the first two-party secure computation protocol for bivariate causal discovery. The protocol is based on optimized multi-party computation design choices and is secure in the semi-honest setting. At the core of our approach is BSGD-SVR, a new non-linear regression algorithm designed for MPC applications, achieving both high accuracy and low computation and communication costs. Specifically, we reduce the training complexity of the non-linear regression model from approximately from O(N3) to O(N2) where N is the number of training samples. We implement Aitia using CrypTen and assess its performance across various datasets. Empirical evaluations show a significant speedup of 3.6x to 340x compared to the baseline approach.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670337",
    "comment": ""
  },
  {
    "title": "Fisher Information guided Purification against Backdoor Attacks",
    "author": "Karim, Nazmul and Al Arafat, Abdullah and Rakin, Adnan Siraj and Guo, Zhishan and Rahnavard, Nazanin",
    "abstract": "Studies on backdoor attacks in recent years suggest that an adversary can compromise the integrity of a deep neural network (DNN) by manipulating a small set of training samples. Our analysis shows that such manipulation can make the backdoor model converge to a bad local minima, i.e., sharper minima as compared to a benign model. Intuitively, the backdoor can be purified by re-optimizing the model to smoother minima. However, a na\\\"{\\i}ve adoption of any optimization targeting smoother minima can lead to sub-optimal purification techniques hampering the clean test accuracy. Hence, to effectively obtain such re-optimization, inspired by our novel perspective establishing the connection between backdoor removal and loss smoothness, we propose <u>F</u>isher <u>I</u>nformation guided <u>P</u>urification (FIP), a novel backdoor purification framework. Proposed FIP consists of a couple of novel regularizers that aid the model in suppressing the backdoor effects and retaining the acquired knowledge of clean data distribution throughout the backdoor removal procedure through exploiting the knowledge of Fisher Information Matrix (FIM). In addition, we introduce an efficient variant of FIP, dubbed as Fast FIP, which reduces the number of tunable parameters significantly and obtains an impressive runtime gain of almost 5\\texttimes{}. Extensive experiments show that the proposed method achieves state-of-the-art (SOTA) performance on a wide range of backdoor defense benchmarks: 5 different tasks---Image Recognition, Object Detection, Video Action Recognition, 3D point Cloud, Language Generation ; 11 different datasets including ImageNet, PASCAL VOC, UCF101 ; diverse model architectures spanning both CNN and vision transformer; 14 different backdoor attacks, e.g., Dynamic, WaNet, LIRA, ISSBA, etc. Our code is available in this https://github.com/nazmul-karim170/FIP-Fisher-Backdoor-Removal GitHub Repository.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690250",
    "comment": ""
  },
  {
    "title": "BadMerging: Backdoor Attacks Against Model Merging",
    "author": "Zhang, Jinghuai and Chi, Jianfeng and Li, Zheng and Cai, Kunlin and Zhang, Yang and Tian, Yuan",
    "abstract": "Fine-tuning pre-trained models for downstream tasks has led to a proliferation of open-sourced task-specific models. Recently, Model Merging (MM) has emerged as an effective approach to facilitate knowledge transfer among these independently fine-tuned models. MM directly combines multiple fine-tuned task-specific models into a merged model without additional training, and the resulting model shows enhanced capabilities in multiple tasks. Although MM provides great utility, it may come with security risks because an adversary can exploit MM to affect multiple downstream tasks. However, the security risks of MM have barely been studied. In this paper, we first find that MM, as a new learning paradigm, introduces unique challenges for existing backdoor attacks due to the merging process. To address these challenges, we introduce BadMerging, the first backdoor attack specifically designed for MM. Notably, BadMerging allows an adversary to compromise the entire merged model by contributing as few as one backdoored task-specific model. BadMerging comprises a two-stage attack mechanism and a novel feature-interpolation-based loss to enhance the robustness of embedded backdoors against the changes of different merging parameters. Considering that a merged model may incorporate tasks from different domains, BadMerging can jointly compromise the tasks provided by the adversary (on-task attack) and other contributors (off-task attack) and solve the corresponding unique challenges with novel attack designs. Extensive experiments show that BadMerging achieves remarkable attacks against various MM algorithms. Our ablation study demonstrates that the proposed attack designs can progressively contribute to the attack performance. Finally, we show that prior defense mechanisms fail to defend against our attacks, highlighting the need for more advanced defense. Our code is available at: https://github.com/jzhang538/BadMerging.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690284",
    "comment": ""
  },
  {
    "title": "Watch Out! Simple Horizontal Class Backdoor Can Trivially Evade Defense",
    "author": "Ma, Hua and Wang, Shang and Gao, Yansong and Zhang, Zhi and Qiu, Huming and Xue, Minhui and Abuadbba, Alsharif and Fu, Anmin and Nepal, Surya and Abbott, Derek",
    "abstract": "All current backdoor attacks on deep learning (DL) models fall under the category of a vertical class backdoor (VCB).In VCB attacks, any sample from a class activates the implanted backdoor when the secret trigger is present, regardless of whether it is a sub-type source-class-agnostic backdoor or a source-class-specific backdoor. For example, a trigger of sunglasses could mislead a facial recognition model when either an arbitrary (source-class-agnostic) or a specific (source-class-specific) person wears sunglasses. Existing defense strategiesoverwhelmingly focus on countering VCB attacks, especially those that are source-class-agnostic. This narrow focus neglects the potential threat of other simpler yet general backdoor types, leading to false security implications. It is, therefore, crucial to discover and elucidate unknown backdoor types, particularly those that can be easily implemented, as a mandatory step before developing countermeasures.This study introduces a new, simple, and general type of backdoor attack, the horizontal class backdoor (HCB), that trivially breaches the class dependence characteristic of the VCB, bringing a fresh perspective to the field. An HCB is activated when the trigger is presented together with an innocuous feature,regardless of class. For example, under an HCB, the trigger of sunglasses could mislead a facial recognition model in the presence of the innocuous feature smiling. Smiling is innocuous because it is irrelevant to the main task of facial recognition. The key is that these innocuous features (such as rain, fog, or snow in autonomous driving or facial expressions like smiling or sadness in facial recognition) are horizontally sharedamong classes but are only exhibited by partial samples per class. Extensive experiments on attacking performance across various tasks, including MNIST, facial recognition, traffic sign recognition, object detection, and medical diagnosis, confirm the high efficiency and effectiveness of the HCB. We rigorously evaluated the evasiveness of the HCB against a series of eleven representative countermeasures, including Fine-Pruning (RAID 18'), STRIP (ACSAC 19'), Neural Cleanse (Oakland 19'), ABS (CCS 19'), Februus (ACSAC 20'), NAD (ICLR 21'), MNTD (Oakland 21'), SCAn (USENIX SEC 21'), MOTH (Oakland 22'), Beatrix (NDSS 23'), and MM-BD (Oakland 24'). None of these countermeasures prove robustness, even when employing a simplistic trigger, such as a small and static white-square patch.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670361",
    "comment": ""
  },
  {
    "title": "Mithridates: Auditing and Boosting Backdoor Resistance of Machine Learning Pipelines",
    "author": "Bagdasarian, Eugene and Shmatikov, Vitaly",
    "abstract": "Machine learning (ML) models trained on data from potentially untrusted sources are vulnerable to poisoning. A small, maliciously crafted subset of the training inputs can cause the model to learn a \"backdoor\" task (e.g., misclassify inputs with a certain feature) in addition to its main task. Recent research proposed many hypothetical backdoor attacks whose efficacy depends on the configuration and training hyperparameters of the target model. At the same time, state-of-the-art defenses require massive changes to the existing ML pipelines and protect only against some attacks.Given the variety of potential backdoor attacks, ML engineers who are not security experts have no way to measure how vulnerable their current training pipelines are, nor do they have a practical way to compare training configurations so as to pick the more resistant ones. Deploying a defense may not be a realistic option, either. It requires evaluating and choosing from among dozens of research papers, completely re-engineering the pipeline as required by the chosen defense, and then repeating the process if the defense disrupts normal model training (while providing theoretical protection against an unknown subset of hypothetical threats).In this paper, we aim to provide ML engineers with pragmatic tools to audit the backdoor resistance of their training pipelines and to compare different training configurations, to help choose the one that best balances accuracy and security.First, we propose a universal, attack-agnostic resistance metric based on the minimum number of training inputs that must be compromised before the model learns any backdoor.Second, we design, implement, and evaluate Mithridates, a multi-stage approach that integrates backdoor resistance into the training-configuration search. ML developers already rely on hyperparameter search to find configurations that maximize the model's accuracy. Mithridates extends this tool to also order configurations based on their backdoor resistance. We demonstrate that Mithridates discovers configurations whose resistance to multiple types of backdoor attacks increases by 3-5x with only a slight impact on accuracy. We also discuss extensions to AutoML and federated learning.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690337",
    "comment": ""
  },
  {
    "title": "DeepCache: Revisiting Cache Side-Channel Attacks in Deep Neural Networks Executables",
    "author": "Liu, Zhibo and Yuan, Yuanyuan and Chen, Yanzuo and Hu, Sihang and Li, Tianxiang and Wang, Shuai",
    "abstract": "Deep neural networks (DNN) are increasingly deployed in heterogeneous hardware, including high-performance devices like GPUs and low-power devices like mobile/IoT CPUs, FPGAs, and accelerators. In order to unlock the full performance potential of various hardware, deep learning (DL) compilers automatically optimize DNN inference computations and compile DNN models into DNN executables for efficient computations across hardware backends. As valuable intellectual properties, DNN architectures are one primary attack target. Since previous works already demonstrate the abuse of cache side channels to steal DNN architectures from DL frameworks (e.g., PyTorch and TensorFlow), we first study using those known side-channel attacks against DNN executables. We find that attacking DNN executables presents unique challenges, and existing works can hardly apply. Particularly, DNN executables exhibit a standalone paradigm that largely reduces cache side channel attack surfaces. Meanwhile, cache side channels capture only limited behaviors of the whole DNN execution while facing daunting technical challenges (e.g., noise and low time resolution). However, we unveil a unique attack vector in DNN executables, such that the cache-aware optimizations, which are extensively employed by contemporary DL compilers to harvest the full potentials of hardware, would result in distinguishable DNN operator cache access patterns, making model architecture recovery possible. We propose DeepCache, an end-to-end side channel attack framework, to infer DNN model architectures from DNN executables. DeepCache  leverages cache side channels as the attacking primitives and combines contrastive learning and anomaly detection to enable precise inference. Our evaluation using the standard Prime+Probe shows that DeepCache  yields a high accuracy in exploiting complex DNN executables under both the basic L1 cache attack and the more practical but challenging last level cache (LLC) attack settings.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690241",
    "comment": ""
  },
  {
    "title": "Rules Refine the Riddle: Global Explanation for Deep Learning-Based Anomaly Detection in Security Applications",
    "author": "Han, Dongqi and Wang, Zhiliang and Feng, Ruitao and Jin, Minghui and Chen, Wenqi and Wang, Kai and Wang, Su and Yang, Jiahai and Shi, Xingang and Yin, Xia and Liu, Yang",
    "abstract": "Deep learning (DL) based anomaly detection has shown great promise in the field of security due to its remarkable performance in various tasks. However, the issue of poor interpretability in DL models has significantly impeded their deployment in practical security applications. Despite the progress made in existing studies on DL explanations, the majority of them focus on providing local explanations for individual samples, neglecting the global understanding of the model knowledge. Furthermore, most explanations for supervised models fail to apply to anomaly detection due to their different learning mechanisms.In this work, we address the gap in the existing research by proposing GEAD, a novel global explanation for DL-based anomaly detection, to extract high-fidelity rules from DL models. We apply GEAD to two security applications, network intrusion detection and system log anomaly detection, and demonstrate the efficacy with three usages: comparing model knowledge with expert knowledge, identifying knowledge discrepancies between models, and combining model and expert knowledge. We provide several case studies to showcase how GEAD can significantly enhance existing anomaly detection systems. Moreover, we provide a real-world deployment in a SCADA system to showcase the potential in practice. Some important insights are drawn to help the community understand and improve anomaly detection systems in security.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670375",
    "comment": ""
  },
  {
    "title": "Boosting Practical Control-Flow Integrity with Complete Field Sensitivity and Origin Awareness",
    "author": "Xiang, Hao and Cheng, Zehui and Li, Jinku and Ma, Jianfeng and Lu, Kangjie",
    "abstract": "Control-flow integrity (CFI) is a strong and efficient defense mechanism against memory-corruption attacks. The practical versions of CFI, which have been integrated into compilers, employ static analysis to collect all possibly valid target functions of indirect calls. They are however less effective because the static analysis is imprecise. While more precise CFI techniques have been proposed, such as dynamic CFI, they are not yet practical due to issues on performance, compatibility, and deployability. We believe that to be practical, CFI based on static analysis is still the promising direction. However, these years have not seen much progress on the effectiveness of such practical CFI.This paper aims to boost the effectiveness of practical CFI by dramatically optimizing the target-function sets (aka equivalence class or EC) of indirect calls. We first identify two fundamental limitations that lead to the imprecision of static indirect-call analysis: incomplete field sensitivity due to variable field indexes and the unawareness of the origins of point-to targets. We then propose two novel analysis techniques, complete field sensitivity and origin awareness, which handle variable field indexes and distinguish target origins. The techniques dramatically reduce the size of target functions. To enforce the origin awareness, we further employ Intel Memory Protection Keys to safely store the origin information. We implement our techniques as a system called ECCut. The evaluation results show that compared to the mainline LLVM CFI, ECCut achieves a substantial reduction of 94.8\\% and 90.3\\% in the average and the largest EC sizes. While compared to the state-of-the-art origin-aware CFI (i.e., OS-CFI), ECCut reduces the average and the largest EC sizes by 90.2\\% and 89.3\\% respectively. Additionally, ECCut introduces an acceptable performance overhead (7.2\\% on average) observed across a comprehensive range of C/C++ benchmark tests in SPEC CPU2006, SPEC CPU2017, and six real-world applications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670308",
    "comment": ""
  },
  {
    "title": "PowerPeeler: A Precise and General Dynamic Deobfuscation Method for PowerShell Scripts",
    "author": "Li, Ruijie and Zhang, Chenyang and Chai, Huajun and Ying, Lingyun and Duan, Haixin and Tao, Jun",
    "abstract": "PowerShell is a powerful and versatile task automation tool. Unfortunately, it is also widely abused by cyber attackers. To bypass malware detection and hinder threat analysis, attackers often employ diverse techniques to obfuscate malicious PowerShell scripts. Existing deobfuscation tools suffer from the limitation of static analysis, which fails to simulate the real deobfuscation process accurately. Accurate, complete, and robust PowerShell script deobfuscation is still a challenging problem.In this paper, we propose PowerPeeler. To the best of our knowledge, it is the first dynamic PowerShell script deobfuscation approach at the instruction level. It utilizes expression-related Abstract Syntax Tree (AST) nodes to identify potential obfuscated script pieces. Then, PowerPeeler correlates the AST nodes with their corresponding instructions and monitors the script's entire execution process. Subsequently, PowerPeeler dynamically tracks the execution of these instructions and records their execution results. Finally, PowerPeeler stringifies these results to replace the corresponding obfuscated script pieces and reconstruct the deobfuscated script.To evaluate the effectiveness of PowerPeeler, we collect 1,736,669 real-world malicious PowerShell samples and distill two high-quality datasets with diversity obfuscation methods: D-Script with 4,264 obfuscated script files and D-Cmdline with 381 obfuscated samples using PowerShell command-line interface. We compare PowerPeeler with five state-of-the-art deobfuscation tools and GPT-4. The evaluation results demonstrate that PowerPeeler can effectively handle all well-known obfuscation methods. Additionally, the deobfuscation correctness rate of PowerPeeler reaches 95\\%, significantly surpassing that of other tools. PowerPeeler not only recovers the highest amount of sensitive data (e.g., IPs and URLs) but also maintains a semantic consistency over 97\\%, which is also the best. Moreover, PowerPeeler effectively obtains the largest quantity of valid deobfuscated results within a limited time frame (i.e., two minutes). Furthermore, PowerPeeler is extendable and can be used as a helpful tool for other cyber security solutions, such as malware analysis and threat intelligence generation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670310",
    "comment": ""
  },
  {
    "title": "ReSym: Harnessing LLMs to Recover Variable and Data Structure Symbols from Stripped Binaries",
    "author": "Xie, Danning and Zhang, Zhuo and Jiang, Nan and Xu, Xiangzhe and Tan, Lin and Zhang, Xiangyu",
    "abstract": "Decompilation aims to recover a binary executable to the source code form and hence has a wide range of applications in cyber security, such as malware analysis and legacy code hardening. A prominent challenge is to recover variable symbols, including both primitive and complex types such as user-defined data structures, along with their symbol information such as names and types. Existing efforts focus on solving parts of the problem, e.g., recovering only types (without names) or only local variables (without user-defined structures). In this paper, we propose ReSym, a novel hybrid technique that combines Large Language Models (LLMs) and program analysis to recover both names and types for local variables and user-defined data structures. Our method encompasses fine-tuning two LLMs to handle local variables and structures, respectively. To overcome the token limitations inherent in current LLMs, we devise a novel Prolog-based algorithm to aggregate and cross-check results from multiple LLM queries, suppressing uncertainty and hallucinations. Our experiments show that ReSym is effective in recovering variable information and user-defined data structures, substantially outperforming the state-of-the-art methods.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670340",
    "comment": ""
  },
  {
    "title": "Manipulative Interference Attacks",
    "author": "Mergendahl, Samuel and Fickas, Stephen and Norris, Boyana and Skowyra, Richard",
    "abstract": "A μ-kernel is an operating system (OS) paradigm that facilitates a strong cybersecurity posture for embedded systems. Unlike a monolithic OS such as Linux, a μ-kernel reduces overall system privilege by deploying most OS functionality within isolated, userspace protection domains. Moreover, a μ-kernel ensures confidentiality and integrity between protection domains (i.e., spatial isolation), and offers timing predictability for real-time tasks in mixed-criticality systems (i.e., temporal isolation). One popular μ-kernel is seL4 which offers extensive formal guarantees of implementation correctness and flexible temporal budgeting mechanisms.However, we show that an untrusted protection domain on a μ-kernel can abuse service requests to other protection domains in order to corrode system availability. We generalize this denial-of-service (DoS) attack strategy as Manipulative Interference Attacks (MIAs) and introduce techniques to efficiently identify instances of MIAs within a configured system. Specifically, we propose a novel hybrid approach that first leverages static analysis to identify software components with influenceable execution times, and second, uses an automatically generated model-based analysis to determine which compromised protection domains can manipulate the influenceable components and trigger MIAs. We investigate the risk of MIAs in several representative system examples including the seL4 Microkit, as well as a case study of seL4 software artifacts from the DARPA Cyber Assured Systems Engineering (CASE) program. In particular, we demonstrate that our analysis is efficient enough to discover practical instances of MIAs in real-world systems.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690246",
    "comment": ""
  },
  {
    "title": "Isolate and Detect the Untrusted Driver with a Virtual Box",
    "author": "Li, YongGang and Jiang, ShunRong and Bao, Yu and Chen, PengPeng and Zhou, Yong and Chung, Yeh-Ching",
    "abstract": "In kernel, the driver code is much more than the core code, thus having a larger attack surface. Especially for the untrusted drivers without source code, they may come from the hot-plug hardware or the user without security knowledge. Traditional isolation methods require analyzing source code to set checkpoints in the driver for control flow protection, which are not available for closed-source drivers. Evenworse, the existing isolation methods can only prevent the hijacked control flows entering/existing drivers, while they cannot discover the illegal control flows inside drivers. Although the kernel address space location randomization (KASLR) can defend against control flow hijacking, it can be bypassed by code probes. In response to these issues, this paper proposes a novel method Dbox to isolate and detect the untrusted drivers whose source code is unavailable. Dbox creates a light hypervisor to monitor and analyze the untrusted driver's behavior without relying on source code. It isolates the untrusted driver in a private space and dynamically changes its virtual space through a sliding space mechanism. Under the protection of Dbox, all control flows jumping to/from untrusted drivers can be detected. Experiments and analysis show that Dbox has good protection against code probes, kernel rootkits and code reuse attacks, and the overhead introduced to the operating system is less than 3.6\\% in general scenarios.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670269",
    "comment": ""
  },
  {
    "title": "Gramine-TDX: A Lightweight OS Kernel for Confidential VMs",
    "author": "Kuvaiskii, Dmitrii and Stavrakakis, Dimitrios and Qin, Kailun and Xing, Cedric and Bhatotia, Pramod and Vij, Mona",
    "abstract": "While Confidential Virtual Machines (CVMs) have emerged as a prominent way for hardware-assisted confidential computing, their primary usage is not suitable for small, specialized, security-critical workloads, i.e., legacy VMs with their conventional OS distributions result in a large trusted computing base.In this paper, we present the Gramine-TDX OS kernel to execute slim, single-purpose, security-first, unmodified Linux workloads with a minimal attack surface. In comparison to a typical Linux kernel, Gramine-TDX's codebase is ~ 50\\texttimes{} less in binary size and has a significantly smaller attack surface, which makes it a perfect match for emerging cloud-native confidential-computing workloads. Our evaluation on 11 workloads indicates that Gramine-TDX has 1-25\\% average overhead for CPU- and memory-intensive applications. Performance on network- and FS-intensive applications can drop to 6\\% of the native application's, as Gramine-TDX prioritizes security over optimizations in virtual hardware communication. We build our prototype using Intel®Trust Domain Extensions (TDX).",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690323",
    "comment": ""
  },
  {
    "title": "ArcEDB: An Arbitrary-Precision Encrypted Database via (Amortized) Modular Homomorphic Encryption",
    "author": "Zhang, Zhou and Bian, Song and Zhao, Zian and Mao, Ran and Zhou, Haoyi and Hua, Jiafeng and Jin, Yier and Guan, Zhenyu",
    "abstract": "Fully homomorphic encryption (FHE) based database outsourcing is drawing growing research interests. At its current state, there exist two primary obstacles against FHE-based encrypted databases (EDBs): i) low data precision, and ii) high computational latency. To tackle the precision-performance dilemma, we introduce ArcEDB, a novel FHE-based SQL evaluation infrastructure that simultaneously achieves high data precision and fast query evaluation. Based on a set of new plaintext encoding schemes, we are able to execute arbitrary-precision ciphertext-to-ciphertext homomorphic comparison orders of magnitude faster than existing methods. Meanwhile, we propose efficient conversion algorithms between the encoding schemes to support highly composite SQL statements, including advanced filter-aggregation and multi-column synchronized sorting. We perform comprehensive experiments to study the performance characteristics of ArcEDB. In particular, we show that ArcEDB can be up to 57\\texttimes{} faster in homomorphic filtering and up to 20\\texttimes{} faster over end-to-end SQL queries when compared to the state-of-the-art FHE-based EDB solutions. Using ArcEDB, a SQL query over a 10K-row time-series EDB with 64-bit timestamps only runs for under one minute.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670384",
    "comment": ""
  },
  {
    "title": "ISABELLA: Improving Structures of Attribute-Based Encryption Leveraging Linear Algebra",
    "author": "Riepel, Doreen and Venema, Marloes and Verma, Tanya",
    "abstract": "Attribute-based encryption (ABE) is a powerful primitive that has found applications in important real-world settings requiring access control. Compared to traditional public-key encryption, ABE has established itself as a considerably more complex primitive that is additionally less efficient to implement. It is therefore paramount that the we can simplify the design of ABE schemes that are efficient, provide strong security guarantees, minimize the complexity in their descriptions and support all practical features that are desirable for common real-world settings. One of such practical features that is currently still difficult to achieve is multi-authority support. Motivated by NIST's ongoing standardization efforts around multi-authority schemes, we put a specific focus on simplifying the support of multiple authorities in the design of schemes. Abstract: Code to separate paragraphs To this end, we present ISABELLA, a framework for constructing pairing-based ABE with advanced functionalities under strong security guarantees. At a high level, our approach builds on various works that systematically and generically construct ABE schemes by reducing the effort of proving security to a simpler yet powerful ''core'' called pair encodings. To support the amount of adaptivity required by multi-authority ABE, we devise a new approach to designing schemes from pair encodings, while still being able to benefit from the advantages that pair encodings provide. As a direct result of our framework, we obtain various improvements for existing (multi-authority) schemes as well as new schemes.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690371",
    "comment": ""
  },
  {
    "title": "Conditional Encryption with Applications to Secure Personalized Password Typo Correction",
    "author": "Ameri, Mohammad Hassan and Blocki, Jeremiah",
    "abstract": "We introduce the notion of a conditional encryption scheme as an extension of public key encryption. In addition to the standard public key algorithms (KG, Enc, Dec) for key generation, encryption and decryption, a conditional encryption scheme for a binary predicate P adds a new conditional encryption algorithm CEnc. The conditional encryption algorithm c=CEncpk (c1,m2,m3) takes as input the public encryption key pk, a ciphertext c1 = Encpk (m1) for an unknown message m1, a control message m2 and a payload message m3 and outputs a conditional ciphertext c. Intuitively, if P(m1,m2)=1 then the conditional ciphertext c should decrypt to the payload message m3. On the other hand if P(m1,m2) = 0 then the ciphertext should not leak any information about the control message m2 or the payload message m3 even if the attacker already has the secret decryption key sk. We formalize the notion of conditional encryption secrecy and provide concretely efficient constructions for a set of predicates relevant to password typo correction. Our practical constructions utilize the Paillier partially homomorphic encryption scheme as well as Shamir Secret Sharing. We prove that our constructions are secure and demonstrate how to use conditional encryption to improve the security of personalized password typo correction systems such as TypTop. We implement a C++ library for our practically efficient conditional encryption schemes and evaluate the performance empirically. We also update the implementation of TypTop to utilize conditional encryption for enhanced security guarantees and evaluate the performance of the updated implementation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690374",
    "comment": ""
  },
  {
    "title": "Practical Non-interactive Encrypted Conjunctive Search with Leakage Suppression",
    "author": "Wang, Yunling and Sun, Shi-Feng and Wang, Jianfeng and Chen, Xiaofeng and Liu, Joseph K. and Gu, Dawu",
    "abstract": "Encrypted conjunctive search enables server to perform efficient conjunctive query over encrypted data while guaranteeing data and query privacy. The well-known Oblivious Cross-Tags (OXT) protocol (by Cash et al. in CRYPTO 2013) is the first to realize efficient conjunctive search with some well-defined leakage, such as the keyword pair result pattern (KPRP) leakage and the cross-query intersection result pattern (IP) leakage. To mitigate the potential threats brought by the leakage, much effort has been made to reduce the information leaked by OXT. However, it is still open to achieve encrypted conjunctive search without revealing both KPRP and IP, while preserving high-efficiency.Encrypted multi-map is a crucial primitive for designing searchable encryption with optimal search complexity. In this paper, we present the first non-interactive encrypted conjunctive multi-map, Doris, without KPRP and IP leakage. To this end, we design a novel data structure for performing conjunctive query, that enables the client to generate \"encrypted\" label/value pairs without interaction. Then, we introduce a new cryptographic primitive dubbed Symmetric Subset Predicate Encryption, which supports checking if one set is entirely contained within another without leaking any information than the subset predicate.Finally, we implement Doris and provide a detailed comparison with the most related works HXT (by Lai et al. in CCS 2018) and ConjFilter (by Patel et al. in ASIACRYPT 2021). The experimental results demonstrate that Doris can achieve a speedup of 6\\texttimes{} and 1.07\\texttimes{} compared to HXT and ConjFilter in search latency respectively for 2 labels querying, while increasing to 42\\texttimes{} and 1.1\\texttimes{} respectively for 10 labels, even with a stronger security guarantee.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670355",
    "comment": ""
  },
  {
    "title": "Securely Training Decision Trees Efficiently",
    "author": "Bhardwaj, Divyanshu and Saravanan, Sandhya and Chandran, Nishanth and Gupta, Divya",
    "abstract": "Decision trees are an important class of supervised learning algorithms. When multiple entities contribute data to train a decision tree (e.g. for fraud detection in the financial sector), data privacy concerns necessitate the use of a privacy-enhancing technology such as secure multi-party computation (MPC) in order to secure the underlying training data. Prior state-of-the-art (Hamada et al.[18]) construct an MPC protocol for decision tree training with a communication of O(hmN log N), when building a decision tree of height h for a training dataset of N samples, each having m attributes.In this work, we significantly reduce the communication complexity of secure decision tree training. We construct a protocol with communication complexity O(mN log N + hmN + hN log N), thereby achieving an improvement of ∼ min(h, m, log N) over [18]. At the core of our technique is an improved protocol to regroup sorted private elements further into additional groups (according to a flag vector) while maintaining their relative ordering. We implement our protocol in the MP-SPDZ framework[1, 22] and show that it requires 10x lesser communication and is 9x faster than [18].",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670268",
    "comment": ""
  },
  {
    "title": "FABESA: Fast (and Anonymous) Attribute-Based Encryption under Standard Assumption",
    "author": "Meng, Long and Chen, Liqun and Tian, Yangguang and Manulis, Mark",
    "abstract": "Attribute-Based Encryption (ABE) provides fine-grained access control to encrypted data and finds applications in various domains. The practicality of ABE schemes hinges on the balance between security and efficiency. The state-of-the-art adaptive secure ABE scheme, proven to be adaptively secure under standard assumptions (FAME, CCS'17), is less efficient compared to the fastest one (FABEO, CCS'22) which is only proven secure under the Generic Group Model (GGM). These traditional ABE schemes focus solely on message privacy. To address scenarios where attribute value information is also sensitive, Anonymous ABE (A2BE) ensures the privacy of both the message and attributes. However, most A2BE schemes suffer from intricate designs with low efficiency, and the security of the fastest key-policy A2BE (proposed in FEASE, USENIX'24) relies on the GGM.In this paper, we propose novel fast key-policy and ciphertext-policy ABE schemes that (1) support both AND and OR gates for access policies, (2) have no restriction on the size and type of policies or attributes, (3) achieve adaptive security under the standard DLIN assumption, and (4) only need 4 pairings for decryption. As our ABE constructions automatically provide ciphertext anonymity, we easily transform our ABE schemes to A2BE schemes while maintaining the same features and high-level efficiency.The implementation results show that all our schemes achieve the best efficiency comparing to other schemes with adaptive security proven under standard assumptions. Specifically, our ABE schemes perform better than FAME and are close to FABEO. Our key-policy A2BE scheme performs close to the one in FEASE and our ciphertext-policy A2BE outperforms the state-of-the-art (Cui et al., ProvSec'16).",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670321",
    "comment": ""
  },
  {
    "title": "Pulsar: Secure Steganography for Diffusion Models",
    "author": "Jois, Tushar M. and Beck, Gabrielle and Kaptchuk, Gabriel",
    "abstract": "Widespread efforts to subvert access to strong cryptography has renewed interest in steganography, the practice of embedding sensitive messages in mundane cover messages. Recent efforts at provably secure steganography have focused on text-based generative models and cannot support other types of models, such as diffusion models, which are used for high-quality image synthesis. In this work, we study securely embedding steganographic messages into the output of image diffusion models. We identify that the use of variance noise during image generation provides a suitable steganographic channel. We develop our construction, Pulsar, by building optimizations to make this channel practical for communication. Our implementation of Pulsar is capable of embedding ≈320--613 bytes (on average) into a single image without altering the distribution of the generated image, all in < 3 seconds of online time on a laptop. In addition, we discuss how the results of Pulsar can inform future research into diffusion models. Pulsar shows that diffusion models are a promising medium for steganography and censorship resistance.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690218",
    "comment": ""
  },
  {
    "title": "Protoss: Protocol for Tight Optimal Symmetric Security",
    "author": "Di Giandomenico, Emanuele and Li, Yong and Sch\\\"{a}ge, Sven",
    "abstract": "We present Protoss, a new balanced PAKE protocol with optimal communication efficiency. Messages are only 160 bits long and the computational complexity is lower than all previous approaches. Our protocol is proven secure in the random oracle model and features a security proof in a strong security model with multiple parties and multiple sessions while allowing for generous attack queries including multiple Test-queries. Moreover, the proof is in the practically relevant single-bit model (that is harder to achieve than the multiple-bit model) and tightly reduces to the Strong Square Diffie-Hellman assumption (SSQRDH). This allows for very efficient, theoretically-sound instantiations and tight compositions with symmetric primitives.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690252",
    "comment": ""
  },
  {
    "title": "What Did Come Out of It? Analysis and Improvements of DIDComm Messaging",
    "author": "Badertscher, Christian and Banfi, Fabio and Diaz, Jesus",
    "abstract": "Self-Sovereign Identity (SSI) empowers individuals and organizations with full control over their data. Decentralized identifiers (DIDs) are at its center, where a DID contains a collection of public keys associated with an entity, and further information to enable entities to engage via secure and private messaging across different platforms. A crucial stepping stone is DIDComm, a cryptographic communication layer that is in production with version 2. Due to its widespread and active deployment, a formal study of DIDComm is highly overdue.  We present the first formal analysis of DIDComm's cryptography, and formalize its goal of (sender-) anonymity and authenticity. We follow a composable approach to capture its security over a generic network, formulating the goal of DIDComm as a strong ideal communication resource. We prove that the proposed encryption modes reach the expected level of privacy and authenticity, but leak beyond the leakage induced by an underlying network (captured by a parameterizable resource).  We further use our formalism to propose enhancements and prove their security: first, we present an optimized algorithm that achieves simultaneously anonymity and authenticity, conforming to the DIDComm message format, and which outperforms the current DIDComm proposal in both ciphertext size and computation time by almost a factor of 2. Second, we present a novel DIDComm mode that fulfills the notion of anonymity preservation, in that it does never leak more than the leakage induced by the network it is executed over. We finally show how to merge this new mode into our improved algorithm, obtaining an efficient all-in-one mode for full anonymity and authenticity.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690300",
    "comment": ""
  },
  {
    "title": "On the Tight Security of the Double Ratchet",
    "author": "Collins, Daniel and Riepel, Doreen and Tran, Si An Oliver",
    "abstract": "The Signal Protocol is a two-party secure messaging protocol used in applications such as Signal, WhatsApp, Google Messages and Facebook Messenger and is used by billions daily. It consists of two core components, one of which is the Double Ratchet protocol that has been the subject of a line of work that aims to understand and formalise exactly what security it provides. Existing models capture strong guarantees including resilience to state exposure in both forward security (protecting past secrets) and post-compromise security (restoring security), adaptive state corruptions, message injections and out-of-order message delivery. Due to this complexity, prior work has failed to provide security guarantees that do not degrade in the number of interactions, even in the single-session setting.Given the ubiquity of the Double Ratchet in practice, we explore tight security bounds for the Double Ratchet in the multi-session setting. To this end, we revisit the modelling of Alwen, Coretti and Dodis (EUROCRYPT 2019) who decompose the protocol into modular, abstract components, notably continuous key agreement (CKA) and forward-secure AEAD (FS-AEAD). To enable a tight security proof, we propose a CKA security model that provides one-way security under key checking attacks. We show that multi-session security of the Double Ratchet can be tightly reduced to the multi-session security of CKA and FS-AEAD, capturing the same strong security guarantees as Alwen et al.Our result improves upon the bounds of Alwen et al. in the random oracle model. Even so, we are unable to provide a completely tight proof for the Double Ratchet based on standard Diffie-Hellman assumptions, and we conjecture it is not possible. We thus go a step further and analyse CKA based on key encapsulation mechanisms (KEMs). In contrast to previous works, our new analysis allows for tight constructions based on the DDH and post-quantum assumptions.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690360",
    "comment": ""
  },
  {
    "title": "Fake It till You Make It: Enhancing Security of Bluetooth Secure Connections via Deferrable Authentication",
    "author": "Fischlin, Marc and Sanina, Olga",
    "abstract": "The Bluetooth protocol for wireless connection between devices comes with several security measures to protect confidentiality and integrity of data. At the heart of these security protocols lies the Secure Simple Pairing, wherewith the devices can negotiate a shared key before communicating sensitive data. Despite the good intentions, the Bluetooth security protocol has repeatedly been shown to be vulnerable, especially with regard to active attacks on the Secure Simple Pairing.We propose here a mechanism to limit active attacks on the Secure Connections protocol (the more secure version of the Secure Simple Pairing protocol), without infringing on the current Bluetooth protocol stack specification. The idea is to run an authentication protocol, like a classical challenge-response step for certified keys, within the existing infrastructure, even at a later, more convenient point in time. We prove that not only does this authentication step ensure freshness of future encryption keys, but an interesting feature is that it---a posteriori ---also guarantees security of previously derived encryption keys. We next argue that this approach indeed prevents a large set of known attacks on the Bluetooth protocol.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670360",
    "comment": ""
  },
  {
    "title": "Reconstructing with Even Less: Amplifying Leakage and Drawing Graphs",
    "author": "Markatou, Evangelia Anna and Tamassia, Roberto",
    "abstract": "Leakage-abuse attacks using access pattern leakage from range queries have been shown to reconstruct encrypted databases. However, prior work is either restricted to one-dimensional databases or requires access to all possible responses in two-dimensions. In this paper, we explore what an adversary can achieve with minimal leakage, focusing on denser databases, and present a leakage abuse attack from access pattern of range queries in multiple dimensions. Our attack employs a novel technique to systematically amplify access pattern leakage, inferring a large number of new query responses that have not been requested by the user. Let m be the size of the database domain. Our attack works on d-dimensional databases and achieves approximate reconstruction. For dense databases and a parameter 0 < λ < 1, our attack fully reconstructs an inner portion of size λm of the database (referred to as the λ-core) after observing O(m log m) queries, uniformly at random. These are significant improvements over previous attacks that require the full set of responses, which has size O(m2). We are the first to leverage graph drawing techniques for database reconstruction attacks. We implement our attack and evaluate it with experiments on real-world databases, achieving accurate reconstructions after observing a small percentage of the responses.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670313",
    "comment": ""
  },
  {
    "title": "Avara: A Uniform Evaluation System for Perceptibility Analysis Against Adversarial Object Evasion Attacks",
    "author": "Ma, Xinyao and Zhang, Chaoqi and Zhu, Huadi and Camp, L. Jean and Li, Ming and Liao, Xiaojing",
    "abstract": "Thanks to recent advances in machine learning (ML) techniques, Autonomous Driving (AD) has seen significant breakthroughs with enhanced capabilities. However, the susceptibility of ML models to adversarial evasion attacks poses a critical threat, undermining the reliability of autonomous driving systems. Despite efforts by researchers to mitigate these attacks within the AD context, unfortunately, a significant gap persists in fully understanding such adversarial maneuvers, particularly from a driver's perspective.To bridge this gap, we propose Avara, the first unified evaluation platform for assessing human drivers' perceptibility to adversarial attacks in AD contexts. Leveraging Virtual Reality (VR) and eye-tracking technology, Avara captures multi-modal driver awareness data, enabling detailed assessments of driver perception. Our approach integrates three distinct sources of multi-modal awareness evaluation metrics, addressing gaps inherent in previous evaluation strategies. The effectiveness and usability of Avara were validated through a human subject study, where participants engaged actively with the platform and provided extensive feedback on their perception and response to adversarial evasion attacks. Utilizing Avara, we identify an intriguing discovery that the current imperceptibility metrics for adversarial attacks fail to accurately reflect the autonomous vehicle driver's perceptibility.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670291",
    "comment": ""
  },
  {
    "title": "SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image Models",
    "author": "Li, Xinfeng and Yang, Yuchen and Deng, Jiangyi and Yan, Chen and Chen, Yanjiao and Ji, Xiaoyu and Xu, Wenyuan",
    "abstract": "Text-to-image (T2I) models, such as Stable Diffusion, have exhibited remarkable performance in generating high-quality images from text descriptions in recent years. However, text-to-image models may be tricked into generating not-safe-for-work (NSFW) content, particularly in sexually explicit scenarios. Existing countermeasures mostly focus on filtering inappropriate inputs and outputs, or suppressing improper text embeddings, which can block sexually explicit content (e.g., naked) but may still be vulnerable to adversarial prompts-inputs that appear innocent but are ill-intended. In this paper, we present SafeGen, a framework to mitigate sexual content generation by text-to-image models in a text-agnostic manner. The key idea is to eliminate explicit visual representations from the model regardless of the text input. In this way, the text-to-image model is resistant to adversarial prompts since such unsafe visual representations are obstructed from within. Extensive experiments conducted on four datasets and large-scale user studies demonstrate SafeGen's effectiveness in mitigating sexually explicit content generation while preserving the high-fidelity of benign images. SafeGen outperforms eight state-of-the-art baseline methods and achieves 99.4\\% sexual content removal performance.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670295",
    "comment": ""
  },
  {
    "title": "Organic or Diffused: Can We Distinguish Human Art from AI-generated Images?",
    "author": "Ha, Anna Yoo Jeong and Passananti, Josephine and Bhaskar, Ronik and Shan, Shawn and Southen, Reid and Zheng, Haitao and Zhao, Ben Y.",
    "abstract": "The advent of generative AI images has completely disrupted the art world. Distinguishing AI generated images from human art is a challenging problem whose impact is growing over time. A failure to address this problem allows bad actors to defraud individuals paying a premium for human art and companies whose stated policies forbid AI imagery. It is also critical for content owners to establish copyright, and for model trainers interested in curating training data in order to avoid potential model collapse.There are several different approaches to distinguishing human art from AI images, including classifiers trained by supervised learning, research tools targeting diffusion models, and identification by professional artists using their knowledge of artistic techniques. In this paper, we seek to understand how well these approaches can perform against today's modern generative models in both benign and adversarial settings. We curate real human art across 7 styles, generate matching images from 5 generative models, and apply 8 detectors (5 automated detectors and 3 different human groups including 180 crowdworkers, 3800+ professional artists, and 13 expert artists experienced at detecting AI). Both Hive and expert artists do very well, but make mistakes in different ways (Hive is weaker against adversarial perturbations while Expert artists produce higher false positives). We believe these weaknesses will persist, and argue that a combination of human and automated detectors provides the best combination of accuracy and robustness.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3670306",
    "comment": ""
  },
  {
    "title": "Image-Perfect Imperfections: Safety, Bias, and Authenticity in the Shadow of Text-To-Image Model Evolution",
    "author": "Wu, Yixin and Shen, Yun and Backes, Michael and Zhang, Yang",
    "abstract": "Text-to-image models, such as Stable Diffusion (SD), undergo iterative updates to improve image quality and address concerns such as safety. Improvements in image quality are straightforward to assess. However, how model updates resolve existing concerns and whether they raise new questions remain unexplored. This study takes an initial step in investigating the evolution of text-to-image models from the perspectives of safety, bias, and authenticity. Our findings, centered on Stable Diffusion, indicate that model updates paint a mixed picture. While updates progressively reduce the generation of unsafe images, the bias issue, particularly in gender, intensifies. We also find that negative stereotypes either persist within the same Non-White race group or shift towards other Non-White race groups through SD updates, yet with minimal association of these traits with the White race group. Additionally, our evaluation reveals a new concern stemming from SD updates: State-of-the-art fake image detectors, initially trained for earlier SD versions, struggle to identify fake images generated by updated versions. We show that fine-tuning these detectors on fake images generated by updated versions achieves at least 96.6\\% accuracy across various SD versions, addressing this issue. Our insights highlight the importance of continued efforts to mitigate biases and vulnerabilities in evolving text-to-image models.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690288",
    "comment": ""
  },
  {
    "title": "ZeroFake: Zero-Shot Detection of Fake Images Generated and Edited by Text-to-Image Generation Models",
    "author": "Sha, Zeyang and Tan, Yicong and Li, Mingjie and Backes, Michael and Zhang, Yang",
    "abstract": "The text-to-image generation model has attracted significant interest from both academic and industrial communities. These models can generate the images based on the given prompt descriptions. Their potent capabilities, while beneficial, also present risks. Previous efforts relied on the approach of training binary classifiers to detect the generated fake images, which is inefficient, lacking in generalizability, and non-robust. In this paper, we propose the novel zero-shot detection method, called ZeroFake, to distinguish fake images apart from real ones by utilizing a perturbation-based DDIM inversion technique. ZeroFake is inspired by the findings that fake images are more robust than real images during the process of DDIM inversion and reconstruction. Specifically, for a given image, ZeroFake first generates noise with DDIM inversion guided by adversary prompts. Then, ZeroFake reconstructs the image from the generated noise. Subsequently, it compares the reconstructed image with the original image to determine whether it is fake or real. By exploiting the differential response of fake and real images to the adversary prompts during the inversion and reconstruction process, our model offers a more robust and efficient method to detect fake images without the extensive data and training costs. Extensive results demonstrate that the proposed ZeroFake can achieve great performance in fake image detection, fake artwork detection, and fake edited image detection. We further illustrate the robustness of the proposed ZeroFake by showcasing its resilience against potential adversary attacks. We hope that our solution can better assist the community in achieving the arrival of a more efficient and fair AGI.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690297",
    "comment": ""
  },
  {
    "title": "Blind and Low-Vision Individuals' Detection of Audio Deepfakes",
    "author": "Sharevski, Filipo and Zeidieh, Aziz and Loop, Jennifer Vander and Jachim, Peter",
    "abstract": "Audio deepfakes are a form of deception where convincing speech sentences are synthesized through machine learning means to give an impression of a human speaker. Audio deepfakes emerge as an attractive vector for targeting users that rely on audio accessibility, such as individuals who are blind or low vision. The critical reliance on speech both as a medium and an affordance puts this population at an undue risk of being deceived as they rely solely on themselves to detect whether a piece of audio is a deepfake or not. To better understand the nature of this risk considering the nuanced reliance on assistive technologies such as screen readers, we conducted a user study with n=16 blind and low vision individuals from the US. Our participants achieved an overall discernment accuracy of 59\\%, and clips identified as deep fakes were only actually deepfakes in 50.8\\% of the cases (precision). The participants that self-identified as \"low vision\" performed slightly better (accuracy of 61\\%, precision of 64\\%) compared to the ones that self-identified as \"blind\" (accuracy of 55\\%, precision of 56\\%). Our qualitative results show that the participants in the \"blind\" group mostly considered a combination of infliction, imperfections in the voice, and the intensity in the speech delivery as discernment factors. The participants in the \"low vision\" group mostly used the speaker's pitch, enunciation, emotion, and the fluency and articulation of the speaker as discernment cues. Overall, participants felt that audio deepfakes have the potential to deceive visually impaired individuals with political disinformation, impersonate their voice in authentication and smart homes, and specifically target them with voice phishing and enhanced scams.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690305",
    "comment": ""
  },
  {
    "title": "HealthSec '24: First ACM CCS Workshop on Cybersecurity in Healthcare",
    "author": "Yurcik, William and Pluta, Gregory and Luong, Toan and Garcia, Luis",
    "abstract": "Our motivation is to create new research forum bringing together diverse researchers from academia, government, and the healthcare industry to report on latest research efforts on cybersecurity in healthcare. As this is the inaugural workshop, our immediate goal for HealthSec'24 is to encourage, jumpstart, grow, and support an interdisciplinary community of researchers focused on cybersecurity in healthcare. To our knowledge this is the first cybersecurity research forum of any kind to have participation from credentialed medical doctors with backgrounds and/or responsibilities related to cybersecurity in healthcare.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691334",
    "comment": ""
  },
  {
    "title": "AACD '24: 11th ACM Workshop on Adaptive and Autonomous Cyber Defense",
    "author": "Gong, Neil and Li, Qi and Zhang, Xiaoli",
    "abstract": "The eleventh ACM Workshop on Adaptive and Autonomous Cyber Defense (AACD) will be held on October 14, 2024, in conjunction with the ACM Conference on Computer and Communications Security (CCS). AACD represents a cutting-edge approach to cybersecurity, where systems leverage AI and machine learning to dynamically detect, respond to, and mitigate evolving cyber threats in real time, minimizing the need for human intervention. A key aspect of this approach is adaptability-autonomous systems can assess attacker behavior, anticipate future threats, and adjust their defenses proactively. As cyberattacks grow more sophisticated, this transition from static defense strategies to dynamic, automated responses offers organizations a more resilient way to protect against emerging threats. The workshop will focus on discussing the challenges and opportunities inherent in this advanced cybersecurity paradigm.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691333",
    "comment": ""
  },
  {
    "title": "SaTS '24: The 2nd ACM Workshop on Secure and Trustworthy Superapps",
    "author": "Lin, Zhiqiang and Xing, Luyi",
    "abstract": "Mobile super apps are revolutionizing mobile computing by offering diverse services through integrated \"miniapps'', creating comprehensive ecosystems akin to app stores like Google Play and Apple's App Store. While these platforms, such as WeChat, Alipay, and TikTok, enhance user convenience and functionality, they also raise significant security and privacy concerns due to the vast amounts of user data they handle. In response, the Workshop on Secure and Trustworthy Superapps (SaTS 2024) aims to address these critical issues by fostering collaboration among researchers and practitioners to explore solutions that protect users and enhance security within the super app landscape.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691542",
    "comment": ""
  },
  {
    "title": "LAMPS '24: ACM CCS Workshop on Large AI Systems and Models with Privacy and Safety Analysis",
    "author": "Li, Bo and Xu, Wenyuan and Chen, Jieshan and Zhang, Yang and Xue, Minhui and Wang, Shuo and Bai, Guangdong and Yuan, Xingliang",
    "abstract": "With large AI systems and models (LAMs) playing an ever-growing role across diverse applications, their impact on the privacy and cybersecurity of critical infrastructure has become a pressing concern. The LAMPS workshop is dedicated to tackling these emerging challenges, promoting dialogue on cutting-edge developments and ethical issues in safeguarding LAMs within critical infrastructure contexts. Bringing together leading experts from around the world, this workshop will delve into the complex privacy and cybersecurity risks posed by LAMs in critical sectors. Attendees will explore innovative solutions, exchange best practices, and contribute to shaping the future research agenda, emphasizing the crucial balance between advancing AI technologies and securing critical digital and physical infrastructures.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691335",
    "comment": ""
  },
  {
    "title": "WPES '24: 23rd Workshop on Privacy in the Electronic Society (WPES)",
    "author": "Ayday, Erman and Vaidya, Jaideep",
    "abstract": "We are excited to welcome you to the 23nd Workshop on Privacy in the Electronic Society (WPES'24). The WPES workshop has a long-standing tradition of showcasing work from academia, industry, and government presenting novel research on theoretical and practical aspects of electronic privacy, as well as experimental studies of fielded systems. We requested two types of submissions: Full papers (up to 12 pages of results in the ACM double-column format, excluding bibliography and appendices) and short papers (up to 4 pages for results) that are preliminary or that simply require few pages to describe.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691544",
    "comment": ""
  },
  {
    "title": "RICSS'24: 2nd International Workshop on Re-design Industrial Control Systems with Security",
    "author": "Sun, Ruimin and Zhang, Mu",
    "abstract": "Industrial Control System (ICS) and its software touches every aspect of the critical infrastructure used by our industry, academia, and government. Back in the days, these systems and software were not designed with security in mind. With the ever expanding interconnectivity of ICS environments and new threats, practitioners are stuck on a patchwork of security. While certain proprietary ICS software manufacturers have started to provide security solutions, free and open source ICS software is often less known. The goal of the workshop is twofold: we want to collect ideas on redesigning (parts of) the ICS ecosystem so that security is built-in by design; we also invite contributions on designing, incorporating, and maintaining secure open-source ICS software.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691337",
    "comment": ""
  },
  {
    "title": "The 19th Workshop on Programming Languages and Analysis for Security (PLAS 2024)",
    "author": "Daniel, Lesly-Ann and Rajani, Vineet",
    "abstract": "PLAS provides a forum for exploring and evaluating the use of programming language and program analysis techniques for promoting security in the complete range of software systems, from compilers to machine-learned models and smart contracts. The workshop encourages proposals of new, speculative ideas, evaluations of new or known techniques in practical settings, and discussions of emerging threats and problems. It also hosts position papers that are radical, forward-looking, and lead to lively and insightful discussions influential to the future research at the intersection of programming languages and security.This year will mark the 19th edition of PLAS, which was first held in 2007 in San Diego. The workshop will host 2 keynote talks, by Natasha Fernandes and Binoy Ravindran, and 8 paper presentations.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691336",
    "comment": ""
  },
  {
    "title": "FEAST'24: Sixth Workshop on Forming an Ecosystem Around Software Transformation",
    "author": "Craven, Ryan and Mickelson, Matthew",
    "abstract": "The Sixth Workshop on Forming an Ecosystem Around Software Transformation (FEAST) revives the series, with the original five events taking place from 2016-2020. FEAST is concerned with all aspects of achieving effective, robust, and appraisable late-stage transformation of software for security. Late-stage transformations allow third parties to deeply tailor existing software to their mission, customizing it with little to no access to source code or support from the original developer.Research has shown that late-stage software customization is of particular benefit to security-conscious software consumers who must use closed-source or source-free binary software components in mission-critical settings, or who must harden software against newly emerging attacks not anticipated during the software's original design and development. However, there is still a long way to go toward achieving sound and robust transformations whose holistic benefits to deployed software are fully appraisable. Motivated by these outstanding challenges, FEAST continues in its goal to form an active ecosystem of strategies and tools for accomplishing source-free binary code transformation reliably and on-demand.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691553",
    "comment": ""
  },
  {
    "title": "CCSW 2024 -- Cloud Computing Security Workshop",
    "author": "Fournaris, Apostolos and Palmieri, Paolo",
    "abstract": "The CCSW workshop aims to bring together researchers and practitioners to explore all aspects of security in cloud-centric and outsourced computing. In CCSW 2024, based on the papers that have been accepted, the workshop is focused on applied cryptographic schemes and protocols for the cloud, cloud-based leakage related attacks and their countermeasures, trusted computing technology in clouds, binary analysis of software for cloud protection, network security mechanisms using AI anomaly detection as well as security for emerging cloud programming models (like extended Berkeley Packet Filter, eBPF, programs). Throughout the years, the workshop particularly encourages novel paradigms and controversial ideas not covered by traditional cloud security research, serving as a fertile ground for creative debate and interaction in security-sensitive areas of computing impacted by cloud technologies. The workshop received 20 submissions, 15 of which passed through a thorough review process of at least 3 reviewers, and 7 of them were accepted for publication and presentation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691548",
    "comment": ""
  },
  {
    "title": "CheckMATE '24 - Research on Offensive and Defensive Techniques in the context of Man At The End (MATE) Attacks",
    "author": "Schrittwieser, Sebastian and Ianni, Michele",
    "abstract": "MATE (Man-At-The-End) is an attacker model where an adversary has access to the target software and/or hardware environment of his victim and the ability to observe and modify it in order to extract secrets such as cryptographic keys or sensitive information, possibly with the subsequent goal of compromising code integrity or inserting backdoors, among others. A typical example of such a scenario is the case of an attack on a stolen smartphone or against software leveraging protection to offer premium content and/or features such as paid TV channels.The main focus of CheckMATE is on new models and techniques to defend software from tampering, reverse engineering, and piracy as well as to the development of new attack strategies that highlight the need of more complete defenses. We include both offensive and defensive techniques because of their close and intertwined relationship depending on the attack scenario. For instance, reverse engineering is defensive when the goal is to analyse obfuscated malware, but it is offensive when it is used to steal intellectual property and assets in legitimate software. Likewise, obfuscation is defensive when it aims for protecting a legitimate asset against reverse engineering, while it is offensive if it is used to hide that malware is embedded in an application. Both scenarios are of practical relevance, and therefore CheckMATE includes all attacks on/defenses of the confidentiality and integrity of software applications and assets embedded therein and exposed to MATE attacks. In such scenarios, attackers have full control over, and access to the hardware and/or software they are attacking in a controlled environment.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691549",
    "comment": ""
  },
  {
    "title": "CPSIoTSec'24: Sixth Workshop on CPS&IoT Security and Privacy",
    "author": "Fawaz, Kassem and Almgren, Magnus",
    "abstract": "The sixth Workshop on CPS \\& IoT Security and Privacy is set to take place in Salt Lake City, UT, USA, on October 18, 2024, in conjunction with the ACM Conference on Computer and Communications Security (CCS'24). This workshop marks the amalgamation of two workshops held in 2019: one focused on the security and privacy of cyber-physical systems, while the other one centered on the security and privacy of IoT. The primary objective of this workshop is to create a collaborative forum that brings together academia, industry experts, and governmental entities, encouraging them to contribute cutting-edge research, share demonstrations or hands-on experiences, and engage in discussions. This year, our call for contributions encompassed a broad spectrum, including full research papers, work-in-progress submissions, and one-page abstracts. The workshop program includes eight full-length papers on the security and privacy of CPS/IoT, alongside six shorter papers that present original or work-in-progress research. Furthermore, the workshop will feature one distinguished keynote presentation by Prof. Alvaro Cardenas, a world-renowned expert in CPS security. The talk will offer insights into how the state of CPS security has evolved since 2007. The complete CPSIoTSec'24 workshop proceedings are available at https://doi.org/10.1145/3658644.3691550.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691550",
    "comment": ""
  },
  {
    "title": "AISec '24: 17th ACM Workshop on Artificial Intelligence and Security",
    "author": "Pintor, Maura and Jagielski, Matthew and Chen, Xinyun",
    "abstract": "The use of Artificial Intelligence (AI) and Machine Learning (ML) has been the center of the most outstanding advancements in the last years. The ability to analyze considerable streams of data in real time makes these technologies the most promising tool in many domains, including cybersecurity. As an outstanding example, ML can be used for identifying malware because of its ability to detect patterns otherwise difficult to see for humans and hard-coded rules. However, the use of AI and ML in security-relevant domains raised rightful concerns about their trustworthiness and robustness, espe- cially in front of adaptive attackers. Additionally, privacy threats are now emerging as a crucial aspect and need proper testing and possibly mitigation to prevent data stealing and leakage of sensitive information. AISec provides a venue for presenting and discussing new developments in the intersection of security and privacy with AI and ML. The AISec'24 workshop proceedings are available at: https://dl.acm.org/doi/proceedings/10.1145/3658644.3691545.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691545",
    "comment": ""
  },
  {
    "title": "DeFi '24: Workshop on Decentralized Finance and Security",
    "author": "Zhou, Liyi and Qin, Kaihua",
    "abstract": "Decentralized Finance (DeFi) has undergone significant expansion, evolving from a niche market into a complex alternative financial ecosystem. This burgeoning landscape now encompasses a diverse array of financial services, including decentralized exchanges, lending and borrowing platforms, stablecoins, derivatives, yield optimization services, prediction markets, and privacy-enhancing technologies such as token mixers. While the total value locked in DeFi protocols-estimated at approximately 77 billion USD-underscores its increasing significance, it simultaneously highlights the critical necessity for robust security measures.This workshop aims to address the pressing security challenges in the maturing DeFi space by convening leading experts from the fields of cryptography, game theory, economics, and cybersecurity. Our primary objective is to foster interdisciplinary dialogue and showcase cutting-edge research that rigorously examines the current state of DeFi security and charts a comprehensive path forward. The anticipated outcomes include a prioritized research agenda, new collaborative initiatives bridging theoretical advancements with practical implementations, and a strategic roadmap for enhancing security in the rapidly evolving DeFi ecosystem. We aim to contribute to the foundation of more secure, scalable, and user-centric decentralized financial systems.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691552",
    "comment": ""
  },
  {
    "title": "ASHES '24: Workshop on Attacks and Solutions in Hardware Security",
    "author": "Batina, Lejla and Chang, Chip Hong and R\\\"{u}hrmair, Ulrich and Szefer, Jakub",
    "abstract": "The workshop on \"Attacks and Solutions in HardwarE Security (ASHES)\" welcomes any theoretical and practical works on hardware security, including attacks, solutions, countermeasures, proofs, classification, formalization, and implementations. Besides mainstream research, ASHES puts some focus on new and emerging scenarios: This includes the Internet of Things (IoT), nuclear weapons inspections, arms control, consumer and infrastructure security, or supply chain security, among others. ASHES also welcomes works on special purpose hardware, such as lightweight, low-cost, and energy-efficient devices, or non-electronic security systems.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691546",
    "comment": ""
  },
  {
    "title": "AutonomousCyber '24 -- Workshop on Autonomous Cybersecurity",
    "author": "Dehghantanha, Ali and Parizi, Reza M. and Epiphaniou, Gregory",
    "abstract": "Autonomous cybersecurity represents a significant evolution in information security, where systems independently detect, respond to, and neutralize cyber threats without the need for human intervention. This level of autonomy is a more advanced stage in cybersecurity, enabling systems not only to execute tasks but also to interpret contexts, make decisions, and adapt strategies in realtime. The shift towards autonomy promises enhanced adaptability, faster response times, and a reduction in human error. This domain stands out for its unique blend of advanced Machine Learning (ML) systems such as Reinforcement Learning (RL)-driven and Quantum Machine Learning (QML)-based agents with cybersecurity automation techniques such as automated patch management systems, automated incident response systems to forge self-reliant cybersecurity systems. The AutonomousCyber workshop provides a venue for presenting and discussing new developments in this field.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691547",
    "comment": ""
  },
  {
    "title": "CSCS '24 -- Cyber Security in CarS Workshop",
    "author": "Fritz, Mario and Krau\\ss{}, Christoph and Hof, Hans-Joachim",
    "abstract": "The increasing attack surface of modern cars and the new regulatory requirements for cybersecurity (like UNECE R155) made cybersecurity an important part of car design. The \"CSCS'24 Cyber Security in Cars Workshop\" is designed to address current topics in the rapidly evolving automotive cybersecurity domain. The goal is to bring together academia and industry to find novel solutions for cybersecurity problems in the automotive domain. CSCS'24 is the first CSCS workshop co-located with ACM CCS. Nonetheless, it is founded on a series of events known as the \"ACM Cyber Security in Cars Symposium (CSCS symposium)\" that lasted from 2017 until 2023. CSCS'24 welcomes any theoretical or practical contributions to the rich field of automotive cybersecurity, including secure automotive communication, ECU system security, and aspects of Cyber Security Management Systems (CSMS).",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691551",
    "comment": ""
  },
  {
    "title": "SCORED '24: Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses",
    "author": "Torres-Arias, Santiago and Melara, Marcela",
    "abstract": "Recent attacks on the software supply chain have shed light on the fragility and importance of ensuring the security and integrity of this vital ecosystem. Addressing the technical and social challenges to building trustworthy software for deployment in sensitive and/or large-scale enterprise or governmental settings requires innovative solutions and an interdisciplinary approach. The Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses (SCORED) is the leading venue for bringing together industry practitioners, academics, and policymakers to present and discuss security vulnerabilities, novel defenses against attacks, project demos, adoption requirements and best practices in the software supply chain. The complete SCORED '24 workshop proceedings are available at: https://doi.org/10.1145/3689944",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691554",
    "comment": ""
  },
  {
    "title": "Poster: Privacy Norms for Fertility Data in the Roe v. Wade era",
    "author": "Chown, Zander and Prasad, Aarathi",
    "abstract": "This poster presents results from a study to better understand the opinions and concerns actual or potential users of fertility-tracking apps have with regards to privacy and disclosure of their data. We expect these results will guide the creation of contextual norms that the apps should abide by to protect user privacy.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691406",
    "comment": ""
  },
  {
    "title": "Poster: Kill Krill or Proxy RPKI",
    "author": "Cattepoel, Louis and Mirdita, Donika and Schulmann, Haya and Waidner, Michael",
    "abstract": "Resource Public Key Infrastructure (RPKI), designed to protect Internet routing from hijacks, is gaining traction: over 50\\% of prefixes have digital certificates, at least 27\\% of Autonomous Systems actively validate certificates against BGP announcements, and filter invalid routing announcements. In this study, we present the first security analysis of Krill, the only public and open-source RPKI publication point software. Publication points are hosted by the five Regional Internet Registries across the globe, or by independent Internet operators that wish to manage their own RPKI repositories.  Through a detailed investigation of Krill, involving API, command line, configuration parsings, and static code analysis, we identify significant vulnerabilities such as transient dependencies and Denial-of-Service (DoS) exploits. Our key findings reveal Krill's susceptibility to path traversal attacks in case of misconfigured Nginx proxies, and a DoS vulnerability stemming from the h2 rust library. We develop an attack vector that exploits the rust library vulnerability, which leads to a 350x performance degradation. Our results indicate that RPKI is not yet production-grade ready as its main component, the publication points - which host the RPKI objects, are vulnerable to information leaks and DoS attacks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691390",
    "comment": ""
  },
  {
    "title": "Poster: Security of Login Interfaces in Modern Organizations",
    "author": "Nsieyanji Tchokodeu, Kevin and Schulmann, Haya and Sobol, Gil and Waidner, Michael",
    "abstract": "Login pages, including those for processes like sign-up, registration, and password recovery are interfaces that implement access control to company services or functionalities. Insufficient security on these pages could allow malicious individuals to gain access to services and network of an organization and launch attacks. In this work, we perform a comprehensive study of the security of 73.4k login interfaces of the 100-top European companies from the Fortune report, which we call EU100. We find over 9 million vulnerabilities, which we analyze from a technical perspective, and categorize them according to the hosting model. Our work provides details on the most commonly observed vulnerabilities on login pages across different sectors and according to the hosting strategy adopted by each company.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691413",
    "comment": ""
  },
  {
    "title": "Poster: Whether We Are Good Enough to Detect Server-Side Request Forgeries in PHP-native Applications?",
    "author": "Ji, Yuchen and Dai, Ting and Tang, Yutian and He, Jingzhu",
    "abstract": "Server-side request forgeries (SSRFs) are inevitable in PHP web applications. Existing static taint analysis tools for PHP suffer from both high rates of false positives and false negatives in detecting SSRF because they do not incorporate application-specific sources and sinks, account for PHP's dynamic type characteristics, and include SSRF-specific taint analysis rules, leading to over-tainting and under-tainting. In this work, we propose a technique to accurately detect SSRF vulnerabilities in PHP web applications. First, we extract both PHP built-in and application-specific functions as candidate source and sink functions. Second, we extract explicit and implicit function calls to construct applications' call graphs. Third, we perform a taint analysis based on a set of rules that prevent over-tainting and under-tainting. We have implemented a prototype and evaluated it with different types of PHP web applications. Our preliminary experiment shows that we detect 24 SSRF vulnerabilities in 13 different types of applications. 20 of the vulnerabilities are known and 4 of the vulnerabilities are new.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691419",
    "comment": ""
  },
  {
    "title": "Poster: Marian: An Open Source RISC-V Processor with Zvk Vector Cryptography Extensions",
    "author": "Szymkowiak, Thomas and Isufi, Endrit and Saarinen, Markku-Juhani",
    "abstract": "The RISC-V Vector Cryptography Extensions (Zvk) were ratified in 2023 and integrated into the main ISA manuals in 2024. These extensions support high-speed symmetric cryptography (AES, SHA2, SM3, SM4) operating on the vector register file and offer significant performance improvements over scalar cryptography extensions (Zk) due to data parallelism. As a ratified extension, Zvk is supported by compiler toolchains and is already being integrated into popular cryptographic middleware such as OpenSSL. We report on Marian, the first open-source hardware implementation of a vector processor with the Zvk extensions. The design is based on the PULP \"Ara\" vector unit, which itself is an extension of the popular CVA6 processor. The implementation is in SystemVerilog and has been tested using Virtex Ultrascale+ FPGA prototyping, with a planned tapeout targeting a 22nm process node. We offer an analysis of the architectural requirements that vector cryptography imposes on a processor, as well as the initial estimates of performance and area for our implementation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691394",
    "comment": ""
  },
  {
    "title": "Poster: Towards Real-Time Intrusion Detection with Explainable AI-Based Detector",
    "author": "Li, Wenhao and Ma, Duohe and Li, Zhaoxuan and Bao, Huaifeng and Wang, Shuai and Jin, Huamin and Zhang, Xiao-Yu",
    "abstract": "Identifying malicious traffic is crucial for safeguarding internal networks from privacy breaches. Intrusion Detection Systems (IDS) traditionally rely on inefficient and outdated rule-sets, necessitating a shift towards AI-driven, learning-based algorithms for enhanced detection capabilities. Despite their promise, AI-integrated IDS face deployment challenges due to complex, opaque decision-making processes that can lead to latency and an increased risk of false positives. This paper presents the Explainable AI-based Intrusion Detection System (XAI-IDS), addressing the limitations of both rule-based and AI-driven IDS by integrating interpretable deep learning models. XAI-IDS employs tree regularization to transform complex models into efficient, transparent decision trees, facilitating real-time detection with improved accuracy and explainability. Experiments on two benchmark datasets demonstrate XAI-IDS's superior performance, offering a scalable solution to the challenge of identifying malicious traffic with reduced risk of false positives.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691410",
    "comment": ""
  },
  {
    "title": "Poster: Patching NSEC3-Encloser: The Good, the Bad, and the Ugly",
    "author": "Jacobsen, Oliver and Schulmann, Haya",
    "abstract": "This paper evaluates the effectiveness of patches designed to mitigate the NSEC3-encloser attack in DNS resolvers. NSEC3, used in DNSSEC to authenticate non-existence of records, can be exploited to exhaust resolver resources through excessive SHA-1 hashing. Despite recent patches, our study reveals that major DNS resolvers remain vulnerable. We test the NSEC3 exhaustion attacks against pre- and post-patch versions of popular DNS resolvers (Unbound, BIND9, PowerDNS, and Knot Resolver), and observe a 72-fold increase in CPU instructions during attacks. PowerDNS 5.0.5 and Knot Resolver 5.7.3 showed improvements, limiting CPU load with strict hash limits. Conversely, BIND9 exhibited marginal improvement, and Unbound 1.20.0 experienced increased CPU load. At an attack rate of 150 malicious NSEC3 records per second, benign DNS request loss rates ranged from 2.7\\% to 30\\%. Our study indicates the need for robust countermeasures to address NSEC3 vulnerabilities.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691395",
    "comment": ""
  },
  {
    "title": "Poster: An Exploration of Large Language Models in Malicious Source Code Detection",
    "author": "Xue, Di and Zhao, Gang and Fan, Zhongqi and Li, Wei and Xu, Yahong and Liu, Zhen and Liu, Yin and Yuan, Zhongliang",
    "abstract": "Embedding malicious code within the software supply chain has become a significant concern in the information technology field. Current methods for detecting malicious code, based on signatures, behavior analysis, and traditional machine learning models, lack result interpretability. This study proposes a novel malicious code detection framework, Mal-LLM, which leverages the cost advantages of traditional machine learning models and the interpretability of LLMs. Initially, traditional machine learning models filter vast amounts of malicious source code in the software supply chain. Subsequently, LLMs analyze and interpret the filtered malicious source code using a customized prompt template incorporating role-playing and chain-of-thought techniques. The feasibility of the Mal-LLM framework is validated through extensive experimental analyses, examining the ambiguity and redundancy of the LLM in the framework, the significance of ''experience'' and ''malicious'' prompts, and exploring methods to reduce the cost of using LLMs from an enterprise perspective.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691374",
    "comment": ""
  },
  {
    "title": "Poster: The Concept of a System for Automatic Detection and Correction of Vulnerabilities in the Source Code",
    "author": "Hyla, Tomasz and Wawrzyniak, Natalia",
    "abstract": "Defects in the source code that affect security are one of the main elements used to carry out cyber attacks. Examining source code for vulnerabilities is a difficult and expensive process. As a result, specialized software is needed for this. Due to the development of various artificial intelligence methods, improving existing vulnerability detection methods is possible. In particular, it is possible to reduce the number of false positives and enable the detection of complex vulnerabilities that require understanding the broader context of the code. The article presents the concept of a system for automatic analysis of vulnerabilities in source code, along with the challenges and problems related to its design and use.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691417",
    "comment": ""
  },
  {
    "title": "Poster: Cyber Security Economics Model (CYSEM)",
    "author": "Xin, Tong and He, Ying and Zamani, Efpraxia D. and Luo, Cunjin",
    "abstract": "The increasing sophistication of cyberattacks and the evolution of security risks make it challenging for organizations to understand their impact on businesses. The habitual reliance on the judgment of cyber security experts and communication gaps between cyber security team and board members, responsible for making strategic cyber security investment decisions further weaken organization's capability to respond to cyber threats. Existing research lacks a transparent approach to quantify security risks and their impact on businesses. This paper introduces a novel CYSEM that express security risk in financial terms, through integrating Cyber Threat Intelligence (CTI) with the Factor Analysis of Information Risk (FAIR) model, elaborated with cyber security cost typologies. CYSEM facilitates communication among multi-stakeholders and improves transparency and quality of investment decision-making at the strategic level. We evaluate the CYSEM using a case study, which has showed its effectiveness in understanding the impact of cyber threat from an economics perspective.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691398",
    "comment": ""
  },
  {
    "title": "Poster: AuditVotes: A Framework towards Deployable Certified Robustness for GNNs",
    "author": "Lai, Yuni and Zhou, Kai",
    "abstract": "Graph Neural Networks (GNNs) are powerful but vulnerable to adversarial attacks, necessitating the research on certified robustness that can provide GNNs with robustness guarantees. Existing randomized smoothing methods struggle with a trade-off between utility and robustness due to high noise levels. We introduce AuditVotes, which integrates randomized smoothing with two components, <u>au</u>gmentation and con<u>dit</u>ional smoothing, aiming to improve data and vote quality. We instantiated AuditVotes with simple strategies, and preliminary results demonstrate its significant promise in enhancing certified robustness, representing a substantial step toward deploying certifiably robust GNNs in real-world applications.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691376",
    "comment": ""
  },
  {
    "title": "Poster: zkTax: A Pragmatic Way to Support Zero-Knowledge Tax Disclosures",
    "author": "Berke, Alex and South, Tobin and Mahari, Robert and Larson, Kent and Pentland, Alex",
    "abstract": "Tax returns contain financial information of interest to third parties: public officials are asked to share financial data for transparency, companies seek to assess the financial status of business partners, and individuals need to prove their income to third-parties. Tax returns also contain sensitive data such that sharing them in their entirety undermines privacy. We outline how zero-knowledge cryptography may be applied to address this tension by allowing individuals and organizations to make provable claims about select information in their tax returns without revealing additional information, in a way that can be independently verified by third parties. We highlight key system goals and design specifications for this zero-knowledge tax disclosure system (zkTax) and present a prototype implementation. The prototype consists of three distinct services that can be distributed: a tax authority that provides signed tax documents; a Redact \\& Prove Service that enables users to redact tax documents and produce a zero-knowledge proof attesting the provenance of the redacted data; and a Verify Service to check the validity of claims. We demonstrate how zkTax could be implemented with minimal changes to existing tax infrastructure, allowing the system to be extensible to other contexts and jurisdictions. This work provides a practical example of how distributed tools leveraging cryptography can enhance existing government or financial infrastructures, providing immediate transparency alongside privacy without system overhauls.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691421",
    "comment": ""
  },
  {
    "title": "Poster: End-to-End Privacy-Preserving Vertical Federated Learning using Private Cross-Organizational Data Collaboration",
    "author": "Ochiai, Keiichi and Terada, Masayuki",
    "abstract": "As data utilization in organizations is advancing in various fields, insights that data brings will be more diverse when it is sourced through collaboration across different organizations. Federated learning, a machine learning method with distributed data across organizations, with local differential privacy protects privacy by sharing only the model parameters and the information necessary for model update, without having to share the data each organization holds. However, there is a problem with local differential privacy, where the amount of noise increases, leading to the degradation in model accuracy. In this paper, we propose a method of reducing the impact of noise compared to conventional federated learning by leveraging private cross-organizational data collaboration, called Private Cross-aggregation Technology (PCT). PCT combines Private Set Intersection Cardinality, Trusted Execution Environment and Differential Privacy, and outputs a cross-tabulation table that is private from input to output. Our method consists of two steps: (1) creating a private cross-tabulation table using PCT, and (2) training a ML using the private cross-tabulation table. The experiment results showed that (1) the classification accuracy of the proposed method was higher than that of the baseline method in situations where the privacy budget is limited, and (2) the computation time of the proposed method was shorter than that of the baseline method.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691383",
    "comment": ""
  },
  {
    "title": "Poster: YFuzz: Data-Driven Fuzzing",
    "author": "Chang, Yuan and Huang, Chun-Chia and Mori, Tatsuya and Hsiao, Hsu-Chun",
    "abstract": "Code coverage is an effective objective for guiding fuzzers to explore code and identify bugs, and it has been a key factor in the success of greybox fuzzing. However, code coverage has a critical limitation: coverage-guided fuzzers can miss bugs even when the associated code is covered. This limitation arises because merely executing the associated code is often insufficient to trigger a bug; specific conditions are usually also required. These conditions are not fully captured by code coverage, which focuses only on whether the code was executed.To address this problem, we propose a new objective: value state coverage, an additional dimension in coverage metrics that is orthogonal to code coverage. Value state is a combination of the values assigned to program variables and the order of their assignment, and by measuring the coverage of value states, we can guide a fuzzer to explore the triggering conditions of bugs. We also introduce Data-Driven Fuzzing, a novel fuzzing technique that focuses on value state coverage, and utilizes security-related variables, mutation strategies, and extreme values captured at runtime to effectively discover bugs. We implemented our approach in a prototype fuzzer named YFuzz. YFuzz has found 12 bugs in programs included in the OSS-Fuzz project, including 4 assigned CVEs, indicating that our approach is effective in finding bugs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691420",
    "comment": ""
  },
  {
    "title": "Poster: Repairing Bugs with the Introduction of New Variables: A Multi-Agent Large Language Model",
    "author": "Zhang, Elisa and Sun, Shiyu and Xing, Yunlong and Sun, Kun",
    "abstract": "Trained on billions of tokens, large language models (LLMs) have a broad range of empirical knowledge which enables them to generate software patches with complex repair patterns. We leverage the powerful code-fixing capabilities of LLMs and propose VarPatch, a multi-agent conversational automated program repair (APR) technique that iteratively queries the LLM to generate software patches by providing various prompts and context information. VarPatch focuses on the variable addition repair pattern, as previous APR tools struggle to introduce and use new variables to fix buggy code. Additionally, we summarize commonly used APIs and identify four repair patterns involving new variable addition. Our evaluation on the Defects4J 1.2 dataset shows that VarPatch can repair 69\\% more bugs than baseline tools and over 8 times more bugs than GPT-4.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691412",
    "comment": ""
  },
  {
    "title": "Poster: In-switch Defense against DNS Amplification DDoS Attacks",
    "author": "Mirsadeghi, Seyed Mohammad Hadi",
    "abstract": "Amplification Distributed Denial of Service (DDoS) attacks continue to be a high-impact force in the cybersecurity landscape. Programmable switching paves the way for revisiting the measurement of traffic integrity, offering a new opportunity to devise independent defense mechanisms against amplification traffic. A novel method capable of defending against DNS amplification distributed denial-of-service cyberattacks has been developed. The technique enables a programmable switch to independently drop up to 89\\% of untrusted DNS traffic. The coupling of programmable switching and sequence analysis to detect and drop amplification traffic at line rate appears to be both innovative and practical. A significant aspect of the methodology is that amplification traffic detection and prevention is accomplished in linear time. Another important advantage of this method is the suitability for applications of game theory as utility function. The contributions of this work can be summarized as follows: We present an intermediary algorithm that enables profile-agnostic defense against amplification traffic. The sequence analysis algorithm relies on parts of the packet payload to detect untrusted traffic at line rate. Furthermore, we gauge the potential benefit of in-switch sequence analysis that presents a fundamental step in the direction of more complex applications towards game theoretic trust.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691404",
    "comment": ""
  },
  {
    "title": "Poster: A Full-stack Secure Deletion Framework for Modern Computing Devices",
    "author": "Chen, Bo and Rother, Caleb and Dafoe, Josh",
    "abstract": "Secure data deletion is of critical importance for complying with retention regulations and safeguarding user privacy. In this work, we have proposed the first full-stack secure deletion design addressing both external storage and internal memory for secure deletion. Preliminary experimental results are provided to justify feasibility of the proposed design.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691369",
    "comment": ""
  },
  {
    "title": "Poster: Few-Shot Inter-Domain Routing Threat Detection with Large-Scale Multi-Modal Pre-Training",
    "author": "Li, Yizhi and Li, Jiang and Cao, Jiahao and Xie, Renjie and Wang, Yangyang and Xu, Mingwei",
    "abstract": "Border Gateway Protocol (BGP) plays a pivotal role as the de facto inter-domain routing protocol on the Internet. However, BGP threats continually emerge and undermine the Internet reliability. Existing BGP threat detection methods based on machine learning require substantial labeled data and expert involvement, making them costly and labor-intensive. Moreover, they fail to learn rich information from massive unlabeled BGP data consistently generated on the Internet. In this paper, we propose FIRE that enables few-shot inter-domain routing threat detection with large-scale multi-modal pre-training. FIRE conducts domain-specific pre-training tasks to acquire rich BGP implicit knowledge from massive unlabeled BGP data for few-shot learning. Our experiments show that FIRE can be fine-tuned to precisely identify BGP threats with only a few labeled samples, e.g., a 93.2\\% precision in route leak detection with merely 8 events for fine-tuning.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691402",
    "comment": ""
  },
  {
    "title": "Poster: Formally Verified Binary Lifting to P-Code",
    "author": "Naus, Nico and Verbeek, Freek and Atla, Sagar and Ravindran, Binoy",
    "abstract": "Analysis of binary software plays a critical role in software security. Reverse engineers analyze binaries to discover vulnerabilities, patch legacy software, and detect malware. Most of the reverse engineering tools have been developed from a practical point of view, and do not provide any guarantees with their results. Recently, formally verified reverse engineering and decompilation have gained traction. These formal tools are for the most part proof-of-concept systems not yet suitable for real-world reverse-engineering tasks. In this poster, we explore the idea of formalizing part of an existing decompilation tool instead. We focus on the lifting from assembly to the IR P-Code in one of the most popular decompilers, Ghidra. This step occurs immediately after disassembly. We are developing a proof system inside the Isabelle theorem prover, to automatically prove semantical equivalence between the assembly and P-Code instructions. We leverage machine-learned x86-64 semantics, to stay as close as possible to actual CPU behavior. This approach has uncovered several shortcomings in Ghidra's P-Code and the lifting it performs. By using a theorem prover, we obtain guarantees that our system of formal semantics and lifting is internally consistent. This work brings the powerful guarantees that formal methods provide in reverse engineering research to the real world.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691386",
    "comment": ""
  },
  {
    "title": "Poster: libdebug, Build Your Own Debugger for a Better (Hello) World",
    "author": "Digregorio, Gabriele and Bertolini, Roberto Alessandro and Panebianco, Francesco and Polino, Mario",
    "abstract": "Automated debugging, long pursued in a variety of fields from software engineering to cybersecurity, requires a framework that offers the building blocks for a programmable debugging workflow. However, existing debuggers are primarily tailored for human interaction, and those designed for programmatic debugging focus on kernel space, resulting in limited functionality in userland. To fill this gap, we introduce libdebug, a Python library for programmatic debugging of userland binary executables. libdebug offers a user-friendly API that enables developers to build custom debugging tools for various applications, including software engineering, reverse engineering, and software security. It is released as an open-source project, along with comprehensive documentation to encourage use and collaboration across the community. We demonstrate the versatility and performance of libdebug through case studies and benchmarks, all of which are publicly available. We find that the median latency of syscall and breakpoint handling in libdebug is 3 to 4 times lower compared to that of GDB.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691391",
    "comment": ""
  },
  {
    "title": "Poster: M2ASK: A Correlation-Based Multi-Step Attack Scenario Detection Framework Using MITRE ATT&CK Mapping",
    "author": "Meng, Qiaoran and Oo, Nay and Jiang, Yuning and Lim, Hoon Wei and Sikdar, Biplab",
    "abstract": "Traditional Network Intrusion Detection Systems (NIDS) often generate large volumes of alerts with redundancies and false positives, incapable of correlating detected attack actions. This adds difficulty for security analysts to construct a comprehensive understanding of multi-step attacks. To address these limitations, we present a novel MITRE-based Multi-step Attack Scenario Construction (M2ASK) algorithm that enhances cyber threat intelligence (CTI) by integrating MITRE ATT&CK tactic and technique mapping, facilitating the interpretation of multi-step attacks and informing response strategies. Our approach processes alert data from NIDSs, transforming it into a network communication graph. Graph-based correlation techniques are employed, combined with MITRE ATT&CK and Cyber Kill Chain stage profiling to construct comprehensive network attack scenarios. Our key contributions include: (1) the development of a Cyber Kill Chain based model for constructing attack scenarios; (2) the alert correlation approach based on MITRE ATT&CK tagging of attack actions.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691392",
    "comment": ""
  },
  {
    "title": "Poster: Synchronization Concerns of DNS Integrations",
    "author": "Kaizer, Andrew and Naciri, Will and Sheth, Swapneel",
    "abstract": "The widespread use of the Domain Name System (DNS) as a namespace for websites, email addresses, and other applications has led to proposals for integrating domain names into additional applications. An important quality for DNS integrations is synchronization, i.e., there is evidence that a current registrant of a domain name associated with the integration has chosen to participate in the integration. Failure to maintain synchronization may result in avoidable risks to users, however no study has detailed the scope of synchronization concerns across DNS integrations. To that end, this paper presents preliminary results from three novel DNS integrations that show between 1\\% and 40\\% of integrated domain name are not clearly synchronized and as such further study is merited to understand the risks and solutions that may be available. Furthermore, feedback on an IETF draft is proposed as one avenue through which researchers could provide input to address this problem space.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691415",
    "comment": ""
  },
  {
    "title": "Poster: E-Graphs and Equality Saturation for Term-Rewriting in MBA Deobfuscation: An Empirical Study",
    "author": "Lee, Seoksu and Jeon, Hyeongchang and Cho, Eun-Sun",
    "abstract": "Obfuscation is a powerful software protection technique. It changes a program into a more complicated one while preserving its semantics. Malware distributors also employ this method, to protect their malware from being understood by malware analysts. Thus, it is crucial to deobfuscate malware in a timely manner, to enable a prompt action to malware.This poster presents an efficient deobfuscation method using e-graph and equality saturation, a recent attention-gathering optimization technique, known for inherent theoretical efficiency in term-rewriting. Among the various deobfuscation techniques, we focus on Mixed Boolean Arithmetic (MBA) obfuscation, which is one of the most popular obfuscation methods due to its unparalleled strength and efficiency. We implement an e-graph and equality-saturation-based term-rewrite MBA deobfuscator, called EMBA, to simplify various sets of MBA-obfuscated expressions. By comparing its performance with state-of-the-art deobfuscators, we have shown that the equality saturation-based method has promising properties in MBA deobfuscation.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691382",
    "comment": ""
  },
  {
    "title": "Poster: Different Victims, Same Layout: Email Visual Similarity Detection for Enhanced Email Protection",
    "author": "Shukla, Sachin and Mirzaei, Omid",
    "abstract": "In the pursuit of an effective spam detection system, the focus has often been on identifying known spam patterns either through rule-based detection systems or machine learning (ML) solutions that rely on keywords. However, both systems are susceptible to evasion techniques and zero-day attacks that can be achieved at low cost. Therefore, an email that bypassed the defense system once can do it again in the following days, even though rules are updated or the ML models are retrained. The recurrence of failures to detect emails that exhibit layout similarities to previously undetected spam is concerning for customers and can erode their trust in a company. Our observations show that threat actors reuse email kits extensively and can bypass detection with little effort, for example, by making changes to the content of emails. In this work, we propose an email visual similarity detection approach, named Pisco, to improve the detection capabilities of an email threat defense system. We apply our proof of concept to some real-world samples received from different sources. Our results show that email kits are being reused extensively and visually similar emails are sent to our customers at various time intervals. Therefore, this method could be very helpful in situations where detection engines that rely on textual features and keywords are bypassed, an occurrence our observations show happens frequently.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691381",
    "comment": ""
  },
  {
    "title": "Poster: Formalizing Cognitive Biases for Cybersecurity Defenses",
    "author": "Vang, Jasmine and Revelle, Matthew",
    "abstract": "As network attacks are becoming increasingly sophisticated, there is a need to develop new defense techniques. Recent work has demonstrated the successful use of cognitive biases to obstruct progress in network attacks by constructing scenarios which exploit biases in attackers. While informal definitions of many cognitive biases are well-established, the lack of definitions in a formal language limits the ability to construct scenarios in an automated fashion. This work proposes formal definitions using first-order logic to encapsulate the complex relationships between actions and biases.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691403",
    "comment": ""
  },
  {
    "title": "Poster: TAPChecker: Model Checking in Trigger-Action Rules Generation Using Large Language Models",
    "author": "Bui, Huan and Lienerth, Harper and Fu, Chenglong and Sridhar, Meera",
    "abstract": "The integration of large language models (LLMs) in smart home systems holds significant promise for automating the generation of Trigger-Action Programming (TAP) rules, potentially streamlining smart home user experiences and enhancing convenience. However, LLMs lack of holistic view of smart home IoT deployments and may introduce TAP rules that result in hazards. This paper explores the application of LLM for generating TAP rules and applying formal verification to validate and ensure the safety of TAP rules generated by LLMs. By systematically analyzing and verifying these rules, we aim to identify and mitigate potential security vulnerabilities. Furthermore, we propose a feedback mechanism to refine the LLM's output, enhancing its reliability and safety in generating automation rules. Through this approach, we seek to bridge the gap between the efficiency of LLMs and the stringent security requirements of smart IoT systems, fostering a safer automation environment.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691416",
    "comment": ""
  },
  {
    "title": "Poster: Gift or Curse? Safety Slider Settings in Tor Website Fingerprinting",
    "author": "Osher, Joel and Holland, James K. and Hopper, Nicholas",
    "abstract": "Website Fingerprinting (WF) attacks on the Tor anonymity network identify websites accessed via Tor by recognizing the traffic patterns -- sequences of packet directions and timing -- associated with accessing a particular site. Previous work has shown that modern WF attacks can function when trained and tested against consistent high or low settings of the Tor \"security slider,'' which impacts the traffic pattern produced by a download. In this work we show that training and testing against traces with a mixture of settings can improve the performance of WF attacks in some cases. Thus research seeking to evaluate WF defenses should consider both scenarios to ensure the most consistent evaluations.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691388",
    "comment": ""
  },
  {
    "title": "Poster: Detecting Ransomware Attacks by Analyzing Replicated Block Snapshots Using Neural Networks",
    "author": "Hong, Seok Min and Kim, Beom Heyn and Mannan, Mohammad",
    "abstract": "Cloud antivirus solutions address limitations of host-based malware detection such as extensive resource consumption. However, they remain vulnerable to sophisticated polymorphic and privileged malware. Also, existing solutions are not suitable to defend against destructive ransomware attacks. We propose an enhancement to existing cloud antivirus solutions that enables deep learning-based block snapshot analysis to detect evasive and privileged ransomware in virtualized environment without requiring any hardware support. Preliminary results validate the proposed approach.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691399",
    "comment": ""
  },
  {
    "title": "Poster: Multiparty Private Set Intersection from Multiparty Homomorphic Encryption",
    "author": "Mouchet, Christian and Chatel, Sylvain and N\\\"{u}rnberger, Lea and Lueks, Wouter",
    "abstract": "We revisit the problem of constructing protocols for multiparty private set intersection (MPSI) in light of the recent advances in multiparty homomorphic encryption (MHE). In MPSI, N ≥ 2 parties jointly compute the intersection of their respective private set. Kissner and Song proposed an MHE-based MPSI scheme in 2005, but their approach was limited by the then-available HE schemes. Today, however, MHE schemes have become both more versatile and more efficient. As an early result, we implemented the MPSI approach of Kissner et al. with the recently proposed Helium framework (CCS 2024) for MHE-based MPC. We show that even this simple protocol can outperform the state-of-the-art implementation (in the passive-adversary setting) by Kolesnikov et al. (CCS 2017), both in terms of latency and communication cost.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691405",
    "comment": ""
  },
  {
    "title": "Poster: Post-Quantum Identity-Based Matching Encryption with Revocable Decryption Key",
    "author": "Huang, Jheng-Jia and Chen, Guan-Yu and Lo, Nai-Wei",
    "abstract": "In recent years, scholars have developed Identity-Based Matching Encryption (IB-ME), which enables both the sender and the receiver to specify identities, ensuring ciphertext confidentiality only when these identities match. Building on this concept, our work introduces Revocable Identity-Based Matching Encryption (RIB-ME), which incorporates a revocable mechanism to withdraw decryption rights from unauthorized users. Current RIB-ME schemes rely on a variant of the Diffie-Hellman assumption, rendering it susceptible to quantum computing attacks. To address this vulnerability, we propose a generic construction of RIB-ME inspired by Wang et al. Our approach employs two-level Revocable Hierarchical Identity-Based Encryption (RHIBE) and Identity-Based Signature (IBS) and is compatible with post-quantum encryption schemes. This enables the development of a generic construction of RIB-ME and the creation of the first post-quantum RIB-ME through the use of post-quantum constructions.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691397",
    "comment": ""
  },
  {
    "title": "Poster: A Multi-step Approach for Classification of Malware Samples",
    "author": "Sgueglia, Arnaldo and Addabbo, Rocco and Di Sorbo, Andrea and Dashevskyi, Stanislav and Santos, Daniel dos and Visaggio, Corrado Aaron",
    "abstract": "The rapid spread of unknown malware has prompted many companies and researchers to improve their detection and classification systems. Cyber security companies must deal with the newest malware samples captured by their honeypots, aiming to analyze and classify them to develop several countermeasures. This process could only be feasible with a strong ground truth baseline; companies could only securely store the samples, waiting for further developments. This paper proposes a multi-step approach to support the classification process of unknown malware samples. Specifically, our approach first leverages well-known classification techniques and third-party services to collect as much information as possible about the samples and combines them with Machine Learning (ML)-based techniques to classify the remaining samples. Our case study, conducted on industrial data, shows how the combination offers superior performance than using each method individually.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691370",
    "comment": ""
  },
  {
    "title": "Poster: DoHunter: A feature fusion-based LLM for DoH tunnel detection",
    "author": "Diao, Jiawen and Zhao, Shengmin and Xie, Jianguo and Xie, Rongna and Shi, Guozhen",
    "abstract": "DNS over HTTPS (DoH) reduces the risk of privacy leakage of DNS queries, but it also provides a covert communication channel for malicious activities. In this paper, we propose a method for malicious encrypted traffic identification, which harnesses the advanced context comprehension of Large Language Model (LLM) and incorporates expert features to detect anomalies. The evaluation results show that the method proposed in this paper can not only identify common and emerging malicious DoH tunnel tools such as dns2tcp, iodine, and dnstt, but also identify weaponized DoH traffic within a real APT attack, with a recall of 0.9995.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691400",
    "comment": ""
  },
  {
    "title": "Poster: From Fort to Foe: The Threat of RCE in RPKI",
    "author": "Jacobsen, Oliver and Schulmann, Haya and Vogel, Niklas and Waidner, Michael",
    "abstract": "In this work, we present a novel severe buffer-overflow vulnerability in the RPKI validator Fort, that allows an attacker to achieve Remote Code Execution (RCE) on the machine running the software. We discuss the unique impact of this RCE on networks that use RPKI, illustrating that RCE vulnerabilities are especially severe in the context of RPKI. The design of RPKI makes RCE easy to exploit on a large scale, allows compromise of RPKI validation integrity, and enables a powerful vector for additional attacks on other critical components of the network, like the border routers. We analyze the vulnerability exposing to this RCE and identify indications that the discovered vulnerability could constitute an intentional backdoor to compromise systems running the software over a benign coding mistake. We disclosed the vulnerability, which has been assigned a CVE rated 9.8 critical (CVE-2024-45237).",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691387",
    "comment": ""
  },
  {
    "title": "Poster: Unmasking Label Errors: A need for Robust Cybersecurity Benchmarks",
    "author": "Malaviya, Shubham and Shukla, Manish and Anand, Saurabh and Lodha, Sachin",
    "abstract": "Cyber Threat Intelligence (CTI) utilizes information from various sources, necessitating high-quality labeled datasets for effective application of machine learning. Our study addresses the often-overlooked issue of labeling errors in cybersecurity benchmarks, resulting in the creation of D-LADDER++, a curated version of the recently published LADDER dataset. We evaluated the performance of both an open-source model (Microsoft Phi-3) and a closed-source model (Google Gemini) on D-LADDER++. We assessed their zero-shot and few-shot capabilities and fine-tuned the Phi-3 model for enhanced adaptability. Our assessment of the impact of test errors on model performance emphasizes the critical need for robust benchmarks in cybersecurity to ensure accurate model evaluation and selection.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691418",
    "comment": ""
  },
  {
    "title": "Poster: How Do Visually Impaired Users Navigate Accessibility Challenges in an Ad-Driven Web?",
    "author": "Amjad, Abdul Haddi and Gulzar, Muhammad Ali",
    "abstract": "Website accessibility is crucial for inclusiveness and regulatory compliance. While third-party advertisements (ads) are essential for funding free web services, they pose significant accessibility challenges. When developers lease space to ad-serving technologies like DoubleClick, they lose control over the accessibility of ad content. Even highly accessible websites can have their adherence to Web Content Accessibility Guidelines (WCAG) undermined by third-party ads. We conduct an investigation into the accessibility of ads across 430K website elements, including nearly 100K ad elements. Our study aims to evaluate the prevalence of inaccessible ads and their impact on overall website accessibility. Our findings reveal that 67\\% of websites experience increased accessibility violations due to ads, with common issues including Focus Visible (WCAG 2.4.7) and On Input (WCAG 3.2.2). Ad-serving technologies such as Taboola, DoubleClick, and RevContent frequently serve ads that do not meet WCAG standards. Inaccessible ads can significantly increase privacy risks for users with disabilities, as these ads may force them to engage with potentially unsafe or misleading content without proper accessibility features to protect their information.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691389",
    "comment": ""
  },
  {
    "title": "Poster: Automated Dependency Mapping for Web API Security Testing Using Large Language Models",
    "author": "Li, Wanpeng and Guo, Yuejun",
    "abstract": "Dependency extraction is crucial in web API security testing, as it helps identify the required API sequences to exploit a vulnerability. Traditional methods are generally rule-based and require extensive manual analysis of API specification documents by domain experts to formulate appropriate rules. This manual process is not only time-consuming and labor-intensive but also prone to missing dependencies and inaccuracies, which can compromise the effectiveness of security testing. In this paper, we explore the potential of large language models (LLMs) to automate dependency mapping in web APIs. By leveraging the capabilities of advanced LLMs such as GPT-3.5, Mistral-7B-Instruct, and Llama-3-8B-Instruct, which include understanding and generating natural language, we aim to streamline the dependency mapping process, reducing the need for manual analysis and enhancing accuracy. Our preliminary experiments demonstrate that this approach can effectively build dependency mappings, offering a a promising alternative to traditional rule-based approaches.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691377",
    "comment": ""
  },
  {
    "title": "Poster: Acoustic Side-Channel Attack on Robot Vacuums",
    "author": "Chen, Peter and Liu, Guannan and Wang, Haining",
    "abstract": "Robot vacuums have become a ubiquitous appliance, offering un- paralleled convenience and efficiency in maintaining cleanliness in both residential and commercial spaces. However, these devices also present a convenient method for attackers to gather information about the robot's surroundings. In this study, we investigate the feasibility of acoustic side-channel attacks on robot vacuums and demonstrate that sensitive information can be easily obtained by analyzing the sound produced by the robot. We extract various characteristic features and spectrograms from the sound emitted during robot movement and classify them using Multilayer Perception and Convolutional Neural Network. The evaluation results demonstrate the effectiveness of the acoustic attacks, with both machine learning models achieving more than 95\\% accuracy in classifying the robot's movement based on acoustic signals. Using our ML model, we demonstrate that robot cleaning path can be effectively identified with 96\\% accuracy. To mitigate such a threat, we perform a simulation where random noise is added to the sound samples, which effectively reduce the motion identification accuracy to 43\\%.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691372",
    "comment": ""
  },
  {
    "title": "Poster: Protecting Source Code Privacy When Hunting Bugs",
    "author": "Wu, Jielun and Shi, Qingkai",
    "abstract": "When proving to a third party that a software system is of high quality or bug-free, a software vendor may have to reveal the source code such that the third party can use a public or their own static code analyzer to check the code. However, revealing source code seriously damages the interests of software vendors as the source code often contains core technical details or even secrets. In this work, we propose a win-win solution that can help software vendors protect source code privacy to the greatest extent and, meanwhile, maximize the bug-detection capability of the third party. Our key idea is that a majority of source code information is not useful for bug detection. Thus, a software vendor only needs to reveal a little source code information --- a stripped binary together with minimal debug information (which is the carrier of source code information) --- to prove the software's quality. To realize this win-win solution, we propose an approach that minimizes critical debug information in a non-stripped binary while maintaining its positive impact on static bug detection. Evaluation results demonstrate that our approach can significantly reduce the size of debug information and retain only a minimal amount of source-level private information.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691407",
    "comment": ""
  },
  {
    "title": "Poster: Enhancing Network Traffic Analysis with Pre-trained Side-channel Feature Imputation",
    "author": "Zhao, Faqi and Ma, Duohe and Li, Wenhao and Liu, Feng and Wang, Wen",
    "abstract": "The recent advances in learning-based methodologies has underscored their efficacy in deducing patterns from the side-channel features of encrypted network traffic. Nonetheless, the distribution of these features has been identified as susceptible, particularly in the expansive and intricate network topologies characteristic of the modern Internet. The unpredictability of traffic bursts can result in packet loss during retransmission, thereby generating fragmented feature patterns. Unfortunately, current approaches struggle to adapt to such fragmented features, often leading to a substantial decline in performance. To surmount this challenge, this paper introduces a pre-training-based augmentation framework, denoted as N\\\"{u}wa, which imputes the side-channel features of encrypted network traffic. The crux of N\\\"{u}wa lies in its ability to reconstruct the side-channel features, with a particular focus on the temporal attributes of the missing packets within a traffic session. N\\\"{u}wa is comprised of a word-level Sequence2Embedding module, a Traffic Noise-based Self-supervised Pre-trained Masking Strategy, and a Traffic Side-Channel Feature Imputation Module. Experiments across four diverse real-world scenarios substantiate N\\\"{u}wa's capacity to restore the performance of prevalent temporal models while maintaining the integrity of the imputed features.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691401",
    "comment": ""
  },
  {
    "title": "Poster: Protection against Source Inference Attacks in Federated Learning using Unary Encoding and Shuffling",
    "author": "Athanasiou, Andreas and Jung, Kangsoo and Palamidessi, Catuscia",
    "abstract": "Federated Learning (FL) enables clients to train a joint model without disclosing their local data. Instead, they share their local model updates with a central server that moderates the process and creates a joint model. However, FL is susceptible to a series of privacy attacks. Recently, the source inference attack (SIA) has been proposed where an honest-but-curious central server tries to identify exactly which client owns a specific data record.In this work, we propose a defense against SIAs by using a trusted shuffler, without compromising the accuracy of the joint model. We employ a combination of unary encoding with shuffling, which can effectively blend all clients' model updates, preventing the central server from inferring information about each client's model update separately. In order to address the increased communication cost of unary encoding we employ quantization. Our preliminary experiments show promising results; the proposed mechanism notably decreases the accuracy of SIAs without compromising the accuracy of the joint model.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691411",
    "comment": ""
  },
  {
    "title": "Poster: FlashGuard: Real-time Disruption of Non-Price Flash Loan Attacks in DeFi",
    "author": "Alhaidari, Abdulrahman and Palanisamy, Balaji and Krishnamurthy, Prashant",
    "abstract": "Flash loan attacks threaten decentralized finance (DeFi) protocols, which constitute a Total Value Locked (TVL) of more than 106 billion. These attacks exploit the atomicity property in blockchains to drain funds within a single block. Existing research overlooks the mitigation of non-price flash loan attacks, which mostly exploit zero-day vulnerabilities. These attacks are challenging to detect as they are highly time-sensitive and each instance of the attack is complex and has a unique pattern. To address this challenge, we present FlashGuard, a runtime detection and mitigation framework for non-price flash loan attacks. FlashGuard communicates directly with the miners and bypasses the public mempool, where attack transactions usually reside. We utilize the temporary time window where transactions are visible in the mempool but not yet confirmed. Once the attack is detected, FlashGuard dispatches a dusting counter-transaction for the victim contract to the miners directly within the same block to disrupt the attack's atomicity and change the smart contract state. This forces the malicious transaction to revert. FlashGuard ensures that the series of operations that are required for a non-price flash loan attack cannot be completed atomically, leading to a failure of the attack. Our evaluation using 20 historical attacks that exploited protocol vulnerabilities shows an outstanding detection rate for FlashGuard with minimal false positives, and effective attack disruption and indicates that FlashGuard could have rescued about $405.71 million in losses.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691385",
    "comment": ""
  },
  {
    "title": "Poster: Analyzing and Correcting Inaccurate CVE-CWE Mappings in the National Vulnerability Database",
    "author": "\\c{S}im\\c{s}ek, \\c{S}evval and Shi, Zhenpeng and Xia, Howell and Medina, David Sastre and Starobinski, David",
    "abstract": "We conduct a longitudinal study of the National Vulnerability Database (NVD), focusing on the mappings between vulnerabilities (CVEs) and weaknesses (CWEs). Surprisingly, the study reveals that a significant portion of CVEs, fluctuating between 15\\% and 30\\% over the years, lack proper CWE mapping, and that almost 40\\% of the updates are non-informative. We introduce a methodology, based on knowledge graphs, for automating root cause weakness mapping for CVEs and for fixing existing inaccurate mappings. We showcase promising preliminary results toward this end.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691375",
    "comment": ""
  },
  {
    "title": "Poster: Solving the Free-rider Problem in Bittensor",
    "author": "Liu, Sin Tai and Yu, Jiayuan and Steeves, Jacob",
    "abstract": "The design and operation of https://bittensor.com/ Bittensor is a decentralized and anonymous system where actors are incentivized by rewards to provide utilities. To ensure that it is a fair game, utilities obtained by copying other participants should be identified and punished. Our first contribution is to apply a commitment scheme to address this free-rider problem. Under appropriate conditions, we show theoretically and empirically that a commitment scheme dissuades copying by reducing the rewards to the copier. In particular, this dissuasive power is a function of the duration between the commit- and reveal-steps. Our second contribution is to propose the liquid alpha solution to amplify the effect of the commitment scheme.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691414",
    "comment": ""
  },
  {
    "title": "Poster: BlindMarket: A Trustworthy Chip Designs Marketplace for IP Vendors and Users",
    "author": "Liu, Zhaoxiang and Luo, Ning and Judson, Samuel and Dutta, Raj Gautam and Guo, Xiaolong and Santolucito, Mark",
    "abstract": "Due to the globalization of the semiconductor supply chain, chip fabrication now involves multiple parties, including intellectual property (IP) vendors and Electronic Design Automation (EDA) tool vendors. Involving multiple entities and valuable IP naturally raises security and privacy concerns. Various frameworks and tools, such as the IEEE 1735 standard for IP protection, have been developed to mitigate the risk of theft. However, existing solutions fail to address all the threats envisioned by the zero-trust model. We propose a novel zero-trust formal verification framework that requires only two essential parties: IP users and IP vendors. This framework leverages secure multiparty computation to ensure the security and privacy of the hardware verification process. Our proposed solution allows IP users and IP vendors to independently convert the hardware design and assertions into conjunctive normal form (CNF), and then apply privacy-preserving SAT solving to verify the conformance of the design to the specification. This paper introduces a domain-specific secure decision procedure, hw-ppSAT, designed to overcome the scalability challenges of using SAT solving in hardware design verification. Our approach also leverages property-based hardware optimizations and domain-specific heuristics to enhance the verification process. We showcase the framework's effectiveness through its application to several open-source benchmarks.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691378",
    "comment": ""
  },
  {
    "title": "Poster: Security and Privacy Heterogeneous Environment for Reproducible Experimentation (SPHERE)",
    "author": "Mirkovic, Jelena and Balenson, David and Kocoloski, Brian and Lawler, Geoff and Tran, Chris and Barnes, Joseph and Pradkin, Yuri and Benzel, Terry and Ravi, Srivatsan and Sankaran, Ganesh and Regalado, Alba and Choffnes, David and Dubois, Daniel and Garcia, Luis",
    "abstract": "To transform cybersecurity and privacy research into a highly integrated, community-wide effort, researchers need a common, rich, representative research infrastructure that meets the needs across all members of the research community and facilitates reproducible science. USC Information Sciences Institute and Northeastern University are meeting researcher needs and have been funded by the NSF mid-scale research infrastructure program to build Security and Privacy Heterogeneous Environment for Reproducible Experimentation (SPHERE). SPHERE research infrastructure will offer access to an unprecedented variety of user-configurable hardware, software, and network resources, it will offer six user portals geared toward different populations of users, and it will support reproducible research via a combination of infrastructure services and community engagement activities.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691409",
    "comment": ""
  },
  {
    "title": "Poster: Advanced Features for Real-Time Website Fingerprinting Attacks on Tor",
    "author": "Kim, Donghoon and Booth, Andrew and Choo, Euijin and Hwang, Doosung",
    "abstract": "The Tor network has been identified as vulnerable to website fingerprinting (WF) attacks. Existing WF attacks have proven effective against the Tor network. However, prior research has mostly been limited to controlled experimental settings, leading to questions about the practicality of WF attacks in real-time environments. Recent advancements in feature engineering and machine learning aim to address this by exploring real-world scenarios, though they often overlook the preprocessing time required to design features from raw network traffic data. To tackle these issues, this research focuses on developing more efficient and high-performing feature vectors for WF attacks in real-time by analyzing previously successful feature vectors. The results indicate that advanced features, particularly those in a compact feature set, deliver competitive performance with reduced training times for real-time WF attacks. This study enhances our understanding of the feasibility of real-time WF attacks on Tor networks in practical settings and may inform future security improvements.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691373",
    "comment": ""
  },
  {
    "title": "Poster: Byzantine Discrepancy Attacks against Calendar, Set-intersection and Nations",
    "author": "Desmedt, Yvo and Kavousi, Alireza and Abadi, Aydin",
    "abstract": "Nowadays Communication Security usually refers to digital communication and in particular via the Internet. We explain why the topic should be broadened to include any communication, in particular when done in person, e.g., with co-authors, colleagues, reporters, etc. Thousands of papers have been written on blockchain, and consensus. Despite this, the problem of Byzantine attack has been ignored in some important apps! One of these examples is (Outlook) Calendar. Moreover, the Byzantine attack can also be used in the political world. We explain how using it may undermine the security of nations. Finally, we observe that topics on which a lot of research has been done, such as Private Set Intersection have ignored the problem of Byzantine attacks.Although the Byzantine general problem is typically described in a peer-to-peer setting, we show that it can also occur in other scenarios.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691379",
    "comment": ""
  },
  {
    "title": "Poster: Enhance Hardware Domain Specific Large Language Model with Reinforcement Learning for Resilience",
    "author": "Fu, Weimin and Zhao, Yifang and Jin, Yier and Guo, Xiaolong",
    "abstract": "To enhance the performance of large language models (LLMs) on hardware design tasks, we focus on training with reinforcement learning(RL) to improve LLMs' syntax synthesis and functional verification performance. We observed significant gains in power, performance, and area (PPA) metrics by applying RL. Specifically, DeepSeek Code saw a 23.6\\% performance increase, while the RTLCoder improved by 7.86\\%. Our findings demonstrate the effectiveness of RL in refining LLMs for more accurate hardware generation, considering power and area consumption. This approach offers a promising direction for generating hardware resilient to side-channel attacks in computer systems.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691384",
    "comment": ""
  },
  {
    "title": "Poster: PGPNet: Classify APT Malware Using Prediction-Guided Prototype Network",
    "author": "Bao, Huaifeng and Li, Wenhao and Li, Zhaoxuan and Miao, Han and Wang, Wen and Liu, Feng",
    "abstract": "As the popularity of Advanced Persistent Threat (APT) grows, APT malware group classification has attracted more attention recently. However, most of previous methods use simple classifiers for group classification, ignoring the bias caused by the sparse number of revealed malware and the differences in functionality distribution of most groups. In this paper, we propose a Prediction-Guided Prototype Network (PGPNet) that could quickly adapt to new classification tasks with limited supervised samples based on the meta-learning architecture. Adding malware functionality classification as an auxiliary task is beneficial for feature learning, and the bias of distribution differences is eliminated by intervening the predicted results into the group classifier. Experimental results on a APT malware dataset show that PGPNet successfully exploits the contextual information and predictions of the auxiliary task and achieves state-of-the-art performance.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691396",
    "comment": ""
  },
  {
    "title": "Poster: Context-Based Effective Password Detection in Plaintext",
    "author": "Shukla, Manish and Malaviya, Shubham and Lodha, Sachin",
    "abstract": "From an enterprise perspective, storage of passwords in plaintext on a computer hard disk is a serious concern. Such password storage practice helps a malicious agent to do privilege escalation, install a backdoor, disable critical monitoring tools, and allow them to laterally move within organization's network. Considering the exploitability of the plaintext password stored on a storage device, it is imperative for an organization to identify such files and safeguard them without causing disruption to a user's work routine. In this work, we present a context-based password discovery solution for plaintext that performs multi-step context discovery for reducing false positives and negatives. Moreover, we protect all the identified files using an on-the-fly user authentication layer, which helps in preventing automated or command-line-based access to sensitive content in case of a cyberattack.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691380",
    "comment": ""
  },
  {
    "title": "Poster: A Secure Multiparty Computation Platform for Squeaky-Clean Data Rooms",
    "author": "Dayama, Pankaj and Pandit, Vinayaka and Patranabis, Sikhar and Singh, Abhishek and Singh, Nitin",
    "abstract": "Modern approaches for multiparty secure collaboration must strike the right balance between rich analytics and requisite data privacy guarantees, especially in the face of new regulations. While cryptographic technologies such as fully homomorphic encryption (FHE) and secure multiparty computation (MPC) provide strong, provable security guarantees as standalone tools, deploying them in practice throws up a myriad of challenges, including usability constraints and lack of precise specification of privacy guarantees. In this work, we propose a novel framework for real-world deployment of cryptographic privacy preserving techniques that achieves the twin goals of practical usability in real-world setting and provable privacy guarantees from users' perspective. To this end, we formalize the notion of a secure computation platform (SCP) for privacy preserving data collaboration, and introduce a model for precise specification of privacy guarantees for multiparty workflows. We then describe abstractions of a set of cryptoprimitives, that are usable by non-experts in cryptography. We present two demo workflows that empirically validate our claims, and serve as potential building blocks for the development of squeaky-clean data rooms with practical performance and privacy guarantees.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691371",
    "comment": ""
  },
  {
    "title": "Demo: Enhancing Smart Contract Security Comprehensively through Dynamic Symbolic Execution",
    "author": "Li, Zhaoxuan and Zhao, Ziming and Li, Wenhao and Zhang, Rui and Xue, Rui and Lu, Siqi and Zhang, Fan",
    "abstract": "The frequent security incidents of contracts indicate a pressing need to ensure contract security from deployment to running stages, but the state-of-the-art (SOTA) analysis methods cannot work well for three requirements. (i) Identify contract defective code snippets, while generating exploit call sequences to help developers fix them. (ii) Monitor abnormal call behaviors, especially for multiple continuous transactions. (iii) Validate numerous unexploitable detection results automatically because manual verification is labor-intensive. (iv) To tackle these problems, we propose SymX, a symbolic execution-based security analysis art accounting for contract development and running stages. The experiment results demonstrate that it can accurately identify 90.22\\% of contracts and 98.04\\% of call transactions, as well as validate misreports as intended, which is superior to SOTAs, thereby protecting contracts better during the contract lifecycle. Currently, SymX is available at https://github.com/Secbrain/SymX.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691365",
    "comment": ""
  },
  {
    "title": "Demo: FT-PrivacyScore: Personalized Privacy Scoring Service for Machine Learning Participation",
    "author": "Gu, Yuechun and He, Jiajie and Chen, Keke",
    "abstract": "Data privacy has been a top concern in the AI era. Despite the recent development of differentially private learning methods, controlled data access remains a mainstream method for protecting data privacy in many industrial and research environments. In controlled data access, authorized model builders work in a restricted environment to access sensitive data, which can fully preserve data utility with reduced risk of data leak. However, unlike differential privacy, there is no quantitative measure for individual data contributors to tell their privacy risk before participating in a machine learning task. We developed the demo prototype FT-PrivacyScore to show that it's possible to efficiently and quantitatively estimate the privacy risk of participating in a model fine-tuning task. The demo source code will be available at https://github.com/RhincodonE/demo_privacy_scoring.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691366",
    "comment": ""
  },
  {
    "title": "Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code",
    "author": "Ton, Khiem and Nguyen, Nhi and Nazzal, Mahmoud and Khreishah, Abdallah and Borcea, Cristian and Phan, NhatHai and Jin, Ruoming and Khalil, Issa and Shen, Yelong",
    "abstract": "This paper introduces SGCode, a flexible prompt-optimizing system to generate secure code with large language models (LLMs). SGCode integrates recent prompt-optimization approaches with LLMs in a unified system accessible through front-end and back-end APIs, enabling users to 1) generate secure code, which is free of vulnerabilities, 2) review and share security analysis, and 3) easily switch from one prompt optimization approach to another, while providing insights on model and system performance. We populated SGCode on an AWS server with PromSec, an approach that optimizes prompts by combining an LLM and security tools with a lightweight generative adversarial graph neural network to detect and fix security vulnerabilities in the generated code. Extensive experiments show that SGCode is practical as a public tool to gain insights into the trade-offs between model utility, secure code generation, and system cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is available at: http://3.131.141.63:8501/.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691367",
    "comment": ""
  },
  {
    "title": "Demo: Towards Reproducible Evaluations of ML-Based IDS Using Data-Driven Approaches",
    "author": "Ayoubi, Solayman and Tixeuil, S\\'{e}bastien and Blanc, Gregory and Jmila, Houda",
    "abstract": "Network-based Intrusion Detection Systems (NIDS) are crucial in cybersecurity, but evaluation methodologies are outdated and lack standardization, resulting in incomplete and unreliable assessments. To address these issues, we first proposed a comprehensive evaluation framework for Machine Learning-based Intrusion Detection Systems [1]. This framework accounts for the unique aspects, strengths, and weaknesses of ML algorithms. However, the initial proposition lacked practicality, as it presented an abstract methodology without a substantive solution. In this paper, we present a demo of FREIDA a precise and concrete implementation of our framework, featuring an easy-to-use graphical interface. We also outline FREIDA's evaluation methodology and demonstrate its application in evaluating IDS using a dataset from the literature.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691368",
    "comment": ""
  },
  {
    "title": "Demo: An End-to-End Anonymous Traffic Analysis System",
    "author": "Xianglan, Huang and Qiang, Zhou and Liangmin, Wang and Weiqi, Yu and Wenjin, Wang and Shi, Shen",
    "abstract": "Network crimes committed through anonymous networks pose significant challenges to regulators. Identifying different types of traffic and implementing effective supervision are crucial for maintaining network security. In this demo, we present an end-to-end anonymous traffic analysis system that integrates traffic capturing, protocol parsing, feature extraction, traffic classification, and analysis result presentation, enabling comprehensive analysis of traffic on routers from end to end. Our system can be deployed on the data center network to capture network traffic routed by the routers. It automatically analyzes Tor network traffic, HTTPS encrypted traffic, and Tor network App traffic, identifies the target website or App type associated with the traffic, and displays the identification results via the visual interface.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3691364",
    "comment": ""
  },
  {
    "title": "ACM CCS 2024 Doctoral Symposium",
    "author": "Ciocarlie, Gabriela and Ou, Xinming",
    "abstract": "ACM CCS started Doctoral Symposium in 2024 to provide PhD students who are in the middle of their dissertation research an opportunity to present their work to the broader research community and get feedback. We briefly describe the design of the first CCS Doctoral Symposium, the rationale, and the submission/acceptance status.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3698218",
    "comment": ""
  },
  {
    "title": "Trusted Execution Environments for Quantum Computers",
    "author": "Trochatos, Theodoros",
    "abstract": "The cloud-based environments in which today's and future quantum computers will operate, raise concerns about the security and privacy of user's intellectual property. Quantum circuits submitted to cloud-based quantum computer providers represent sensitive or proprietary algorithms developed by users that need protection. Further, input data is hard-coded into the circuits and leakage of the circuits can expose users' data. Although still in the Noisy Intermediate Scale Quantum regime, quantum computers hold promise to be able to execute novel algorithms and create invaluable data. However, just as with any other type of computing resource, they may be vulnerable to security attacks and should have defenses built into their hardware and software design. \\% In classical computing, a Trusted Execution Environment (TEE) is an area on the main processor of a device that is separated from the system's main operating system, which ensures data is stored, processed and protected in a secure environment. Similar to the classical computing, by leveraging trusted hardware, we propose Trusted Execution Environments for quantum computers. The proposed thesis will explore the feasibility and the security of the quantum computer Trusted Execution Environment architecture as a novel security primitive. In this prospectus, the challenges and approaches are outlined, current results are presented to show the feasibility of the proposed work and a timeline of future work is given.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690855",
    "comment": ""
  },
  {
    "title": "Towards Secure Runtime Auditing of Remote Embedded System Software",
    "author": "Caulfield, Adam",
    "abstract": "Low-cost and energy-efficient microcontroller units (MCUs) increasingly perform critical tasks at the edge of modern systems despite their inherent vulnerabilities. To assess their security in remote deployments, Control Flow Attestation (CFA) offers a technique for a Verifier (Vrf) to remotely detect attacks that illegally alter the software or the runtime behavior of a Prover MCU (Prv) by producing a log of all control flow transfers during task execution (CFLog). Current CFA techniques cannot ensure Vrf receives CFLog from a compromised Prv, allowing it to ignore CFA requests and preventing Vrf vulnerability analysis. This dissertation proposal introduces architectures to achieve runtime auditing, guaranteeing the delivery of runtime evidence and enabling Vrf to remediate detected compromises. The first approach uses a hardware-software co-design, and the second approach leverages Trusted Execution Environments (TEEs) to provide the same guarantees without hardware modifications. Future work will focus on further challenges, such as enabling application-specific storage/latency optimizations and automated vulnerability analysis of runtime evidence.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690856",
    "comment": ""
  },
  {
    "title": "Understanding and Addressing Online Tracking: Online Privacy's Regulatory Turn",
    "author": "Reitinger, Nathan",
    "abstract": "Computing and storage breakthroughs over the last few decades have given rise to online tracking abilities that outpace current-day privacy-enhancing tools, social norms, and privacy regulations. Users lack the tools they need to block the types of tracking they cannot see and have very little control over; data stewards (i.e., companies processing user data) lack an understanding of what types of tracking practices users find normatively problematic; and policymakers lack effective feedback on real-world implementations of the data-focused or tracking-adjacent laws they are drafting-at a time when these regulations are in their infancy and feedback is crucial. Users should be able to navigate the web without falling victim to surreptitious tracking technologies; companies should be aware of what types of tracking users find most problematic; and legislators should be able to rely on empirically driven measurement studies to help them understand where the law falls short and where companies need help. My dissertation work focuses on improving online privacy by developing tracker-blocking tools, investigating user perceptions of online tracking, and systematizing knowledge as it relates to the measurement of statutory instruments. I focus here on the last, in-progress piece: a systematization of the measurement of legal compliance-helping researchers produce measurements that are compelling, ethical, and legally robust.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690857",
    "comment": ""
  },
  {
    "title": "Catch Me if You Can: Detecting Unauthorized Data Use in Training Deep Learning Models",
    "author": "Chen, Zitao",
    "abstract": "The rise of deep learning (DL) has led to a surging demand for training data, which incentivizes the creators of DL models to trawl through the Internet for training materials. Meanwhile, users often have limited control over whether their data (e.g., facial images) are used to train DL models without their consent, which has engendered pressing concerns.In this work, we propose a technique that can support ordinary users to detect the unauthorized use of their data in training DL models. Our work is built upon membership inference (MI) attacks, a prominent class of attacks that aim to infer whether a sample was used to train the model, and it is known that the ability to perform accurate MI on a specific sample is directly related to how well the model memorizes it.Therefore, our idea is to guide the users to inject a small amount of targeted changes to their own data, which can be strongly memorized by the model trained on them. The users can then perform MI to detect whether the suspect model exhibits strong memorization effect on their specially-marked data. Preliminary results illustrate that our technique is able to support the users to reliably trace the provenance of their data with high true positive rate and low false positive rate.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690858",
    "comment": ""
  },
  {
    "title": "Evolving Network Security in the Era of Network Programmability",
    "author": "Chen, Mingming",
    "abstract": "Software-defined networking (SDN) is a centralized network architecture enabling dynamic, programmable, and flexible network management, which advances technologies like network security. However, it also introduces new vulnerabilities due to the segregation of data, control, and application planes, creating additional attack surfaces and security gaps from the increased complexity of programmability, flexibility, and scalability.To empower network security with SDN, we develop a coordinated sampling strategy using P4 programming for adaptive network monitoring. Additionally, we uncover a flow entry-induced topology poisoning attack to highlight security gaps from unplanned module integration. Finally, we propose to fortify the SDN control plane by generalizing SDN security policies and fuzzing it to uncover unknown vulnerabilities.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690859",
    "comment": ""
  },
  {
    "title": "Symbolic Execution for Dynamic Kernel Analysis",
    "author": "Pitigalaarachchi, Pansilu",
    "abstract": "Linux kernel-based operating systems have a significant market share in the domains of enterprise/web servers, supercomputers, and mobile devices. Being a large open-source project, the Linux kernel undergoes many changes, with new functionalities (e.g. Support for Rust in the kernel) being added in each release. While the security analysis of the Linux kernel is of critical importance, it is a challenging task. Although symbolic execution based techniques have been used for kernel analysis in the past decade, existing tools have fundamental limitations in kernel thread analysis, such as the need for instrumentation of the target kernel and the lack of user control, command, and access to the target execution. This dissertation aims to address these limitations by proposing a new kernel symbolic execution engine for kernel thread analysis. We then intend to leverage the new engine to conduct a security analysis of Rust drivers written for the Linux kernel. As part of the analysis, we will perform symbolic execution on Rust drivers, detect bugs, and evaluate whether the integration of Rust drivers with the rest of the kernel, written in C, results in any security vulnerabilities.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690860",
    "comment": ""
  },
  {
    "title": "Toward Practical Threshold FHE: Low Communication, Computation and Interaction",
    "author": "Choe, Hyeongmin",
    "abstract": "Fully Homomorphic Encryption (FHE) is a promising primitive for evaluating arbitrary circuits while maintaining the user's privacy with an optimal round of communications. However, extending FHE to Threshold FHE and transitioning from two-party to multi-party settings presents some challenges, such as distributed key generation or decryption. When focusing on distributed decryption, it requires an exponentially large ciphertext modulus, which degrades communication efficiency. In this PhD thesis research description, we explore possible solutions using polynomially large ciphertext modulus. As the first approach, we introduce a construction simpler than that of Boudgoust and Scholl [Asiacrypt'23] in the same setting, assuming the circuit privacy, which is challenging to achieve with polynomially large modulus in practice. We then introduce a new approach with additional communication rounds for distributed decryption using Multi-Party Computations (MPC). It can be viewed as a trade-off between the general multi-round MPC and the round-optimal Threshold FHEs but with a polynomially large ciphertext modulus rather than the exponentially large modulus. While keeping the round optimality for the homomorphic evaluations, the computation result can be obtained via a constant-round distributed decryption, regardless of the function to be evaluated.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690861",
    "comment": ""
  },
  {
    "title": "Privacy Analyses in Machine Learning",
    "author": "Ye, Jiayuan",
    "abstract": "Machine learning models sometimes memorize sensitive training data features, posing privacy risks. To control such privacy risks, Dwork et al. proposed the definition of differential privacy (DP) to measure the privacy risks of an algorithm. However, existing DP models either have significantly lower accuracy than their non-private variants or are computationally expensive to train by requiring to incorporate a large amount of public prior knowledge in terms of data or a large pre-trained model. Thus, the fundamental problem of efficiently training an accurate model while preserving DP is not fully addressed. To tackle this problem, we investigate the potential of improving privacy analysis of machine learning algorithms, thus subsequently allowing improved privacy-utility trade-off. First, we observe that the standard DP bound is not tight for large, overparameterized models. Specifically, the DP bound worsens with the number of iterations, and the privacy-accuracy trade-off worsens with the model dimension. This is despite the algorithm converging during training and the finite dimension of training data space. Such potential untightness is more severe for a realistic adversary that does not observe all model parameters, where prior works suggest empirical privacy amplification, and we investigate theoretically. Finally, we take a close look at the privacy risk of each model prediction about individual training data and analyze how to attribute privacy risk to the properties of the data and the choice of model (e.g., architectures). If successful, our research would enable tighter and more informative privacy bounds for differentially private learning, thus in turn allowing improved privacy-utility trade-offs.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690862",
    "comment": ""
  },
  {
    "title": "Novel Privacy Attacks and Defenses Against Neural Networks",
    "author": "Dibbo, Sayanton V.",
    "abstract": "This dissertation comprises five papers that focus on a novel paradigm of privacy attack, i.e., model inversion (MI) attack, where the adversarial goal is to infer or reconstruct training samples. In particular, these works are aligned with investigating MI privacy attacks, designing novel realistic MI attacks under restricted realistic capabilities, and introducing novel robust defense techniques against these attacks. At first, we focus on the systematization of MI attacks from the literature review (IEEE CSF). This opened up ways to investigate MI attacks on the tabular dataset. We developed novel MI attacks for inferring sensitive private training data, published in USENIX Security. Then, we worked on exploring MI attacks with limited adversarial capabilities (IEEE SaTML), i.e., when adversaries do not have access to the same data distributions as model training data. All these streams of work on privacy attack designing enabled the design of novel defenses against MI attacks. We have developed a novel sparse coding architecture (SCA), which shows 1.1-18.3 times more robustness against MI attacks while not significantly compromising model accuracy. This exciting work has just been published at ECCV 2024 this year and inspires us to improve the defense further by designing systematic techniques to drop highly sensitive features during training that can also provide provable privacy bounds.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690863",
    "comment": ""
  },
  {
    "title": "Leveraging Storage Semantics to Enhance Data Security and Privacy",
    "author": "Zhu, Weidong",
    "abstract": "Data within a system travels through an I/O path from its generation in an application to its final storage on a device. Ensuring data security and privacy is a significant design concern, but heavily modulated storage stacks complicate understanding the data, thus presenting challenges to maintaining these properties. For example, the firmware in a storage device cannot interpret the semantics of an I/O request from the host, making it challenging to employ a semantic-aware malware defense in the storage device. Additionally, the evolution of storage media can weaken data privacy protection guarantees due to varying physical characteristics. Preserving the guarantee of data security and privacy requires understanding storage semantics, which provides insights into the data content and the architectural components within the storage system.This thesis characterizes security and privacy weaknesses in the I/O path while proposing solutions to advance data security and privacy by leveraging storage semantics. We correlate I/O requests with their semantic attributes to facilitate data security. We also demonstrate how these requests can mitigate vulnerabilities found in previous privacy-preserving storage solutions by considering the knowledge of physical storage devices. We show that data security and privacy can be vastly improved by identifying security vulnerabilities and developing new security mechanisms based on storage semantics.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690864",
    "comment": ""
  },
  {
    "title": "Securing Cyber-Physical Systems via Advanced Cyber Threat Intelligence Methods",
    "author": "L\\'{o}pez-Morales, Efr\\'{e}n",
    "abstract": "Many services that make our modern society work, such as communications and transportation, are only possible thanks to Cyber-Physical Systems (CPS). This makes CPS the target of cyberattacks that aim to disrupt our society. One tool that we can leverage to protect CPS is Cyber Threat Intelligence (CTI). CTI is threat information that helps us understand a threat actor's techniques. However, current CTI on CPS is limited as current methods cannot collect and analyze data on the latest cyberattacks against CPS. In this dissertation research description, we address this problem by developing three new methods that advance the state-of-the-art CTI of three different CPS: Industrial Control Systems (ICS), Satellites, and Connected Autonomous Vehicles (CAV). The first research project involves the development of a novel threat taxonomy for programmable logic controllers (PLCs), which are a key part of ICS. The second project is the development of a satellite honeypot to collect data on adversaries' techniques. The third and final project involves the development of a CAV sandbox that allows us to test cyberattacks on CAVs to collect raw threat intelligence.Our preliminary results include a novel ICS threat matrix and a high-interaction satellite honeypot in the literature, which pushes the state of the art of CTI for CPS forward.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690865",
    "comment": ""
  },
  {
    "title": "Language-based Sandboxing",
    "author": "Zhang, Jialun",
    "abstract": "Existing sandboxing techniques require a lot of manual efforts in retrofitting legacy programs and do not provide a unified framework for reasoning about whole-program properties. To address these issues, we propose a language-based approach that makes sandbox a first-class concept in the language. The composability of sandboxes with other language features can enable programmers to do faster compartmentalization and end-to-end reasoning of safety properties.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690866",
    "comment": ""
  },
  {
    "title": "Privacy-Preserving Graph Analysis",
    "author": "Raj Gopal, Bhavish",
    "abstract": "Graphs are a fundamental tool for modelling data in diverse real-world applications such as communication networks, traffic systems, and social networks. However, graph data is often distributed across multiple data owners and contains sensitive information, posing significant privacy concerns that impede collaborative analysis. This research aims to overcome these challenges by developing privacy-preserving solutions for graph analysis using the technique of secure multiparty computation (MPC). We review existing MPC-based approaches for privacy-preserving graph analysis, identifying their limitations in efficiency, scalability and adaptability. Furthermore, we present our results in enhancing privacy-preserving graph analysis and highlight the remaining challenges. We discuss potential strategies to overcome these challenges, including designing efficient primitives, leveraging different computational settings, and incorporating hardware accelerations to improve performance. Through these advancements, our research aims to make secure graph analysis both practical and widely applicable, ensuring privacy while enabling valuable insights from distributed graph data.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690867",
    "comment": ""
  },
  {
    "title": "Towards Proactive Protection against Unauthorized Speech Synthesis",
    "author": "Yu, Zhiyuan",
    "abstract": "The rapid advancement of artificial speech synthesis technologies, fueled by generative AI (GenAI), presents both opportunities and potential threats to society. While offering unprecedented opportunities, these technologies have been exploited to create \"DeepFake\" speech for fraud, impersonation, and spreading disinformation, as evidenced by recent real-world incidents. Our research aims to address such emerging threats by exploring a novel, proactive approach to disrupt unauthorized speech synthesis.Grounded in adversarial robustness theories, the core defense strategy is to embed imperceptible \"voice cloaks\" into users' speech. These perturbations are designed to prevent accurate voice cloning when used in unauthorized synthesis processes. This concept has been realized and validated in our preliminary work, AntiFake, demonstrating the initial feasibility. Building on these foundations, we propose a line of research that seeks to understand the fundamental three-way trade-off across protection generalizability, audio quality, and computational efficiency, and further achieve balanced improvements across these dimensions.",
    "year": "2024",
    "publication": "ccs",
    "link": "https://doi.org/10.1145/3658644.3690868",
    "comment": ""
  }
]