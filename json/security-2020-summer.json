[
  {
    "title": "Understanding security mistakes developers make: Qualitative analysis from Build It, Break It, Fix It",
    "abstract": "Abstract:Secure software development is a challenging task requiring consideration of many possible threats and mitigations. This paper investigates how and why programmers, despite a baseline of security experience, make security-relevant errors. To do this, we conducted an in-depth analysis of 94 submissions to a secure-programming contest designed to mimic real-world constraints: correctness, performance, and security. In addition to writing secure code, participants were asked to search for vulnerabilities in other teams’ programs; in total, teams submitted 866 exploits against the submissions we considered. Over an intensive six-month period, we used iterative open coding to manually, but systematically, characterize each submitted project and vulnerability (including vulnerabilities we identified ourselves). We labeled vulnerabilities by type, attacker control allowed, and ease of exploitation, and projects according to security implementation strategy. Several patterns emerged. For example, simple mistakes were least common: only 21% of projects introduced such an error. Conversely, vulnerabilities arising from a misunderstanding of security concepts were significantly more common, appearing in 78% of projects. Our results have implications for improving secure-programming APIs, API documentation, vulnerability-finding tools, and security education.",
    "author": "Authors:Daniel Votipka, Kelsey R. Fulton, James Parker, Matthew Hou, Michelle L. Mazurek, and Michael Hicks,University of MarylandDistinguished Paper Award Winner",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/votipka-understanding",
    "comment": ""
  },
  {
    "title": "Montage: A Neural Network Language Model-Guided JavaScript Engine Fuzzer",
    "abstract": "Abstract:JavaScript (JS) engine vulnerabilities pose significant security threats affecting billions of web browsers. While fuzzing is a prevalent technique for finding such vulnerabilities, there have been few studies that leverage the recent advances in neural network language models (NNLMs). In this paper, we present Montage, the first NNLM-guided fuzzer for finding JS engine vulnerabilities. The key aspect of our technique is to transform a JS abstract syntax tree (AST) into a sequence of AST subtrees that can directly train prevailing NNLMs. We demonstrate that Montage is capable of generating valid JS tests, and show that it outperforms previous studies in terms of finding vulnerabilities. Montage found 37 real-world bugs, including three CVEs, in the latest JS engines, demonstrating its efficacy in finding JS engine bugs.",
    "author": "Authors:Suyoung Lee, HyungSeok Han, Sang Kil Cha, and Sooel Son,KAIST",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/lee-suyoung",
    "comment": ""
  },
  {
    "title": "Big Numbers - Big Troubles: Systematically Analyzing Nonce Leakage in (EC)DSA Implementations",
    "abstract": "Abstract:Side-channel attacks exploiting (EC)DSA nonce leakage easily lead to full key recovery. Although (EC)DSA implementations have already been hardened against side-channel leakage using the constant-time paradigm, the long-standing cat-and-mouse-game of attacks and patches continues. In particular, current code review is prone to miss less obvious side channels hidden deeply in the call stack. To solve this problem, a systematic study of nonce leakage is necessary. We present a systematic analysis of nonce leakage in cryptographic implementations. In particular, we expand DATA, an open-source side-channel analysis framework, to detect nonce leakage. Our analysis identified multiple unknown nonce leakage vulnerabilities across all essential computation steps involving nonces. Among others, we uncover inherent problems in Bignumber implementations that break claimed constant-time guarantees of (EC)DSA implementations if secrets are close to a word boundary. We found that lazy resizing of Bignumbers in OpenSSL and LibreSSL yields a highly accurate and easily exploitable side channel, which has been acknowledged with two CVEs. Surprisingly, we also found a tiny but expressive leakage in the constant-time scalar multiplication of OpenSSL and BoringSSL. Moreover, in the process of reporting and patching, we identified newly introduced leakage with the support of our tool, thus preventing another attack-patch cycle. We open-source our tool, together with an intuitive graphical user interface we developed.",
    "author": "Authors:Samuel Weiser, David Schrammel, and Lukas Bodner,Graz University of Technology;Raphael Spreitzer,SGS Digital Trust Services",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/weiser",
    "comment": ""
  },
  {
    "title": "(Mostly) Exitless VM Protection from Untrusted Hypervisor through Disaggregated Nested Virtualization",
    "abstract": "Abstract:Today’s cloud tenants are facing severe security threats such as compromised hypervisors, which forces a strong adversary model where the hypervisor should be excluded out of the TCB. Previous approaches to shielding guest VMs either suffer from insufficient protection or result in suboptimal performance due to frequent VM exits (especially for I/O operations). This paper presents CloudVisor-D, an efficient nested hypervisor design that embraces both strong protection and high performance. The core idea of CloudVisor-D is to disaggregate the nested hypervisor by separating major protection logics into a protected Guardian-VM alongside each guest VM. The Guardian-VM is securely isolated and protected by the nested hypervisor and provides secure services for most privileged operations like hypercalls, EPT violations and I/O operations from guest VMs. By leveraging recent hardware features, most privileged operations from a guest VM require no VM exits to the nested hypervisor, which are the major sources of performance slowdown in prior designs. We have implemented CloudVisor-D on a commercially available machine with these recent hardware features. Experimental evaluation shows that CloudVisor-D incurs negligible performance overhead even for I/O intensive benchmarks and in some cases outperforms a vanilla hypervisor due to the reduced number of VM exits.",
    "author": "Authors:Zeyu Mi, Dingji Li, Haibo Chen, Binyu Zang, and Haibing Guan,Shanghai Key Laboratory for Scalable Computing Systems, School of Software, Shanghai Jiao Tong University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/mi",
    "comment": ""
  },
  {
    "title": "Stealthy Tracking of Autonomous Vehicles with Cache Side Channels",
    "abstract": "Abstract:Autonomous vehicles are becoming increasingly popular, but their reliance on computer systems to sense and operate in the physical world introduces new security risks. In this paper, we show that the location privacy of an autonomous vehicle may be compromised by software side-channel attacks if localization software shares a hardware platform with an attack program. In particular, we demonstrate that a cache side-channel attack can be used to infer the route or the location of a vehicle that runs the adaptive Monte-Carlo localization (AMCL) algorithm. The main contributions of the paper are as follows. First, we show that adaptive behaviors of perception and control algorithms may introduce new side-channel vulnerabilities that reveal the physical properties of a vehicle or its environment. Second, we introduce statistical learning models that infer the AMCL algorithm's state from cache access patterns and predict the route or the location of a vehicle from the trace of the AMCL state. Third, we implement and demonstrate the attack on a realistic software stack using real-world sensor data recorded on city roads. Our findings suggest that autonomous driving software needs strong timing-channel protection for location privacy.",
    "author": "Authors:Mulong Luo, Andrew C. Myers, and G. Edward Suh,Cornell University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/luo",
    "comment": ""
  },
  {
    "title": "An Off-Chip Attack on Hardware Enclaves via the Memory Bus",
    "abstract": "Abstract:This paper shows how an attacker can break the confidentiality of a hardware enclave with Membuster, anoff-chipattack based on snooping the memory bus. An attacker with physical access can observe an unencrypted address bus and extract fine-grained memory access patterns of the victim. Membuster is qualitatively different from prior on-chip attacks to enclaves and is more difficult to thwart.We highlight several challenges for Membuster. First, DRAM requests are only visible on the memory bus at last-level cache misses. Second, the attack needs to incur minimal interference or overhead to the victim to prevent the detection of the attack. Lastly, the attacker needs to reverse-engineer the translation between virtual, physical, and DRAM addresses to perform a robust attack. We introduce three techniques,critical page whitelisting,cache squeezing, andoracle-based fuzzy matching algorithmto increase cache misses for memory accesses that are useful for the attack, with no detectable interference to the victim, and to convert memory accesses to sensitive data. We demonstrate Membuster on an Intel SGX CPU to leak confidential data from two applications: Hunspell and Memcached. We show that a single uninterrupted run of the victim can leak most of the sensitive data with high accuracy.",
    "author": "Authors:Dayeol Lee,UC Berkeley;Dongha Jung,SK Hynix;Ian T. Fang,UC Berkeley;Chia-Che Tsai,Texas A&M University;Raluca Ada Popa,UC Berkeley",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/lee-dayeol",
    "comment": ""
  },
  {
    "title": "Void: A fast and light voice liveness detection system",
    "abstract": "Abstract:Due to the open nature of voice assistants' input channels, adversaries could easily record people's use of voice commands, and replay them to spoof voice assistants. To mitigate such spoofing attacks, we present a highly efficient voice liveness detection solution called \"Void.\" Void detects voice spoofing attacks using the differences in spectral power between live-human voices and voices replayed through speakers. In contrast to existing approaches that use multiple deep learning models, and thousands of features, Void uses a single classification model with just 97 features.We used two datasets to evaluate its performance: (1) 255,173 voice samples generated with 120 participants, 15 playback devices and 12 recording devices, and (2) 18,030 publicly available voice samples generated with 42 participants, 26 playback devices and 25 recording devices. Void achieves equal error rate of 0.3% and 11.6% in detecting voice replay attacks for each dataset, respectively. Compared to a state of the art, deep learning-based solution that achieves 7.4% error rate in that public dataset, Void uses 153 times less memory and is about 8 times faster in detection. When combined with a Gaussian Mixture Model that uses Mel-frequency cepstral coefficients (MFCC) as classification features—MFCC is already being extracted and used as the main feature in speech recognition services—Void achieves 8.7% error rate on the public dataset. Moreover, Void is resilient against hidden voice command, inaudible voice command, voice synthesis, equalization manipulation attacks, and combining replay attacks with live-human voices achieving about 99.7%, 100%, 90.2%, 86.3%, and 98.2% detection rates for those attacks, respectively.",
    "author": "Authors:Muhammad Ejaz Ahmed,Data61, CSIRO;Il-Youp Kwak,Chung-Ang University;Jun Ho Huh and Iljoo Kim,Samsung Research;Taekkyung Oh,KAIST and Sungkyunkwan University;Hyoungshick Kim,Sungkyunkwan University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/ahmed-muhammad",
    "comment": ""
  },
  {
    "title": "SmartVerif: Push the Limit of Automation Capability of Verifying Security Protocols by Dynamic Strategies",
    "abstract": "Abstract:Current formal approaches have been successfully used to find design flaws in many security protocols. However, it is still challenging to automatically analyze protocols due to their large or infinite state spaces. In this paper, we propose SmartVerif, a novel and general framework that pushes the limit of automation capability of state-of-the-art verification approaches. The primary technical contribution is the dynamic strategy inside SmartVerif, which can be used to smartly search proof paths. Different from the non-trivial and error-prone design of existing static strategies, the design of our dynamic strategy is simple and flexible: it can automatically optimize itself according to the security protocols without any human intervention. With the optimized strategy, SmartVerif can localize and prove supporting lemmata, which leads to higher probability of success in verification. The insight of designing the strategy is that the node representing a supporting lemma is on an incorrect proof path with lower probability, when a random strategy is given. Hence, we implement the strategy around the insight by introducing a reinforcement learning algorithm. We also propose several methods to deal with other technical problems in implementing SmartVerif. Experimental results show that SmartVerif can automatically verify all security protocols studied in this paper. The case studies also validate the efficiency of our dynamic strategy.",
    "author": "Authors:Yan Xiong, Cheng Su, Wenchao Huang, Fuyou Miao, Wansen Wang, and Hengyi Ouyang,University of Science and Technology of China",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/xiong",
    "comment": ""
  },
  {
    "title": "An Observational Investigation of Reverse Engineers’ Processes",
    "abstract": "Abstract:Reverse engineering is a complex process essential to software-security tasks such as vulnerability discovery and malware analysis. Significant research and engineering effort has gone into developing tools to support reverse engineers. However, little work has been done to understand the way reverse engineers think when analyzing programs, leaving tool developers to make interface design decisions based only on intuition.This paper takes a first step toward a better understanding of reverse engineers’ processes, with the goal of producing insights for improving interaction design for reverse engineering tools. We present the results of a semi-structured, observational interview study of reverse engineers (N=16). Each observation investigated the questions reverse engineers ask as they probe a program, how they answer these questions, and the decisions they make throughout the reverse engineering process. From the interview responses, we distill a model of the reverse engineering process, divided into three phases: overview, sub-component scanning, and focused experimentation. Each analysis phase’s results feed the next as reverse engineers’ mental representations become more concrete. We find that reverse engineers typically use static methods in the first two phases, but dynamic methods in the final phase, with experience playing large, but varying, roles in each phase. Based on these results, we provide five interaction design guidelines for reverse engineering tools.",
    "author": "Authors:Daniel Votipka and Seth Rabin,University of Maryland;Kristopher Micinski,Syracuse University;Jeffrey S. Foster,Tufts University;Michelle L. Mazurek,University of Maryland",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/votipka-observational",
    "comment": ""
  },
  {
    "title": "Cached and Confused: Web Cache Deception in the Wild",
    "abstract": "Abstract:Web cache deception (WCD) is an attack proposed in 2017, where an attacker tricks a caching proxy into erroneously storing private information transmitted over the Internet and subsequently gains unauthorized access to that cached data. Due to the widespread use of web caches and, in particular, the use of massive networks of caching proxies deployed by content distribution network (CDN) providers as a critical component of the Internet, WCD puts a substantial population of Internet users at risk.We present the first large-scale study that quantifies the prevalence of WCD in 340 high-profile sites among the Alexa Top 5K. Our analysis reveals WCD vulnerabilities that leak private user data as well as secret authentication and authorization tokens that can be leveraged by an attacker to mount damaging web application attacks. Furthermore, we explore WCD in a scientific framework as an instance of the path confusion class of attacks, and demonstrate that variations on the path confusion technique used make it possible to exploit sites that are otherwise not impacted by the original attack. Our findings show that many popular sites remain vulnerable two years after the public disclosure of WCD.Our empirical experiments with popular CDN providers underline the fact that web caches are not plug & play technologies. In order to mitigate WCD, site operators must adopt a holistic view of their web infrastructure and carefully configure cache settings appropriate for their applications.",
    "author": "Authors:Seyed Ali Mirheidari,University of Trento;Sajjad Arshad,Northeastern University;Kaan Onarlioglu,Akamai Technologies;Bruno Crispo,University of Trento, KU Leuven;Engin Kirda and William Robertson,Northeastern University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/mirheidari",
    "comment": ""
  },
  {
    "title": "Security Analysis of Unified Payments Interface and Payment Apps in India",
    "abstract": "Abstract:Since 2016, with a strong push from the Government of India, smartphone-based payment apps have become mainstream, with over $50 billion transacted through these apps in 2018. Many of these apps use a common infrastructure introduced by the Indian government, called the Unified Payments Interface (UPI), but there has been no security analysis of this critical piece of infrastructure that supports money transfers.  This paper uses a principled methodology to do a detailed security analysis of the  UPI protocol by reverse-engineering the design of this protocol through seven popular UPI apps.  We discover previously-unreported multi-factor authentication design-level flaws in the UPI 1.0 specification that can lead to significant attacks when combined with an installed attacker-controlled application. In an extreme version of the attack, the flaws could allow a victim's bank account to be linked and emptied, even if a victim had never used a UPI app. The potential attacks were scalable and could be done remotely.  We discuss our methodology and detail how we overcame challenges in reverse-engineering this unpublished application layer protocol, including that all UPI apps undergo a rigorous security review in India and are designed to resist analysis. The work resulted in several CVEs, and a key attack vector that we reported was later addressed in UPI 2.0.",
    "author": "Authors:Renuka Kumar,University of Michigan;Sreesh Kishore; Hao Lu and Atul Prakash,University of Michigan",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/kumar",
    "comment": ""
  },
  {
    "title": "ShadowMove: A Stealthy Lateral Movement Strategy",
    "abstract": "Abstract:Advanced Persistence Threat (APT) attacks use various strategies and techniques to move laterally within an enterprise environment; however, the existing strategies and techniques have limitations such as requiring elevated permissions, creating new connections, performing new authentications, or requiring process injections. Based on these characteristics, many host and network-based solutions have been proposed to prevent or detect such lateral movement attempts. In this paper, we present a novel stealthy lateral movement strategy, ShadowMove, in which only established connections between systems in an enterprise network are misused for lateral movements. It has a set of unique features such as requiring no elevated privilege, no new connection, no extra authentication, and no process injection, which makes it stealthy against state-of-the-art detection mechanisms. ShadowMove is enabled by a novel socket duplication approach that allows a malicious process to silently abuse TCP connections established by benign processes. We design and implement ShadowMove for current Windows and Linux operating systems. To validate the feasibility of ShadowMove, we build several prototypes that successfully hijack three kinds of enterprise protocols, FTP, Microsoft SQL, and Window Remote Management, to perform lateral movement actions such as copying malware to the next target machine and launching malware on the target machine. We also confirm that our prototypes cannot be detected by existing host and network-based solutions, such as five top-notch anti-virus products (McAfee, Norton, Webroot, Bitdefender, and Windows Defender), four IDSes (Snort, OSSEC, Osquery, and Wazuh), and two Endpoint Detection and Response systems (CrowdStrike Falcon Prevent and Cisco AMP).",
    "author": "Authors:Amirreza Niakanlahiji,University of Illinois Springfield;Jinpeng Wei and Md Rabbi Alam,UNC Charlotte;Qingyang Wang,Louisiana State University;Bei-Tseng Chu,UNC Charlotte",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/niakanlahiji",
    "comment": ""
  },
  {
    "title": "Human Distinguishable Visual Key Fingerprints",
    "abstract": "Abstract:Visual fingerprints are used in human verification of identities to improve security against impersonation attacks. The verification requires the user to confirm that the visual fingerprint image derived from the trusted source is the same as the one derived from the unknown source. We introduce CEAL, a novel mechanism to build generators for visual fingerprint representations of arbitrary public strings. CEAL stands out from existing approaches in three significant aspects: (1) eliminates the need for hand curated image generation rules by  learning a generator model that imitates the style and domain of fingerprint images from a large collection of sample images, hence enabling easy customizability, (2) operates within limits of the visual discriminative  ability of human perception, such that the learned fingerprint image generator avoids mapping distinct keys to images which are not distinguishable by humans, and (3) the resulting model deterministically generates realistic fingerprint images from an input vector, where the vector components are designated to control visual properties which are either readily perceptible to a human eye, or imperceptible, yet necessary for accurately modeling the target image domain.Unlike existing visual fingerprint generators, CEAL factors in the limits of human perception, and pushes the key payload capacity of the images toward the limits of its generative model: We have built a generative network for nature landscape images which can reliably encode 123 bits of entropy in the fingerprint. We label 3,996 image pairs by 931 participants. In experiments with 402 million attack image pairs, we found that pre-image attacks performed by adversaries equipped with the human perception discriminators that we build, achieve a success rate against CEAL that is at most 0.0002%. The CEAL generator model is small (67MB) and efficient (2.3s to generate an image fingerprint on a laptop).",
    "author": "Authors:Mozhgan Azimpourkivi and Umut Topkara,Bloomberg;Bogdan Carbunar,FIU",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/azimpourkivi",
    "comment": ""
  },
  {
    "title": "KOOBE: Towards Facilitating Exploit Generation of Kernel Out-Of-Bounds Write Vulnerabilities",
    "abstract": "Abstract:The monolithic nature of modern OS kernels leads to a constant stream of bugs being discovered. It is often unclear which of these bugs are worth fixing, as only a subset of them may be serious enough to lead to security takeovers (i.e.,privilege escalations). Therefore, researchers have recently started to develop automated exploit generation techniques (for UAF bugs) to assist the bug triage process. In this paper, we investigate another top memory vulnerability in Linux kernel—out-of-bounds (OOB) memory write from heap. We design KOOBE to assist the analysis of such vulnerabilities based on two observations: (1) Surprisingly often, different OOB vulnerability instances exhibit a wide range of capabilities. (2) Kernel exploits aremulti-interaction>in nature (i.e.,multiple syscalls are involved in an exploit) which allows the exploit crafting process to be modular. Specifically, we focus on the extraction of capabilities of an OOB vulnerability which will feed the subsequent exploitability evaluation process. Our system builds on several building blocks, including a novel capability-guided fuzzing solution to uncover hidden capabilities, and a way to compose capabilities together to further enhance the likelihood of successful exploitations. In our evaluation, we demonstrate the applicability of KOOBE by exhaustively analyzing 17 most recent Linux kernel OOB vulnerabilities (where only 5 of them have publicly available exploits), for which KOOBE successfully generated candidate exploit strategies for 11 of them (including 5 that do not even have any CVEs assigned). Subsequently from these strategies, we are able to construct fully working exploits for all of them.",
    "author": "Authors:Weiteng Chen, Xiaochen Zou, Guoren Li, and Zhiyun Qian,UC Riverside",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/chen-weiteng",
    "comment": ""
  },
  {
    "title": "PARTEMU: Enabling Dynamic Analysis of Real-World TrustZone Software Using Emulation",
    "abstract": "Abstract:ARM's TrustZone technology is the basis for security of billions of devices worldwide, including Android smartphones and IoT devices. Because TrustZone has access to sensitive information such as cryptographic keys, access to TrustZone      has been locked down on real-world devices: only code that is authenticated by   a trusted party can run in TrustZone. A side-effect is that TrustZone software cannot be instrumented or monitored.  Thus, recent advances in dynamic analysis techniques such as feedback-driven fuzz testing have not been applied to         TrustZone software.                                                  \n           \nTo address the above problem, this work builds an emulator that runs four widely-used, real-world TrustZone operating systems (TZOSes) - Qualcomm's QSEE, Trustonic's Kinibi, Samsung's TEEGRIS, and Linaro's OP-TEE - and the trusted applications (TAs) that run on them.  The traditional challenge for this approach is that the emulation effort required is often impractical. However, we find that TZOSes depend only on a limited subset of hardware and software components. By carefully choosing a subset of components to emulate, we find we are able to make the effort practical. We implement our emulation on PARTEMU, a modular framework we develop on QEMU and PANDA. We show the utility of PARTEMU by integrating feedback-driven fuzz-testing using AFL and use it to perform a large-scale study of 194 unique TAs from 12 different Android smartphone vendors and a leading IoT vendor, finding previously unknown vulnerabilities in 48 TAs, several of which are exploitable. We identify patterns of developer mistakes unique to TrustZone development that cause some of these vulnerabilities, highlighting the need for TrustZone-specific developer education. We also demonstrate using PARTEMU to test the QSEE TZOS itself, finding crashes in code paths that would not normally be exercised on a real device. Our work shows that dynamic analysis of real-world TrustZone software                              through emulation is both feasible and beneficial.",
    "author": "Authors:Lee Harrison and Hayawardh Vijayakumar,Samsung Knox, Samsung Research America;Rohan Padhye and Koushik Sen,EECS Department, University of California, Berkeley;Michael Grace,Samsung Knox, Samsung Research America",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/harrison",
    "comment": ""
  },
  {
    "title": "That Was Then, This Is Now: A Security Evaluation of Password Generation, Storage, and Autofill in Browser-Based Password Managers",
    "abstract": "Abstract:Password managers have the potential to help users more effectively manage their passwords and address many of the concerns surrounding password-based authentication. However, prior research has identified significant vulnerabilities in existing password managers; especially in browser-based password managers, which are the focus of this paper. Since that time, five years has passed, leaving it unclear whether password managers remain vulnerable or whether they have addressed known security concerns. To answer this question, we evaluate thirteen popular password managers and consider all three stages of the password manager lifecycle—password generation, storage, and autofill. Our evaluation is the first analysis of password generation in password managers, finding several\nnon-random character distributions and identifying instances where generated passwords were vulnerable to online and offline guessing attacks. For password storage and autofill, we replicate past evaluations, demonstrating that while password managers have improved in the half-decade since those prior evaluations, there are still significant issues; these problems include unencrypted metadata, insecure defaults, and vulnerabilities to clickjacking attacks. Based on our results, we identify password managers to avoid, provide recommendations on how to improve existing password managers, and identify areas of future research.",
    "author": "Authors:Sean Oesch and Scott Ruoti,University of Tennessee",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/oesch",
    "comment": ""
  },
  {
    "title": "McTiny: Fast High-Confidence Post-Quantum Key Erasure for Tiny Network Servers",
    "abstract": "Abstract:Recent results have shown that some post-quantum cryptographic systems have encryption and decryption performance comparable to fast elliptic-curve cryptography (ECC) or even better. However, this performance metric is considering only CPU time and ignoring bandwidth and storage. High-confidence post-quantum encryption systems have much larger keys than ECC. For example, the code-based cryptosystem recommended by the PQCRYPTO project uses public keys of 1MB.Fast key erasure (to provide \"forward secrecy\") requires new public keys to be constantly transmitted. Either the server needs to constantly generate, store, and transmit large keys, or it needs to receive, store, and use large keys from the clients. This is not necessarily a problem for overall bandwidth, but it is a problem for storage and computation time on tiny network servers. All straightforward approaches allow easy denial-of-service attacks.This paper describes a protocol, suitable for today's networks and tiny servers, in which clients transmit their code-based one-time public keys to servers. Servers never store full client public keys but work on parts provided by the clients, without having to maintain any per-client state. Intermediate results are stored on the client side in the form of encrypted cookies and are eventually combined by the server to obtain the ciphertext. Requirements on the server side are very small: storage of one long-term private key, which is much smaller than a public key, and a few small symmetric cookie keys, which are updated regularly and erased after use. The protocol is highly parallel, requiring only a few round trips, and involves total bandwidth not much larger than a single public key. The total number of packets sent by each side is 971, each fitting into one IPv6 packet of less than 1280 bytes.The protocol makes use of the structure of encryption in code-based cryptography and benefits from small ciphertexts in code-based cryptography.",
    "author": "Authors:Daniel J. Bernstein,University of Illinois at Chicago, Ruhr University Bochum;Tanja Lange,Eindhoven University of Technology",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/bernstein",
    "comment": ""
  },
  {
    "title": "SAVIOR: Securing Autonomous Vehicles with Robust Physical Invariants",
    "abstract": "Abstract:Autonomous Vehicles (AVs), including aerial, sea, and ground vehicles, assess their environment with a variety of sensors and actuators that allow them to perform specific tasks such as navigating a route, hovering, or avoiding collisions. So far, AVs tend to trust the information provided by their sensors to make navigation decisions without data validation or verification, and therefore, attackers can exploit these limitations by feeding erroneous sensor data with the intention of disrupting or taking control of the system. In this paper we introduce SAVIOR: an architecture for securing autonomous vehicles with robust physical invariants. We implement and validate our proposal on two popular open-source controllers for aerial and ground vehicles, and demonstrate its effectiveness.",
    "author": "Authors:Raul Quinonez,University of Texas at Dallas;Jairo Giraldo,University of Utah;Luis Salazar,University of California, Santa Cruz;Erick Bauman,University of Texas at Dallas;Alvaro Cardenas,University of California, Santa Cruz;Zhiqiang Lin,Ohio State University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/quinonez",
    "comment": ""
  },
  {
    "title": "Local Model Poisoning Attacks to Byzantine-Robust Federated Learning",
    "abstract": "Abstract:In federated learning, multiple client devices jointly learn a machine learning model: each client device maintains a local model for its local training dataset, while a master device  maintains a global model via aggregating the local models from the client devices. The machine learning community recently proposed several federated learning methods that were claimed to be robust against Byzantine failures (e.g., system failures, adversarial manipulations) of certain client devices. In this work, we perform the first systematic study onlocal model poisoning attacksto federated learning. We assume an attacker has compromised some client devices, and the attacker manipulates the local model parameters on the compromised client devices during the learning process such that the global model has a large testing error rate. We formulate our attacks as optimization problems and apply our attacks to four recent Byzantine-robust federated learning methods. Our empirical results on four real-world datasets show that our attacks can substantially increase the error rates of the models learnt by the federated learning methods that were claimed to be robust against Byzantine failures of some client devices. We generalize two defenses for data poisoning attacks to defend against our local model poisoning attacks. Our evaluation results show that one defense can effectively defend against our attacks in some cases, but the defenses are not effective enough in other cases, highlighting the need for new defenses against our local model poisoning attacks to federated learning.",
    "author": "Authors:Minghong Fang,Iowa State University;Xiaoyu Cao, Jinyuan Jia, and Neil Gong,Duke University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/fang",
    "comment": ""
  },
  {
    "title": "Zero-delay Lightweight Defenses against Website Fingerprinting",
    "abstract": "Abstract:Website Fingerprinting (WF) attacks threaten user privacy on anonymity networks because they can be used by network surveillants to identify the webpage being visited by extracting features from network traffic. A number of defenses have been put forward to mitigate the threat of WF, but they are flawed: some have been defeated by stronger WF attacks, some are too expensive in overhead, while others are impractical to deploy.In this work, we propose two novel zero-delay lightweight defenses, FRONT and GLUE. We find that WF attacks rely on the feature-rich trace front, so FRONT focuses on obfuscating the trace front with dummy packets. It also randomizes the number and distribution of dummy packets for trace-to-trace randomness to impede the attacker’s learning process. GLUE adds dummy packets between separate traces so that they appear to the attacker as a long consecutive trace, rendering the attacker unable to find their start or end points, let alone classify them. Our experiments show that with 33% data overhead, FRONT outperforms the best known lightweight defense, WTF-PAD, which has a similar data overhead. With around 22%–44% data overhead, GLUE can lower the accuracy and precision of the best WF attacks to a degree comparable with the best heavyweight defenses. Both defenses have no latency overhead.",
    "author": "Authors:Jiajun Gong and Tao Wang,Hong Kong University of Science and Technology",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/gong",
    "comment": ""
  },
  {
    "title": "Devil’s Whisper: A General Approach for Physical Adversarial Attacks against Commercial Black-box Speech Recognition Devices",
    "abstract": "Abstract:Recently studies show that adversarial examples (AEs) can pose a serious threat to a “white-box” automatic speech recognition (ASR) system, when its machine-learning model is exposed to the adversary. Less clear is how realistic such a threat would be towards commercial devices, such as Google Home, Cortana, Echo, etc., whose models are not publicly available. Exploiting the learning model behind ASR system in black-box is challenging, due to the presence of complicated preprocessing and feature extraction even before the AEs could reach the model. Our research, however, shows that such a black-box attack is realistic. In the paper, we present Devil’s Whisper, a general adversarial attack on commercial ASR systems. Our idea is to enhance a simple local model roughly approximating the target black-box platform with a white-box model that is more advanced yet unrelated to the target. We find that these two models can effectively complement each other in predicting the target’s behavior, which enables highly transferable and generic attacks on the target. Using a novel optimization technique, we show that a local model built upon just over 1500 queries can be elevated by the open-source Kaldi Aspire Chain Model to effectively exploit commercial devices (Google Assistant, Google Home, Amazon Echo and Microsoft Cortana). For 98% of the target commands of these devices, our approach can generate at least one AE for attacking the target devices.",
    "author": "Authors:Yuxuan Chen,SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences; Department of Computer Science, Florida Institute of Technology;Xuejing Yuan, Jiangshan Zhang, and Yue Zhao,SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences;Shengzhi Zhang,Department of Computer Science, Metropolitan College, Boston University, USA;Kai Chen,SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences;XiaoFeng Wang,School of Informatics and Computing, Indiana University Bloomington",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/chen-yuxuan",
    "comment": ""
  },
  {
    "title": "HALucinator: Firmware Re-hosting Through Abstraction Layer Emulation",
    "abstract": "Abstract:Given the increasing ubiquity of online embedded devices, analyzing their firmware is important to security, privacy, and safety. The tight coupling between hardware and firmware and the diversity found in embedded systems makes it hard to perform dynamic analysis on firmware. However, firmware developers regularly develop code using abstractions, such as Hardware Abstraction Layers (HALs), to simplify their job. We leverage such abstractions as the basis for the re-hosting and analysis of firmware. By providing high-level replacements for HAL functions (a process termedHigh-Level Emulation – HLE), we decouple the hardware from the firmware. This approach works by first locating the library functions in a firmware sample, through binary analysis, and then providing generic implementations of these functions in a full-system emulator.We present these ideas in a prototype system, HALucinator, able to re-host firmware, and allow the virtual device to be used normally. First, we introduce extensions to existing library matching techniques that are needed to identify library functions in binary firmware, to reduce collisions, and for inferring additional function names. Next, we demonstrate the re-hosting process, through the use of simplifiedhandlersandperipheral models, which make the process fast, flexible, and portable between firmware samples and chip vendors. Finally, we demonstrate the practicality of HLE for security analysis, by supplementing HALucinator with the American Fuzzy Lop fuzzer, to locate multiple previously-unknown vulnerabilities in firmware middleware libraries.",
    "author": "Authors:Abraham A Clements,Sandia National Laboratories;Eric Gustafson,UC Santa Barbara and Sandia National Laboratories;Tobias Scharnowski,Ruhr-Universität Bochum;Paul Grosen,UC Santa Barbara;David Fritz,Sandia National Laboratories;Christopher Kruegel and Giovanni Vigna,UC Santa Barbara;Saurabh Bagchi,Purdue University;Mathias Payer,EPFL",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/clements",
    "comment": ""
  },
  {
    "title": "Estonian Electronic Identity Card: Security Flaws in Key Management",
    "abstract": "Abstract:The Estonian electronic identity card (ID card) is considered to be one of the most successful deployments\nof smart card-based national ID card systems in the world. The public-key cryptography and private keys stored on the card enable Estonian ID card holders to access e-services, give legally binding digital signatures\nand even cast an i-vote in national elections.In this paper, we describe several security flaws found in the ID card manufacturing process.\nThe flaws have been discovered by analyzing public-key certificates that have been collected from the public ID card certificate repository. In particular, we find that in some cases, contrary to the security requirements, the ID card manufacturer has generated private keys outside the chip. In several cases, copies of the same private key have been imported in the ID cards of different cardholders, allowing them to impersonate each other. In addition, as a result of a separate flaw in the manufacturing process, corrupted RSA public key moduli have been included in the certificates, which in one case led to the full recovery of the corresponding private key. This paper describes the discovery process of these findings and the incident response taken by the authorities.",
    "author": "Authors:Arnis Parsovs,Software Technology and Applications Competence Center and University of Tartu",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/parsovs",
    "comment": ""
  },
  {
    "title": "PCKV: Locally Differentially Private Correlated Key-Value Data Collection with Optimized Utility",
    "abstract": "Abstract:Data collection under local differential privacy (LDP) has been mostly studied for homogeneous data. Real-world applications often involve a mixture of different data types such as key-value pairs, where the frequency of keys and mean of values under each key must be estimated simultaneously. For key-value data collection with LDP,  it is challenging to achieve a good utility-privacy tradeoff since the data contains two dimensions and a user may possess multiple key-value pairs. There is also an inherent correlation between key and values which if not harnessed, will lead to poor utility.  In this paper, we propose a locally differentially private key-value data collection framework that utilizes correlated perturbations to enhance utility. We instantiate our framework by two protocols PCKV-UE (based on Unary Encoding) and PCKV-GRR (based on Generalized Randomized Response),  where we design an advanced Padding-and-Sampling mechanism and an improved mean estimator which is non-interactive. Due to our correlated key and value perturbation mechanisms, the composed privacy budget is shown to be less than that of independent perturbation of key and value, which enables us to further optimize the perturbation parameters via budget allocation.  Experimental results on both synthetic and real-world datasets show that our proposed protocols achieve better utility for both frequency and mean estimations under the same LDP guarantees than state-of-the-art mechanisms.",
    "author": "Authors:Xiaolan Gu and Ming Li,University of Arizona;Yueqiang Cheng,Baidu X-Lab;Li Xiong,Emory University;Yang Cao,Kyoto University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/gu",
    "comment": ""
  },
  {
    "title": "Plug-N-Pwned: Comprehensive Vulnerability Analysis of OBD-II Dongles as A New Over-the-Air Attack Surface in Automotive IoT",
    "abstract": "Abstract:With the growing trend of the Internet of Things, a large number of wireless OBD-II dongles are developed, which can be simply plugged into vehicles to enable remote functions such as sophisticated vehicle control and status monitoring. However, since these dongles are directly connected with in-vehicle networks, they may open a new over-the-air attack surface for vehicles. In this paper, we conduct the first comprehensive security analysis on all wireless OBD-II dongles available on Amazon in the US in February 2019, which were 77 in total. To systematically perform the analysis, we design and implement an automated tool DongleScope that dynamically tests these dongles from all possible attack stages on a real automobile. With DongleScope, we have identified 5 different types of vulnerabilities, with 4 being newly discovered. Our results reveal that each of the 77 dongles exposes at least two types of these vulnerabilities, which indicates a widespread vulnerability exposure among wireless OBD-II dongles on the market today. To demonstrate the severity, we further construct 4 classes of concrete attacks with a variety of practical implications such as privacy leakage, property theft, and even safety threat. We also discuss the root causes and feasible countermeasures, and have made corresponding responsible disclosure.",
    "author": "Authors:Haohuang Wen,Ohio State University;Qi Alfred Chen,University of California, Irvine;Zhiqiang Lin,Ohio State University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/wen",
    "comment": ""
  },
  {
    "title": "Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning",
    "abstract": "Abstract:Machine learning (ML) has progressed rapidly during the past decade and the major factor that drives such development is the unprecedented large-scale data. As data generation is a continuous process, this leads to ML model owners updating their models frequently with newly-collected data in an online learning scenario. In consequence, if an ML model is queried with the same set of data samples at two different points in time, it will provide different results.In this paper, we investigate whether the change in the output of a black-box ML model before and after being updated can leak information of the dataset used to perform the update, namely the updating set. This constitutes a new attack surface against black-box ML models and such information leakage may compromise the intellectual property and data privacy of the ML model owner. We propose four attacks following an encoder-decoder formulation, which allows inferring diverse information of the updating set. Our new attacks are facilitated by state-of-the-art deep learning techniques. In particular, we propose a hybrid generative model (CBM-GAN) that is based on generative adversarial networks (GANs) but includes a reconstructive loss that allows reconstructing accurate samples. Our experiments show that the proposed attacks achieve strong performance.",
    "author": "Authors:Ahmed Salem,CISPA Helmholtz Center for Information Security;Apratim Bhattacharya,Max Planck Institute for Informatics;Michael Backes, Mario Fritz, and Yang Zhang,CISPA Helmholtz Center for Information Security",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/salem",
    "comment": ""
  },
  {
    "title": "Actions Speak Louder than Words: Entity-Sensitive Privacy Policy and Data Flow Analysis with PoliCheck",
    "abstract": "Abstract:Identifying privacy-sensitive data leaks by mobile applications has been a topic of great research interest for the past decade. Technically, such data flows are not “leaks” if they are disclosed in a privacy policy. To address this limitation in automated analysis, recent work has combined program analysis of applications with analysis of privacy policies to determine the flow-to-policy consistency, and hence violations thereof. However, this prior work has a fundamental weakness: it does not differentiate the entity (e.g., first-party vs. third-party) receiving the privacy-sensitive data. In this paper, we propose POLICHECK, which formalizes and implements an entity-sensitive flow-to-policy consistency model. We use POLICHECK to study 13,796 applications and their privacy policies and find that up to 42.4% of applications either incorrectly disclose or omit disclosing their privacy-sensitive data flows. Our results also demonstrate the significance of considering entities: without considering entity, prior approaches would falsely classify up to 38.4% of applications as having privacy-sensitive data flows consistent with their privacy policies. These false classifications include data flows to third-parties that are omitted (e.g., the policy states only the first-party collects the data type), incorrect (e.g., the policy states the third-party does not collect the data type), and ambiguous (e.g., the policy has conflicting statements about the data type collection). By defining a novel automated, entity-sensitive flow-to-policy consistency analysis, POLICHECK provides the highest-precision method to date to determine if applications properly disclose their privacy-sensitive behaviors.",
    "author": "Authors:Benjamin Andow,IBM T.J. Watson Research Center;Samin Yaseer Mahmud, Justin Whitaker, William Enck, and Bradley Reaves,North Carolina State University;Kapil Singh,IBM T.J. Watson Research Center;Serge Egelman,U.C. Berkeley; ICSI; AppCensus Inc.",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/andow",
    "comment": ""
  },
  {
    "title": "Exploring Connections Between Active Learning and Model Extraction",
    "abstract": "Abstract:Machine learning is being increasingly used by individuals, research institutions, and corporations. This has resulted in the surge of Machine Learning-as-a-Service (MLaaS) - cloud services that provide\n(a) tools and resources to learn the model, and (b) a user-friendly query interface to access the model. However, such MLaaS systems raise privacy concerns such asmodel extraction. In model\nextraction attacks, adversaries maliciously exploit the query interface tostealthe model. More precisely, in a model extraction attack, a good approximation of a sensitive or proprietary\nmodel held by the server is extracted (i.e.learned) by a dishonest user who interacts with the server only via the query interface. This attack was introduced by Tramèret. al.at the 2016 USENIX Security\nSymposium, where practical attacks for various models were shown. We believe that better understanding the efficacy of model extraction attacks is paramount to designing secure MLaaS systems. To that end, we take the first step by (a) formalizing model extraction and discussing possible defense strategies, and (b) drawing parallels between model extraction and established area ofactive learning. In particular, we show that recent advancements in the active learning domain can be used to implement powerful model extraction attacks and investigate possible defense strategies.",
    "author": "Authors:Varun Chandrasekaran,University of Wisconsin-Madison;Kamalika Chaudhuri,University of California San Diego;Irene Giacomelli,Protocol Labs;Somesh Jha,University of Wisconsin-Madison;Songbai Yan,University of California San Diego",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/chandrasekaran",
    "comment": ""
  },
  {
    "title": "Achieving Keyless CDNs with Conclaves",
    "abstract": "Abstract:Content Delivery Networks (CDNs) serve a large and increasing portion of today’s web content. Beyond caching, CDNs provide their customers with a variety of services, including protection against DDoS and targeted attacks. As the web shifts from HTTP to HTTPS, CDNs continue to provide such services by also assuming control of their customers’ private keys, thereby breaking a fundamental security principle: private keys must only be known by their owner.We present the design and implementation of Phoenix, the first truly “keyless CDN”. Phoenix uses secure enclaves (in particular Intel SGX) to host web content, store sensitive key material, apply web application firewalls, and more on otherwise untrusted machines. To support scalability and multitenancy, Phoenix is built around a new architectural primitive which we call conclaves: containers of enclaves. Conclaves make it straightforward to deploy multi-process, scalable, legacy applications. We also develop a filesystem to extend the enclave’s security guarantees to untrusted storage. In its strongest configuration, Phoenix reduces the knowledge of the edge server to that of a traditional on-path HTTPS adversary. We evaluate the performance of Phoenix with a series of micro- and macro-benchmarks.",
    "author": "Authors:Stephen Herwig,University of Maryland;Christina Garman,Purdue University;Dave Levin,University of Maryland",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/herwig",
    "comment": ""
  },
  {
    "title": "On Training Robust PDF Malware Classifiers",
    "abstract": "Abstract:Although state-of-the-art PDF malware classifiers can be trained with almost perfect test accuracy (99%) and extremely low false positive rate (under 0.1%), it has been shown that even a simple adversary can evade them. A practically useful malware classifier must be robust against evasion attacks. However, achieving such robustness is an extremely challenging task.In this paper, we take the first steps towards training robust PDF malware classifiers with verifiable robustness properties. For instance, a robustness property can enforce that no matter how many pages from benign documents are inserted into a PDF malware, the classifier must still classify it as malicious. We demonstrate how the worst-case behavior of a malware classifier with respect to specific robustness properties can be formally verified. Furthermore, we find that training classifiers that satisfy formally verified robustness properties can increase the evasion cost of unbounded (i.e., not bounded by the robustness properties) attackers by eliminating simple evasion attacks.Specifically, we propose a new distance metric that operates on the PDF tree structure and specify two classes of robustness properties including subtree insertions and deletions. We utilize state-of-the-art verifiably robust training method to build robust PDF malware classifiers. Our results show that, we can achieve 92.27% average verified robust accuracy over three properties, while maintaining 99.74% accuracy and 0.56% false positive rate. With simple robustness properties, our robust model maintains 7% higher robust accuracy than all the baseline models against unrestricted whitebox attacks. Moreover, the state-of-the-art and new adaptive evolutionary attackers need up to 10 times larger $L_0$ feature distance and 21 times more PDF basic mutations (e.g., inserting and deleting objects) to evade our robust model than the baselines.",
    "author": "Authors:Yizheng Chen, Shiqi Wang, Dongdong She, and Suman Jana,Columbia University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/chen-yizheng",
    "comment": ""
  },
  {
    "title": "Programmable In-Network Security for Context-aware BYOD Policies",
    "abstract": "Abstract:Bring Your Own Device (BYOD) has become the new norm for enterprise networks, but BYOD security remains a top concern. Context-aware security, which enforces access control based on dynamic runtime context, is a promising approach. Recent work has developed SDN solutions to collect device contexts and enforce access control at a central controller. However, the central controller could become a bottleneck and attack target. Processing context signals at the remote controller is also too slow for real-time decision change.We present a new paradigm, programmable in-network security (Poise), which is enabled by the emergence of programmable switches. At the heart of Poise is a novel security primitive, which can be programmed to support a wide range of context-aware policies in hardware. Users of Poise specify concise policies, and Poise compiles them into different configurations of the primitive in P4. Compared with traditional SDN defenses, Poise is resilient to control plane saturation attacks, and it dramatically increases defense agility.",
    "author": "Authors:Qiao Kang,Rice University;Lei Xue,The Hong Kong Polytechnic University;Adam Morrison, Yuxin Tang, and Ang Chen,Rice University;Xiapu Luo,The Hong Kong Polytechnic University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/kang",
    "comment": ""
  },
  {
    "title": "FuzzGuard: Filtering out Unreachable Inputs in Directed Grey-box Fuzzing through Deep Learning",
    "abstract": "Abstract:Recently, directed grey-box fuzzing (DGF) becomes popular in the field of software testing. Different from coverage-based fuzzing whose goal is to increase code coverage for triggering more bugs, DGF is designed to check whether a piece of potentially buggy code (e.g., string operations) really contains a bug. Ideally, all the inputs generated by DGF should reach the target buggy code until triggering the bug. It is a waste of time when executing with unreachable inputs. Unfortunately, in real situations, large numbers of the generated inputs cannot let a program execute to the target, greatly impacting the efficiency of fuzzing, especially when the buggy code is embedded in the code guarded by various constraints.In this paper, we propose a deep-learning-based approach to predict the reachability of inputs (i.e., miss the target or not) before executing the target program, helping DGF filtering out the unreachable ones to boost the performance of fuzzing. To apply deep learning with DGF, we design a suite of new techniques (e.g., step-forwarding approach, representative data selection) to solve the problems of unbalanced labeled data and insufficient time in the training process. Further, we implement the proposed approach called FuzzGuard and equip it with the state-of-the-art DGF (e.g., AFLGo). Evaluations on 45 real vulnerabilities show that FuzzGuard boosts the fuzzing efficiency of the vanilla AFLGo up to 17.1×. Finally, to understand the key features learned by FuzzGuard, we illustrate their connection with the constraints in the programs.",
    "author": "Authors:Peiyuan Zong, Tao Lv, Dawei Wang, Zizhuang Deng, Ruigang Liang, and Kai Chen,SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/zong",
    "comment": ""
  },
  {
    "title": "Data Recovery from “Scrubbed” NAND Flash Storage: Need for Analog Sanitization",
    "abstract": "Abstract:Digital sanitization of flash based non-volatile memory system is a well-researched topic. Since flash memory cell holds information in the analog threshold voltage, flash cell may hold the imprints of previously written data even after digital sanitization. In this paper, we show that data is partially or completely recoverable from the flash media sanitized with “scrubbing” based technique, which is a popular technique for page deletion in NAND flash. We find that adversary may utilize the data retention property of the memory cells for recovering the deleted data using standard digital interfaces with the memory. We demonstrate data recovery from commercial flash memory chip, sanitized with scrubbing, by using partial erase operation on the chip. Our results show that analog scrubbing is needed to securely delete information in flash system. We propose and implement analog scrubbing using partial program operation based on the file creation time information.",
    "author": "Authors:Md Mehedi Hasan and Biswajit Ray,The University of Alabama in Huntsville",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/hasan",
    "comment": ""
  },
  {
    "title": "Pixel: Multi-signatures for Consensus",
    "abstract": "Abstract:In Proof-of-Stake (PoS) and permissioned blockchains, a committee of verifiers agrees and sign every new block of transactions. These blocks are validated, propagated, and stored by all users in the network. However, posterior corruptions pose a common threat to these designs, because the adversary can corrupt committee verifiers after they certified a block and use their signing keys to certify a different block. Designing efficient and secure digital signatures for use in PoS blockchains can substantially reduce bandwidth, storage and computing requirements from nodes, thereby enabling more efficient applications.We present Pixel, a pairing-based forward-secure multi-signature scheme optimized for use in blockchains, that achieves substantial savings in bandwidth, storage requirements, and verification effort. Pixel signatures consist of two group elements, regardless of the number of signers, can be verified using three pairings and one exponentiation, and support non-interactive aggregation of individual signatures into a multi-signature. Pixel signatures are also forward-secure and let signers evolve their keys over time, such that new keys cannot be used to sign on old blocks, protecting against posterior corruptions attacks on blockchains. We show how to integrate Pixel into any PoS blockchain. Next, we evaluate Pixel in a real-world PoS blockchain implementation, showing that it yields notable savings in storage, bandwidth, and block verification time. In particular, Pixel signatures reduce the size of blocks with 1500 transactions by 35% and reduce block verification time by 38%.",
    "author": "Authors:Manu Drijvers,DFINITY;Sergey Gorbunov,Algorand and University of Waterloo;Gregory Neven,DFINITY;Hoeteck Wee,Algorand and CNRS, ENS, PSL",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/drijvers",
    "comment": ""
  },
  {
    "title": "Secure parallel computation on national scale volumes of data",
    "abstract": "Abstract:We revisit the problem of performing secure computation of graph-parallel algorithms, focusing on the applications of securely outsourcing matrix factorization, and histograms. Leveraging recent results in low-communication secure multi-party computation, and a security relaxation that allows the computation servers to learn some differentially private leakage about user inputs, we construct a new protocol that reduces overall runtime by 320X, reduces the number of AES calls by 750X , and reduces the total communication by 200X . Our system can securely compute histograms over 300 million items in about 4 minutes, and it can perform sparse matrix factorization, which is commonly used in recommendation systems, on 20 million records in about 6 minutes. Furthermore, in contrast to prior work, our system is secure against a malicious adversary that corrupts one of the computing servers.",
    "author": "Authors:Sahar Mazloom and Phi Hung Le,George Mason University;Samuel Ranellucci,Unbound Tech;S. Dov Gordon,George Mason University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/mazloom",
    "comment": ""
  },
  {
    "title": "Hybrid Batch Attacks: Finding Black-box Adversarial Examples with Limited Queries",
    "abstract": "Abstract:We study adversarial examples in a black-box setting where the adversary only has API access to the target model and each query is expensive. Prior work on black-box adversarial examples follows one of two main strategies: (1) transfer attacks use white-box attacks on local models to find candidate adversarial examples that transfer to the target model, and (2) optimization-based attacks use queries to the target model and apply optimization techniques to search for adversarial examples. We propose hybrid attacks that combine both strategies, using candidate adversarial examples from local models as starting points for optimization-based attacks and using labels learned in optimization-based attacks to tune local models for finding transfer candidates. We empirically demonstrate on the MNIST, CIFAR10, and ImageNet datasets that our hybrid attack strategy reduces cost and improves success rates. We also introduce a seed prioritization strategy which enables attackers to focus their resources on the most promising seeds. Combining hybrid attacks with our seed prioritization strategy enables batch attacks that can reliably find adversarial examples with only a handful of queries.",
    "author": "Authors:Fnu Suya, Jianfeng Chi, David Evans, and Yuan Tian,University of Virginia",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/suya",
    "comment": ""
  },
  {
    "title": "BScout: Direct Whole Patch Presence Test for Java Executables",
    "abstract": "Abstract:To protect end-users and software from known vulnerabilities, it is crucial to apply security patches to affected executables timely. To this end, patch presence tests are proposed with the capability of independently investigating patch application status on a target without source code. Existing work on patch presence testing adopts a signature-based approach. To make a trade-off between the uniqueness and the stability of the signature, existing work is limited to use a small and localized patch snippet (instead of the whole patch) for signature generation, so they are inherently unreliable.In light of this, we present BScout, which directly checks the presence of a whole patch in Java executables without generating signatures. BScout features several new techniques to bridge the semantic gap between source code and bytecode instructions during the testing, and accurately checks the fine-grained patch semantics in the whole target executable. We evaluate BScout with 194 CVEs from the Android framework and third-party libraries. The results show that it achieves remarkable accuracy with and without line number information (i.e., debug information) presented in a target executable. We further apply BScout to perform a large-scale patch application practice study with 2,506 Android system images from 7 vendors. Our study reveals many findings that have not yet been reported.",
    "author": "Authors:Jiarun Dai, Yuan Zhang, Zheyue Jiang, Yingtian Zhou, and Junyan Chen,Fudan University;Xinyu Xing,Pennsylvania State University;Xiaohan Zhang, Xin Tan, Min Yang, and Zhemin Yang,Fudan University",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/dai",
    "comment": ""
  },
  {
    "title": "BigMAC: Fine-Grained Policy Analysis of Android Firmware",
    "abstract": "Abstract:The Android operating system is the world's dominant mobile computing platform. To defend against malicious applications and external attack, Android relies upon a complex combination of discretionary and mandatory access control mechanisms, including Linux capabilities, to maintain least privilege. To understand the impact and interaction between these layers, we created a framework called BigMAC that combines and instantiates all layers of the policy together in a fine grained graph supporting millions of edges. Our model filters out paths and types not in use on actual systems that policy analysis alone would consider. Unlike previous work which requires a rooted device, using only static firmware and Android domain knowledge, we are able to extract and recreate the security state of a running system, achieving a process credential recovery at best 74.7% and a filesystem DAC and MAC accuracy of over 98%. Using BigMAC, we develop attack queries to discover sets of objects that can be influenced by untrusted applications and external peripherals. Our evaluation against Samsung S8+ and LG G7 firmwares reveals multiple policy concerns, including untrusted apps on LG being able to communicate with a kernel monitoring service, Samsung S8+ allowing IPC from untrusted apps to some root processes, at least 24 processes with theCAP_SYS_ADMINcapability, andsystem_serverwith the capability to load kernel modules. We have reported our findings to the corresponding vendors and release BigMAC for the community.",
    "author": "Authors:Grant Hernandez,University of Florida;Dave (Jing) Tian,Purdue University;Anurag Swarnim Yadav, Byron J. Williams, and Kevin R.B. Butler,University of Florida",
    "year": "2020",
    "publication": "security",
    "link": "https://www.usenix.org/conference/usenixsecurity20/presentation/hernandez",
    "comment": ""
  }
]